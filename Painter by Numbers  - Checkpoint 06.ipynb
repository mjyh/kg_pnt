{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/data/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "from PIL import Image\n",
    "import skimage.data\n",
    "import skimage.exposure\n",
    "import skimage.color\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_pairs(train_info):\n",
    "    \"\"\"Creates training data from the supplied training image information file\"\"\"\n",
    "    artists = train_info.artist.unique()\n",
    "\n",
    "    n = train_info.groupby('artist').size()\n",
    "    n = (2*n**2).sum() \n",
    "    t = pd.DataFrame(np.zeros((n, 4)), columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    for artist in artists:\n",
    "\n",
    "        #artist info is Ax2 matrix of artist, filename\n",
    "        artistInfo = train_info[train_info.artist==artist][['artist', 'filename']].values\n",
    "        \n",
    "        use = train_info[train_info.artist != artist ].index.values\n",
    "        np.random.shuffle(use)\n",
    "        \n",
    "        #nm = np.min([a.shape[0]**2, train_info[train_info.artist != m].shape[0] ])\n",
    "        numExamples = np.min([len(artistInfo)**2, sum(train_info.artist != artist) ])\n",
    "        use = use[0:numExamples]\n",
    "        \n",
    "        #diffArtistInfo a Bx2 matrix of artist, filename\n",
    "        diffArtistInfo = train_info[train_info.artist!=artist][['artist', 'filename']].ix[use, :].values\n",
    "\n",
    "        \n",
    "        toAdd_SameArtist = pd.DataFrame(np.concatenate([  np.repeat(artistInfo[:, 0], len(artistInfo)).reshape((-1,1)), #artist\n",
    "                                            np.repeat(artistInfo[:, 1],\n",
    "                                            artistInfo.shape[0]).reshape((-1,1)),\n",
    "                                            np.tile(artistInfo, (len(artistInfo), 1))],\n",
    "                                         axis=1),\n",
    "                          columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "        toAdd_SameArtist = toAdd_SameArtist.loc[0:numExamples, :]\n",
    "        \n",
    "        toAdd_DiffArtist = pd.DataFrame(np.concatenate([np.tile(artistInfo,\n",
    "                                                  (len(artistInfo), 1))[0:len(diffArtistInfo), :],\n",
    "                                          diffArtistInfo], axis=1),\n",
    "                          columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "        toAdd_DiffArtist = toAdd_DiffArtist.loc[0:numExamples, :]\n",
    "        \n",
    "        #print(j, i, a2.shape[0], b2.shape[0])\n",
    "        #print(b2)\n",
    "        t.iloc[i:i+len(toAdd_SameArtist), :] = toAdd_SameArtist.values\n",
    "        t.iloc[i+len(toAdd_SameArtist):i+len(toAdd_SameArtist)+len(toAdd_DiffArtist), :] = toAdd_DiffArtist.values\n",
    "        \n",
    "        i += len(toAdd_SameArtist) + len(toAdd_DiffArtist)\n",
    "        j += 1\n",
    "        if j%100==0:\n",
    "            print('finished %s of %s artists'%(j, len(artists)))\n",
    "\n",
    "    print('make pairs completed')\n",
    "    t = t[~t.image2.isin([np.nan, 0])]\n",
    "    return t[t.image1 > t.image2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Image List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def prepImageList(image_info, isTest):\n",
    "#     \"\"\"given the train_image_info or submission_info, returns a dataframe with a single column containing filenames of images\"\"\"\n",
    "#     if isTest:\n",
    "#         images = list(set(list(image_info.image1.unique()) + list(image_info.image2.unique())))\n",
    "#         result = pd.DataFrame(np.array(images).reshape((-1, 1)), columns = ['filename'])\n",
    "#     else:\n",
    "#         result = pd.DataFrame(columns = ['filename'], data = image_info['filename'] )\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features Parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeaturesParent(isTest):\n",
    "    \"\"\"Creates features for training and test images. This function utilizes multiprocessing.\n",
    "    Args:\n",
    "        isTest: bool to fetch training or test data\n",
    "    Returns:\n",
    "        pandas DataFrame containing features\n",
    "    \"\"\"\n",
    "    \n",
    "    num_cores = multiprocessing.cpu_count() - 5\n",
    "    \n",
    "    argsList = []\n",
    "    \n",
    "    for jobNum in range(num_cores):\n",
    "        argsList.append((isTest, jobNum, num_cores))\n",
    "        \n",
    "\n",
    "    print('Launching %s jobs' % (num_cores))\n",
    "    startTime = time.time()\n",
    "    \n",
    "    pool = multiprocessing.Pool(num_cores)\n",
    "    image_features_list = pool.starmap(getFeaturesWorker, argsList)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    image_features = pd.concat(image_features_list)\n",
    "    \n",
    "    endTime = time.time()\n",
    "    \n",
    "    print(\"collecting features complete, time taken = %.2f minutes\" % ((endTime - startTime) / 60.0))\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFeaturesWorker(isTest, jobNum, totalJobs):\n",
    "    \"\"\"Child function for computing image features, only to be called by getFeaturesParent\n",
    "    Args:\n",
    "        isTest: whether to compute features for test or training images\n",
    "        jobNum: which job number this is\n",
    "        totalJobs: total number of jobs\n",
    "    Returns:\n",
    "        pandas dataframe containing a data for a fraction of the training or test images\n",
    "    \"\"\"\n",
    "    if isTest:\n",
    "        mydir = r'/data/test_data/test'\n",
    "        info = pd.read_csv(r'/data/test_data/submission_info.csv', index_col = 0)\n",
    "    else:\n",
    "        mydir = r'/data/training_data/train'\n",
    "        info = pd.read_csv(r'/data/training_data/train_info.csv', index_col = 0)\n",
    "    \n",
    "    totalNumImages = len(info)\n",
    "    \n",
    "    chunkSize = np.int(totalNumImages/totalJobs)\n",
    "    \n",
    "    if jobNum == totalJobs - 1:\n",
    "        startInd = jobNum * chunkSize\n",
    "        endInd = totalNumImages\n",
    "    else:\n",
    "        startInd = jobNum * chunkSize\n",
    "        endInd = (jobNum + 1) * chunkSize\n",
    "        \n",
    "    info = info.iloc[startInd:endInd]\n",
    "    \n",
    "    info['pixelsx'] = np.nan\n",
    "    info['pixelsy'] = np.nan\n",
    "    info['size_bytes'] = np.nan\n",
    "    \n",
    "    info['r_mean'] = np.nan\n",
    "    info['r_med'] = np.nan\n",
    "    info['r_std'] = np.nan\n",
    "    \n",
    "    info['g_mean'] = np.nan\n",
    "    info['g_med'] = np.nan\n",
    "    info['g_std'] = np.nan\n",
    "    \n",
    "    info['b_mean'] = np.nan\n",
    "    info['b_med'] = np.nan\n",
    "    info['b_std'] = np.nan\n",
    "    \n",
    "    info['h_mean'] = np.nan\n",
    "    info['h_var'] = np.nan\n",
    "    \n",
    "    info['s_mean'] = np.nan\n",
    "    info['s_std'] = np.nan\n",
    "    info['s_med'] = np.nan\n",
    "    \n",
    "    info['v_mean'] = np.nan\n",
    "    info['v_std'] = np.nan\n",
    "    info['v_med'] = np.nan\n",
    "    \n",
    "    info['is_grayscale'] = np.nan\n",
    "      \n",
    "    print('Job %s, starting getting image info for images %s-%s' % (jobNum, startInd, endInd-1))\n",
    "    startTime = time.clock()\n",
    "    \n",
    "    for ind, i in enumerate(info.index.values):\n",
    "        try:       \n",
    "            #im = Image.open(mydir+'/'+info.loc[i, 'filename'])\n",
    "            #info.loc[i, 'pixelsx'], info.loc[i, 'pixelsy'] = im.size\n",
    "            \n",
    "            im = skimage.data.imread(mydir + '/' + info.loc[i, 'filename'])\n",
    "                \n",
    "            info.loc[i, 'pixelsx'] = im.shape[1]\n",
    "            info.loc[i, 'pixelsy'] = im.shape[0]\n",
    "            \n",
    "            grayscale = (len(im.shape) == 2)\n",
    "            \n",
    "            if grayscale:\n",
    "                info.loc[i, 'r_mean'] = im.mean()\n",
    "                info.loc[i, 'g_mean'] = info.loc[i, 'b_mean'] = info.loc[i, 'r_mean']\n",
    "                \n",
    "                info.loc[i, 'r_med'] = np.median(im)\n",
    "                info.loc[i, 'g_med'] = info.loc[i, 'b_med'] = info.loc[i, 'r_med']\n",
    "                \n",
    "                info.loc[i, 'r_std'] = im.std()\n",
    "                info.loc[i, 'g_std'] = info.loc[i, 'b_std'] = info.loc[i, 'r_std']\n",
    "                \n",
    "                info.loc[i, 'is_grayscale' ] = 1\n",
    "                \n",
    "                info.loc[i, 'h_mean'] = 0\n",
    "                info.loc[i, 'h_var'] = 0\n",
    "                info.loc[i, 's_mean'] = 0\n",
    "                info.loc[i, 's_std'] = 0\n",
    "                info.loc[i, 's_med'] = 0\n",
    "                info.loc[i, 'v_mean'] = info.loc[i, 'r_mean']/256.0\n",
    "                info.loc[i, 'v_std'] = info.loc[i, 'r_std']/256.0\n",
    "                info.loc[i, 'v_med'] = info.loc[i, 'r_med']/256.0\n",
    "                \n",
    "            else:\n",
    "                info.loc[i, 'r_mean'] = im[:,:,0].mean()\n",
    "                info.loc[i, 'g_mean'] = im[:,:,1].mean()\n",
    "                info.loc[i, 'b_mean'] = im[:,:,2].mean()\n",
    "                info.loc[i, 'r_med'] = np.median(im[:,:,0])\n",
    "                info.loc[i, 'g_med'] = np.median(im[:,:,1])\n",
    "                info.loc[i, 'b_med'] = np.median(im[:,:,2])\n",
    "                info.loc[i, 'r_std'] = im[:,:,0].std()\n",
    "                info.loc[i, 'g_std'] = im[:,:,1].std()\n",
    "                info.loc[i, 'b_std'] = im[:,:,2].std()\n",
    "                info.loc[i, 'is_grayscale' ] = 0\n",
    "                \n",
    "                #if it is in RGBA, we don't handle it for now\n",
    "                if (len(im.shape) == 3) and im.shape[2] == 4:\n",
    "                    print('%s is rgba' % info.loc[i, 'filename'])\n",
    "                else:     \n",
    "                    # convert image to hue/saturation/value\n",
    "                    hsvImage = skimage.color.rgb2hsv(im)\n",
    "                    angles = hsvImage[:,:,0] * 2.0 * np.pi\n",
    "\n",
    "                    # average hue is converting the (0-1) hue value to unit vector coordinates\n",
    "                    # and finding the average direction\n",
    "                    sinSum = np.sin(angles).sum()\n",
    "                    cosSum = np.cos(angles).sum()\n",
    "                    info.loc[i, 'h_mean'] = np.arctan(sinSum/cosSum)\n",
    "\n",
    "                    # use the variance formula for a circulator distribution\n",
    "                    R2 = np.power(sinSum, 2) + np.power(cosSum, 2)\n",
    "                    numPixels = info.loc[i, 'pixelsx'] * info.loc[i, 'pixelsy']\n",
    "                    R_bar = np.sqrt(R2)/numPixels\n",
    "                    info.loc[i, 'h_var'] = 1 - R_bar\n",
    "\n",
    "                    info.loc[i, 's_mean'] = hsvImage[:,:,1].mean()\n",
    "                    info.loc[i, 's_std'] = np.median(hsvImage[:,:,1])\n",
    "                    info.loc[i, 's_med'] = hsvImage[:,:,1].std()\n",
    "                    info.loc[i, 'v_mean'] = hsvImage[:,:,2].mean()\n",
    "                    info.loc[i, 'v_std'] = np.median(hsvImage[:,:,2])\n",
    "                    info.loc[i, 'v_med'] = hsvImage[:,:,2].std()\n",
    "                \n",
    "            #im = cv2.imread(dir+'/'+info.loc[i, 'new_filename'])\n",
    "            #info.loc[i, 'pixelsx'], info.loc[i, 'pixelsy'] = im.shape[0:2]\n",
    "            info.loc[i, 'size_bytes'] = os.path.getsize(mydir+'/'+info.loc[i, 'filename']) \n",
    "            if (ind+1)%100==0:\n",
    "                currentTime = time.clock()\n",
    "                print('Job %s, finished %s of %s, total time = %.2f min' %\n",
    "                     (jobNum, (ind+1), len(info), (currentTime - startTime)/60.0))\n",
    "        except:\n",
    "            print('job %s - error in %s' % (jobNum, mydir+'/'+info.loc[i, 'filename']))\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    currentTime = time.clock()\n",
    "    print('- Job %s, finished getting image info, total time = %.2f min' % ( jobNum, (currentTime - startTime) / 60.0))\n",
    "    \n",
    "    return info\n",
    "\n",
    "    #return info.rename(columns={'filename' : 'new_filename'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load image info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load training info\n",
    "train_info = pd.read_csv(r'/data/training_data/train_info.csv', index_col=0)\n",
    "submission_info = pd.read_csv(r'/data/test_data/submission_info.csv', index_col=0)\n",
    "\n",
    "#shuffle and save info\n",
    "#train_info = train_info.iloc[np.random.permutation(len(train_info))]\n",
    "#submission_info = submission_info.iloc[np.random.permutation(len(submission_info))]\n",
    "\n",
    "#train_info.to_csv(r'/data/training_data/train_info.csv')\n",
    "#submission_info.to_csv(r'/data/test_data/submission_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create submission image info from submission pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission image data is a bunch of images pairs, but we may want to work with a list of test images instead\n",
    "\n",
    "#submission_pairs = pd.read_csv(r'/data/test_data/submission_pairs.csv')\n",
    "#images = list(set(list(submission_info.image1.unique()) + list(submission_info.image2.unique())))\n",
    "#submission_info = pd.DataFrame(data=images, columns=['filename'])\n",
    "#submission_info = pd.read_csv(r'/data/test_data/submission_info.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pairs = pd.read_csv(r'/data/test_data/submission_pairs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make training pairs\n",
    "#train_pairs = make_pairs(train_image_info)\n",
    "#train_pairs[ 'sameArtist' ] = train_pairs[ 'artist1' ] == train_pairs[ 'artist2' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save as csv\n",
    "#train_pairs.to_csv(r'/data/training_data/train_pairs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load pairs\n",
    "train_pairs = pd.read_csv(r'/data/training_data/train_pairs.csv', index_col = 0)\n",
    "#submission_pairs = pd.read_csv(r'/data/test_data/submission_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4737102"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shuffle pairs, reduce number if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pairs = train_pairs.iloc[np.random.permutation(len(train_pairs))]\n",
    "train_pairs = train_pairs.iloc[0:2000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin computing features\n",
      "Launching 35 jobs\n",
      "Job 3, starting getting image info for images 2040-2719\n",
      "Job 24, starting getting image info for images 16320-16999\n",
      "Job 18, starting getting image info for images 12240-12919\n",
      "Job 12, starting getting image info for images 8160-8839\n",
      "Job 7, starting getting image info for images 4760-5439\n",
      "Job 16, starting getting image info for images 10880-11559\n",
      "Job 23, starting getting image info for images 15640-16319\n",
      "Job 13, starting getting image info for images 8840-9519\n",
      "Job 10, starting getting image info for images 6800-7479\n",
      "Job 6, starting getting image info for images 4080-4759\n",
      "Job 14, starting getting image info for images 9520-10199\n",
      "Job 11, starting getting image info for images 7480-8159\n",
      "Job 0, starting getting image info for images 0-679\n",
      "Job 33, starting getting image info for images 22440-23119\n",
      "Job 15, starting getting image info for images 10200-10879\n",
      "Job 1, starting getting image info for images 680-1359\n",
      "Job 31, starting getting image info for images 21080-21759\n",
      "Job 19, starting getting image info for images 12920-13599\n",
      "Job 28, starting getting image info for images 19040-19719\n",
      "Job 27, starting getting image info for images 18360-19039\n",
      "Job 30, starting getting image info for images 20400-21079\n",
      "Job 9, starting getting image info for images 6120-6799\n",
      "Job 29, starting getting image info for images 19720-20399\n",
      "Job 34, starting getting image info for images 23120-23816\n",
      "Job 21, starting getting image info for images 14280-14959\n",
      "Job 8, starting getting image info for images 5440-6119\n",
      "Job 32, starting getting image info for images 21760-22439\n",
      "Job 22, starting getting image info for images 14960-15639\n",
      "Job 26, starting getting image info for images 17680-18359\n",
      "Job 4, starting getting image info for images 2720-3399\n",
      "Job 25, starting getting image info for images 17000-17679\n",
      "Job 20, starting getting image info for images 13600-14279\n",
      "Job 5, starting getting image info for images 3400-4079\n",
      "Job 17, starting getting image info for images 11560-12239\n",
      "Job 2, starting getting image info for images 1360-2039\n",
      "job 29 - error in /data/test_data/test/72610.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-33-badd30fc032f>\", line 69, in getFeaturesWorker\n",
      "    info.loc[i, 'pixelsx'] = im.shape[1]\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32071.jpg is rgba\n",
      "Job 11, finished 100 of 680, total time = 1.59 min\n",
      "Job 22, finished 100 of 680, total time = 1.68 min\n",
      "Job 32, finished 100 of 680, total time = 1.70 min\n",
      "Job 34, finished 100 of 697, total time = 1.80 min\n",
      "Job 29, finished 100 of 680, total time = 1.82 min\n",
      "Job 20, finished 100 of 680, total time = 1.82 min\n",
      "Job 6, finished 100 of 680, total time = 1.83 min\n",
      "Job 8, finished 100 of 680, total time = 1.90 min\n",
      "Job 31, finished 100 of 680, total time = 1.97 min\n",
      "Job 23, finished 100 of 680, total time = 1.99 min\n",
      "Job 13, finished 100 of 680, total time = 2.00 min\n",
      "Job 12, finished 100 of 680, total time = 2.02 min\n",
      "Job 3, finished 100 of 680, total time = 2.04 min\n",
      "Job 4, finished 100 of 680, total time = 2.05 min\n",
      "Job 14, finished 100 of 680, total time = 2.09 min\n",
      "Job 26, finished 100 of 680, total time = 2.11 min\n",
      "Job 30, finished 100 of 680, total time = 2.14 min\n",
      "Job 27, finished 100 of 680, total time = 2.17 min\n",
      "Job 9, finished 100 of 680, total time = 2.18 min\n",
      "Job 1, finished 100 of 680, total time = 2.20 min\n",
      "Job 15, finished 100 of 680, total time = 2.21 min\n",
      "Job 28, finished 100 of 680, total time = 2.32 min\n",
      "Job 2, finished 100 of 680, total time = 2.31 min\n",
      "job 5 - error in /data/test_data/test/18649.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/Image.py\", line 1151, in getdata\n",
      "    self.load()\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/ImageFile.py\", line 218, in load\n",
      "    \"(%d bytes not processed)\" % len(b))\n",
      "OSError: image file is truncated (79 bytes not processed)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-33-badd30fc032f>\", line 67, in getFeaturesWorker\n",
      "    im = skimage.data.imread(mydir + '/' + info.loc[i, 'filename'])\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 61, in pil_to_ndarray\n",
      "    raise ValueError(error_message)\n",
      "ValueError: Could not load \"\" \n",
      "Reason: \"image file is truncated (79 bytes not processed)\"\n",
      "Please see documentation at: http://pillow.readthedocs.org/en/latest/installation.html#external-libraries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 33, finished 100 of 680, total time = 2.34 min\n",
      "Job 21, finished 100 of 680, total time = 2.37 min\n",
      "Job 7, finished 100 of 680, total time = 2.41 min\n",
      "Job 24, finished 100 of 680, total time = 2.43 min\n",
      "Job 17, finished 100 of 680, total time = 2.47 min\n",
      "Job 19, finished 100 of 680, total time = 2.50 min\n",
      "91447.jpg is rgba\n",
      "Job 10, finished 100 of 680, total time = 2.77 min\n",
      "Job 25, finished 100 of 680, total time = 2.91 min\n",
      "Job 5, finished 100 of 680, total time = 3.08 min\n",
      "Job 18, finished 100 of 680, total time = 3.10 min\n",
      "Job 11, finished 200 of 680, total time = 3.17 min\n",
      "Job 22, finished 200 of 680, total time = 3.42 min\n",
      "Job 3, finished 200 of 680, total time = 3.67 min\n",
      "Job 14, finished 200 of 680, total time = 3.73 min\n",
      "Job 16, finished 100 of 680, total time = 3.75 min\n",
      "Job 6, finished 200 of 680, total time = 3.82 min\n",
      "Job 31, finished 200 of 680, total time = 3.84 min\n",
      "Job 12, finished 200 of 680, total time = 3.89 min\n",
      "Job 0, finished 100 of 680, total time = 3.89 min\n",
      "Job 32, finished 200 of 680, total time = 3.92 min\n",
      "Job 1, finished 200 of 680, total time = 3.90 min\n",
      "Job 27, finished 200 of 680, total time = 3.93 min\n",
      "Job 29, finished 200 of 680, total time = 3.96 min\n",
      "Job 8, finished 200 of 680, total time = 4.08 min\n",
      "Job 13, finished 200 of 680, total time = 4.12 min\n",
      "Job 23, finished 200 of 680, total time = 4.12 min\n",
      "Job 10, finished 200 of 680, total time = 4.18 min\n",
      "Job 34, finished 200 of 697, total time = 4.19 min\n",
      "Job 2, finished 200 of 680, total time = 4.19 min\n",
      "Job 30, finished 200 of 680, total time = 4.27 min\n",
      "Job 4, finished 200 of 680, total time = 4.30 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (133026477 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 20, finished 200 of 680, total time = 4.52 min\n",
      "Job 9, finished 200 of 680, total time = 4.55 min\n",
      "Job 15, finished 200 of 680, total time = 4.66 min\n",
      "Job 19, finished 200 of 680, total time = 4.70 min\n",
      "Job 28, finished 200 of 680, total time = 4.77 min\n",
      "Job 33, finished 200 of 680, total time = 4.78 min\n",
      "Job 17, finished 200 of 680, total time = 4.79 min\n",
      "Job 5, finished 200 of 680, total time = 4.84 min\n",
      "Job 26, finished 200 of 680, total time = 4.86 min\n",
      "Job 18, finished 200 of 680, total time = 4.88 min\n",
      "Job 7, finished 200 of 680, total time = 4.98 min\n",
      "Job 22, finished 300 of 680, total time = 5.13 min\n",
      "Job 21, finished 200 of 680, total time = 5.14 min\n",
      "Job 12, finished 300 of 680, total time = 5.29 min\n",
      "Job 11, finished 300 of 680, total time = 5.38 min\n",
      "Job 1, finished 300 of 680, total time = 5.46 min\n",
      "Job 14, finished 300 of 680, total time = 5.52 min\n",
      "25416.jpg is rgba\n",
      "Job 23, finished 300 of 680, total time = 5.62 min\n",
      "89073.jpg is rgba\n",
      "Job 8, finished 300 of 680, total time = 5.79 min\n",
      "75551.jpg is rgba\n",
      "69828.jpg is rgba\n",
      "Job 2, finished 300 of 680, total time = 5.91 min\n",
      "Job 27, finished 300 of 680, total time = 5.94 min\n",
      "Job 32, finished 300 of 680, total time = 6.00 min\n",
      "Job 31, finished 300 of 680, total time = 6.08 min\n",
      "Job 3, finished 300 of 680, total time = 6.12 min\n",
      "Job 30, finished 300 of 680, total time = 6.14 min\n",
      "Job 16, finished 200 of 680, total time = 6.20 min\n",
      "Job 4, finished 300 of 680, total time = 6.23 min\n",
      "Job 29, finished 300 of 680, total time = 6.27 min\n",
      "Job 24, finished 200 of 680, total time = 6.33 min\n",
      "Job 13, finished 300 of 680, total time = 6.38 min\n",
      "Job 9, finished 300 of 680, total time = 6.38 min\n",
      "Job 6, finished 300 of 680, total time = 6.39 min\n",
      "Job 5, finished 300 of 680, total time = 6.41 min\n",
      "Job 26, finished 300 of 680, total time = 6.56 min\n",
      "Job 20, finished 300 of 680, total time = 6.68 min\n",
      "Job 15, finished 300 of 680, total time = 6.72 min\n",
      "Job 33, finished 300 of 680, total time = 6.73 min\n",
      "17888.jpg is rgba\n",
      "Job 19, finished 300 of 680, total time = 6.80 min\n",
      "35962.jpg is rgba\n",
      "Job 25, finished 200 of 680, total time = 6.93 min\n",
      "Job 28, finished 300 of 680, total time = 7.00 min\n",
      "Job 10, finished 300 of 680, total time = 7.14 min\n",
      "Job 21, finished 300 of 680, total time = 7.19 min\n",
      "Job 34, finished 300 of 697, total time = 7.24 min\n",
      "Job 1, finished 400 of 680, total time = 7.23 min\n",
      "Job 7, finished 300 of 680, total time = 7.28 min\n",
      "Job 14, finished 400 of 680, total time = 7.30 min\n",
      "Job 18, finished 300 of 680, total time = 7.36 min\n",
      "Job 12, finished 400 of 680, total time = 7.41 min\n",
      "Job 0, finished 200 of 680, total time = 7.62 min\n",
      "Job 31, finished 400 of 680, total time = 7.67 min\n",
      "Job 22, finished 400 of 680, total time = 7.67 min\n",
      "Job 11, finished 400 of 680, total time = 7.69 min\n",
      "Job 32, finished 400 of 680, total time = 7.73 min\n",
      "Job 23, finished 400 of 680, total time = 7.92 min\n",
      "Job 2, finished 400 of 680, total time = 8.12 min\n",
      "Job 27, finished 400 of 680, total time = 8.14 min\n",
      "Job 5, finished 400 of 680, total time = 8.22 min\n",
      "Job 30, finished 400 of 680, total time = 8.29 min\n",
      "16469.jpg is rgba\n",
      "Job 15, finished 400 of 680, total time = 8.40 min\n",
      "Job 26, finished 400 of 680, total time = 8.42 min\n",
      "Job 33, finished 400 of 680, total time = 8.44 min\n",
      "Job 24, finished 300 of 680, total time = 8.46 min\n",
      "Job 9, finished 400 of 680, total time = 8.58 min\n",
      "Job 6, finished 400 of 680, total time = 8.62 min\n",
      "Job 17, finished 300 of 680, total time = 8.63 min\n",
      "Job 4, finished 400 of 680, total time = 8.68 min\n",
      "Job 16, finished 300 of 680, total time = 8.84 min\n",
      "Job 3, finished 400 of 680, total time = 8.83 min\n",
      "64004.jpg is rgba\n",
      "Job 20, finished 400 of 680, total time = 8.93 min\n",
      "Job 14, finished 500 of 680, total time = 8.95 min\n",
      "Job 13, finished 400 of 680, total time = 9.00 min\n",
      "Job 19, finished 400 of 680, total time = 9.07 min\n",
      "Job 8, finished 400 of 680, total time = 9.16 min\n",
      "Job 10, finished 400 of 680, total time = 9.20 min\n",
      "Job 18, finished 400 of 680, total time = 9.28 min\n",
      "Job 7, finished 400 of 680, total time = 9.32 min\n",
      "Job 12, finished 500 of 680, total time = 9.32 min\n",
      "Job 28, finished 400 of 680, total time = 9.36 min\n",
      "Job 27, finished 500 of 680, total time = 9.37 min\n",
      "Job 11, finished 500 of 680, total time = 9.37 min\n",
      "Job 29, finished 400 of 680, total time = 9.38 min\n",
      "Job 34, finished 400 of 697, total time = 9.51 min\n",
      "Job 21, finished 400 of 680, total time = 9.53 min\n",
      "Job 22, finished 500 of 680, total time = 9.54 min\n",
      "Job 31, finished 500 of 680, total time = 9.71 min\n",
      "Job 25, finished 300 of 680, total time = 9.86 min\n",
      "Job 1, finished 500 of 680, total time = 9.88 min\n",
      "Job 32, finished 500 of 680, total time = 10.06 min\n",
      "Job 23, finished 500 of 680, total time = 10.33 min\n",
      "Job 24, finished 400 of 680, total time = 10.38 min\n",
      "Job 15, finished 500 of 680, total time = 10.39 min\n",
      "Job 33, finished 500 of 680, total time = 10.54 min\n",
      "Job 9, finished 500 of 680, total time = 10.66 min\n",
      "Job 0, finished 300 of 680, total time = 10.68 min\n",
      "Job 6, finished 500 of 680, total time = 10.71 min\n",
      "Job 5, finished 500 of 680, total time = 10.78 min\n",
      "Job 27, finished 600 of 680, total time = 10.80 min\n",
      "Job 14, finished 600 of 680, total time = 10.80 min\n",
      "Job 17, finished 400 of 680, total time = 10.83 min\n",
      "Job 8, finished 500 of 680, total time = 10.92 min\n",
      "Job 30, finished 500 of 680, total time = 10.96 min\n",
      "Job 10, finished 500 of 680, total time = 11.00 min\n",
      "Job 16, finished 400 of 680, total time = 11.20 min\n",
      "Job 13, finished 500 of 680, total time = 11.22 min\n",
      "Job 4, finished 500 of 680, total time = 11.25 min\n",
      "Job 11, finished 600 of 680, total time = 11.28 min\n",
      "Job 2, finished 500 of 680, total time = 11.28 min\n",
      "39101.jpg is rgba\n",
      "Job 22, finished 600 of 680, total time = 11.32 min\n",
      "Job 26, finished 500 of 680, total time = 11.35 min\n",
      "Job 29, finished 500 of 680, total time = 11.43 min\n",
      "Job 20, finished 500 of 680, total time = 11.46 min\n",
      "Job 3, finished 500 of 680, total time = 11.53 min\n",
      "Job 7, finished 500 of 680, total time = 11.60 min\n",
      "Job 19, finished 500 of 680, total time = 11.62 min\n",
      "Job 18, finished 500 of 680, total time = 11.72 min\n",
      "Job 25, finished 400 of 680, total time = 11.82 min\n",
      "Job 31, finished 600 of 680, total time = 11.82 min\n",
      "job 7 - error in /data/test_data/test/20153.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/Image.py\", line 1151, in getdata\n",
      "    self.load()\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/ImageFile.py\", line 218, in load\n",
      "    \"(%d bytes not processed)\" % len(b))\n",
      "OSError: image file is truncated (0 bytes not processed)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-33-badd30fc032f>\", line 67, in getFeaturesWorker\n",
      "    im = skimage.data.imread(mydir + '/' + info.loc[i, 'filename'])\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 61, in pil_to_ndarray\n",
      "    raise ValueError(error_message)\n",
      "ValueError: Could not load \"\" \n",
      "Reason: \"image file is truncated (0 bytes not processed)\"\n",
      "Please see documentation at: http://pillow.readthedocs.org/en/latest/installation.html#external-libraries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 21, finished 500 of 680, total time = 11.96 min\n",
      "Job 12, finished 600 of 680, total time = 11.97 min\n",
      "- Job 14, finished getting image info, total time = 12.09 min\n",
      "Job 34, finished 500 of 697, total time = 12.12 min\n",
      "Job 32, finished 600 of 680, total time = 12.13 min\n",
      "Job 33, finished 600 of 680, total time = 12.18 min\n",
      "- Job 27, finished getting image info, total time = 12.18 min\n",
      "Job 28, finished 500 of 680, total time = 12.27 min\n",
      "Job 24, finished 500 of 680, total time = 12.30 min\n",
      "Job 1, finished 600 of 680, total time = 12.36 min\n",
      "Job 6, finished 600 of 680, total time = 12.43 min\n",
      "Job 10, finished 600 of 680, total time = 12.50 min\n",
      "Job 5, finished 600 of 680, total time = 12.54 min\n",
      "- Job 22, finished getting image info, total time = 12.61 min\n",
      "Job 8, finished 600 of 680, total time = 12.63 min\n",
      "93262.jpg is rgba\n",
      "Job 30, finished 600 of 680, total time = 12.94 min\n",
      "Job 4, finished 600 of 680, total time = 12.92 min\n",
      "- Job 11, finished getting image info, total time = 12.93 min\n",
      "Job 0, finished 400 of 680, total time = 12.94 min\n",
      "Job 23, finished 600 of 680, total time = 13.03 min\n",
      "Job 26, finished 600 of 680, total time = 13.07 min\n",
      "Job 15, finished 600 of 680, total time = 13.10 min\n",
      "Job 9, finished 600 of 680, total time = 13.11 min\n",
      "Job 16, finished 500 of 680, total time = 13.12 min\n",
      "Job 2, finished 600 of 680, total time = 13.12 min\n",
      "- Job 31, finished getting image info, total time = 13.18 min\n",
      "Job 17, finished 500 of 680, total time = 13.18 min\n",
      "Job 29, finished 600 of 680, total time = 13.33 min\n",
      "Job 7, finished 600 of 680, total time = 13.33 min\n",
      "Job 21, finished 600 of 680, total time = 13.47 min\n",
      "- Job 12, finished getting image info, total time = 13.48 min\n",
      "job 17 - error in /data/test_data/test/100532.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/Image.py\", line 1151, in getdata\n",
      "    self.load()\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/ImageFile.py\", line 218, in load\n",
      "    \"(%d bytes not processed)\" % len(b))\n",
      "OSError: image file is truncated (57 bytes not processed)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-33-badd30fc032f>\", line 67, in getFeaturesWorker\n",
      "    im = skimage.data.imread(mydir + '/' + info.loc[i, 'filename'])\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 61, in pil_to_ndarray\n",
      "    raise ValueError(error_message)\n",
      "ValueError: Could not load \"\" \n",
      "Reason: \"image file is truncated (57 bytes not processed)\"\n",
      "Please see documentation at: http://pillow.readthedocs.org/en/latest/installation.html#external-libraries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 13, finished 600 of 680, total time = 13.55 min\n",
      "Job 18, finished 600 of 680, total time = 13.59 min\n",
      "Job 20, finished 600 of 680, total time = 13.58 min\n",
      "Job 24, finished 600 of 680, total time = 13.74 min\n",
      "Job 25, finished 500 of 680, total time = 13.77 min\n",
      "- Job 33, finished getting image info, total time = 13.82 min\n",
      "69423.jpg is rgba\n",
      "- Job 4, finished getting image info, total time = 13.85 min\n",
      "- Job 1, finished getting image info, total time = 13.85 min\n",
      "Job 28, finished 600 of 680, total time = 13.94 min\n",
      "30623.jpg is rgba\n",
      "- Job 5, finished getting image info, total time = 14.00 min\n",
      "- Job 8, finished getting image info, total time = 14.01 min\n",
      "- Job 6, finished getting image info, total time = 14.04 min\n",
      "Job 19, finished 600 of 680, total time = 14.11 min\n",
      "- Job 30, finished getting image info, total time = 14.14 min\n",
      "- Job 15, finished getting image info, total time = 14.20 min\n",
      "- Job 9, finished getting image info, total time = 14.20 min\n",
      "- Job 32, finished getting image info, total time = 14.28 min\n",
      "- Job 23, finished getting image info, total time = 14.33 min\n",
      "Job 17, finished 600 of 680, total time = 14.35 min\n",
      "- Job 2, finished getting image info, total time = 14.37 min\n",
      "Job 34, finished 600 of 697, total time = 14.40 min\n",
      "Job 0, finished 500 of 680, total time = 14.39 min\n",
      "- Job 26, finished getting image info, total time = 14.51 min\n",
      "- Job 10, finished getting image info, total time = 14.51 min\n",
      "- Job 29, finished getting image info, total time = 14.53 min\n",
      "- Job 18, finished getting image info, total time = 14.55 min\n",
      "- Job 21, finished getting image info, total time = 14.71 min\n",
      "Job 25, finished 600 of 680, total time = 14.77 min\n",
      "Job 16, finished 600 of 680, total time = 14.84 min\n",
      "- Job 19, finished getting image info, total time = 14.86 min\n",
      "- Job 13, finished getting image info, total time = 14.88 min\n",
      "- Job 7, finished getting image info, total time = 14.97 min\n",
      "- Job 20, finished getting image info, total time = 15.03 min\n",
      "- Job 24, finished getting image info, total time = 15.05 min\n",
      "- Job 28, finished getting image info, total time = 15.06 min\n",
      "- Job 17, finished getting image info, total time = 15.11 min\n",
      "Job 3, finished 600 of 680, total time = 15.11 min\n",
      "- Job 34, finished getting image info, total time = 15.19 min\n",
      "- Job 16, finished getting image info, total time = 15.29 min\n",
      "- Job 25, finished getting image info, total time = 15.35 min\n",
      "- Job 3, finished getting image info, total time = 15.96 min\n",
      "Job 0, finished 600 of 680, total time = 16.20 min\n",
      "- Job 0, finished getting image info, total time = 16.83 min\n",
      "collecting features complete, time taken = 16.90 minutes\n",
      "Finished computing features, time taken = 16.90 min\n"
     ]
    }
   ],
   "source": [
    "print('Begin computing features')\n",
    "startTime = time.time()\n",
    "\n",
    "test_features = getFeaturesParent(True)\n",
    "\n",
    "endTime = time.time()\n",
    "print(\"Finished computing features, time taken = %.2f min\" % ((endTime-startTime)/60.0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_features.to_csv(r'/data/test_data/test_features.csv')\n",
    "#test_features_sorted.to_csv(r'/data/test_data/test_features.csv')\n",
    "#y = pd.read_csv(r'/data/test_data/test_features.csv', index_col=0)\n",
    "#test_features_sorted = test_features_sorted.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_features.to_csv(r'/data/training_data/train_features_40000_end.csv')\n",
    "#test_features_sorted.to_csv(r'/data/test_data/test_features.csv')\n",
    "#y = pd.read_csv(r'/data/test_data/test_features.csv', index_col=0)\n",
    "#test_features_sorted = test_features_sorted.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load features\n",
    "train_features_0 = pd.read_csv(r'/data/training_data/train_features_0_20000.csv', index_col = 0)\n",
    "train_features_1 = pd.read_csv(r'/data/training_data/train_features_20000_40000.csv', index_col = 0)\n",
    "train_features_2 = pd.read_csv(r'/data/training_data/train_features_40000_end.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = pd.concat([train_features_0, train_features_1, train_features_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = pd.read_csv(r'/data/test_data/test_features.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'pixelsx', 'pixelsy', 'size_bytes', 'r_mean', 'r_med',\n",
       "       'r_std', 'g_mean', 'g_med', 'g_std', 'b_mean', 'b_med', 'b_std',\n",
       "       'h_mean', 'h_var', 's_mean', 's_std', 's_med', 'v_mean', 'v_std',\n",
       "       'v_med'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = test_features.columns.copy()\n",
    "\n",
    "cols.drop('is_grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features[cols].fillna(test_featurse[cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional processing on feature - remove extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saved features are straight from the feature functions with no handling of nulls, etc\n",
    "# these have to be addressed prior to training/predicting\n",
    "\n",
    "#rgb_features = ['r_mean', 'r_med', 'r_std', 'g_mean', 'g_med',\n",
    "#                'g_std', 'b_mean', 'b_med', 'b_std',]\n",
    "\n",
    "#size_features =  [ 'pixelsx',\n",
    "#       'pixelsy', 'size_bytes' ]\n",
    "\n",
    "\n",
    "# take out unnecessary columns\n",
    "def removeColumns(features):\n",
    "    feature_names = ['pixelsx', 'pixelsy', 'size_bytes',\n",
    "                     'r_mean', 'r_med', 'r_std',\n",
    "                     'g_mean', 'g_med', 'g_std',\n",
    "                     'b_mean', 'b_med', 'b_std',\n",
    "                     'h_mean', 'h_var',\n",
    "                     's_mean', 's_med', 's_std',\n",
    "                     'v_mean', 'v_med', 'v_std',\n",
    "                     'is_grayscale']\n",
    "\n",
    "    features = features[ ['filename'] + feature_names ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "removeColumns(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'artist', 'title', 'style', 'genre', 'date', 'pixelsx',\n",
       "       'pixelsy', 'size_bytes', 'r_mean', 'r_med', 'r_std', 'g_mean', 'g_med',\n",
       "       'g_std', 'b_mean', 'b_med', 'b_std', 'h_mean', 'h_var', 's_mean',\n",
       "       's_std', 's_med', 'v_mean', 'v_std', 'v_med', 'is_grayscale',\n",
       "       'aspect_ratio', 'size_per_pixel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature processing - add image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def addImageFeatures(features):\n",
    "    \"\"\"modifies in place\"\"\"\n",
    "    features['aspect_ratio'] = features['pixelsx']/features['pixelsy']\n",
    "    features['size_per_pixel'] = features['size_bytes']/features['pixelsx']/features['pixelsy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addImageFeatures(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addImageFeatures(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'artist', 'title', 'style', 'genre', 'date', 'pixelsx',\n",
       "       'pixelsy', 'size_bytes', 'r_mean', 'r_med', 'r_std', 'g_mean', 'g_med',\n",
       "       'g_std', 'b_mean', 'b_med', 'b_std', 'h_mean', 'h_var', 's_mean',\n",
       "       's_std', 's_med', 'v_mean', 'v_std', 'v_med', 'is_grayscale',\n",
       "       'aspect_ratio', 'size_per_pixel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join features to pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#join pair data to image features\n",
    "\n",
    "def joinPairsToFeatures(pairs, features):\n",
    "    \n",
    "    feature_base_names = ['pixelsx', 'pixelsy', 'size_bytes', 'aspect_ratio', 'size_per_pixel',\n",
    "                     'r_mean', 'r_med', 'r_std',\n",
    "                     'g_mean', 'g_med', 'g_std',\n",
    "                     'b_mean', 'b_med', 'b_std',\n",
    "                     'h_mean', 'h_var',\n",
    "                     's_mean', 's_med', 's_std',\n",
    "                     'v_mean', 'v_med', 'v_std', \n",
    "                     'is_grayscale' ]\n",
    "\n",
    "    col_dict_1 = {}\n",
    "    col_dict_2 = {}\n",
    "\n",
    "    for feature in feature_base_names:\n",
    "        col_dict_1[feature] = '%s_1' % feature\n",
    "        col_dict_2[feature] = '%s_2' % feature\n",
    "\n",
    "    pairs = pairs.merge(features,\n",
    "                        left_on='image1', right_on='filename')\n",
    "    pairs.rename( columns = col_dict_1,\n",
    "                          inplace=True)\n",
    "    pairs = pairs.merge(features,\n",
    "                        left_on='image2', right_on='filename')\n",
    "    pairs.rename( columns = col_dict_2,\n",
    "                          inplace=True)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pairs = joinPairsToFeatures(train_pairs, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist1', 'image1', 'artist2', 'image2', 'sameArtist', 'filename_x',\n",
       "       'artist_x', 'title_x', 'style_x', 'genre_x', 'date_x', 'pixelsx_1',\n",
       "       'pixelsy_1', 'size_bytes_1', 'r_mean_1', 'r_med_1', 'r_std_1',\n",
       "       'g_mean_1', 'g_med_1', 'g_std_1', 'b_mean_1', 'b_med_1', 'b_std_1',\n",
       "       'h_mean_1', 'h_var_1', 's_mean_1', 's_std_1', 's_med_1', 'v_mean_1',\n",
       "       'v_std_1', 'v_med_1', 'is_grayscale_1', 'aspect_ratio_1',\n",
       "       'size_per_pixel_1', 'filename_y', 'artist_y', 'title_y', 'style_y',\n",
       "       'genre_y', 'date_y', 'pixelsx_2', 'pixelsy_2', 'size_bytes_2',\n",
       "       'r_mean_2', 'r_med_2', 'r_std_2', 'g_mean_2', 'g_med_2', 'g_std_2',\n",
       "       'b_mean_2', 'b_med_2', 'b_std_2', 'h_mean_2', 'h_var_2', 's_mean_2',\n",
       "       's_std_2', 's_med_2', 'v_mean_2', 'v_std_2', 'v_med_2',\n",
       "       'is_grayscale_2', 'aspect_ratio_2', 'size_per_pixel_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pairs = joinPairsToFeatures(test_pairs, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pairs = test_pairs.sort_values(by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pairs.set_index('index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image1', 'image2', 'filename_x', 'pixelsx_1', 'pixelsy_1',\n",
       "       'size_bytes_1', 'r_mean_1', 'r_med_1', 'r_std_1', 'g_mean_1', 'g_med_1',\n",
       "       'g_std_1', 'b_mean_1', 'b_med_1', 'b_std_1', 'h_mean_1', 'h_var_1',\n",
       "       's_mean_1', 's_std_1', 's_med_1', 'v_mean_1', 'v_std_1', 'v_med_1',\n",
       "       'is_grayscale_1', 'aspect_ratio_1', 'size_per_pixel_1', 'filename_y',\n",
       "       'pixelsx_2', 'pixelsy_2', 'size_bytes_2', 'r_mean_2', 'r_med_2',\n",
       "       'r_std_2', 'g_mean_2', 'g_med_2', 'g_std_2', 'b_mean_2', 'b_med_2',\n",
       "       'b_std_2', 'h_mean_2', 'h_var_2', 's_mean_2', 's_std_2', 's_med_2',\n",
       "       'v_mean_2', 'v_std_2', 'v_med_2', 'is_grayscale_2', 'aspect_ratio_2',\n",
       "       'size_per_pixel_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'image1', 'image2', 'filename_x', 'pixelsx_1', 'pixelsy_1',\n",
       "       'size_bytes_1', 'r_mean_1', 'r_med_1', 'r_std_1', 'g_mean_1', 'g_med_1',\n",
       "       'g_std_1', 'b_mean_1', 'b_med_1', 'b_std_1', 'h_mean_1', 'h_var_1',\n",
       "       's_mean_1', 's_std_1', 's_med_1', 'v_mean_1', 'v_std_1', 'v_med_1',\n",
       "       'is_grayscale_1', 'aspect_ratio_1', 'size_per_pixel_1', 'filename_y',\n",
       "       'pixelsx_2', 'pixelsy_2', 'size_bytes_2', 'r_mean_2', 'r_med_2',\n",
       "       'r_std_2', 'g_mean_2', 'g_med_2', 'g_std_2', 'b_mean_2', 'b_med_2',\n",
       "       'b_std_2', 'h_mean_2', 'h_var_2', 's_mean_2', 's_std_2', 's_med_2',\n",
       "       'v_mean_2', 'v_std_2', 'v_med_2', 'is_grayscale_2', 'aspect_ratio_2',\n",
       "       'size_per_pixel_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove nulls in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist1                  0\n",
      "image1                   0\n",
      "artist2                  0\n",
      "image2                   0\n",
      "sameArtist               0\n",
      "filename_x               0\n",
      "artist_x                 0\n",
      "title_x                 38\n",
      "style_x              11237\n",
      "genre_x              10732\n",
      "date_x              487163\n",
      "pixelsx_1                0\n",
      "pixelsy_1                0\n",
      "size_bytes_1             0\n",
      "r_mean_1                 0\n",
      "r_med_1                  0\n",
      "r_std_1                  0\n",
      "g_mean_1                 0\n",
      "g_med_1                  0\n",
      "g_std_1                  0\n",
      "b_mean_1                 0\n",
      "b_med_1                  0\n",
      "b_std_1                  0\n",
      "h_mean_1                 0\n",
      "h_var_1                  0\n",
      "s_mean_1                 0\n",
      "s_std_1                  0\n",
      "s_med_1                  0\n",
      "v_mean_1                 0\n",
      "v_std_1                  0\n",
      "                     ...  \n",
      "size_per_pixel_1         0\n",
      "filename_y               0\n",
      "artist_y                 0\n",
      "title_y                220\n",
      "style_y              15034\n",
      "genre_y              17095\n",
      "date_y              497309\n",
      "pixelsx_2                0\n",
      "pixelsy_2                0\n",
      "size_bytes_2             0\n",
      "r_mean_2                 0\n",
      "r_med_2                  0\n",
      "r_std_2                  0\n",
      "g_mean_2                 0\n",
      "g_med_2                  0\n",
      "g_std_2                  0\n",
      "b_mean_2                 0\n",
      "b_med_2                  0\n",
      "b_std_2                  0\n",
      "h_mean_2                 0\n",
      "h_var_2                  0\n",
      "s_mean_2                 0\n",
      "s_std_2                  0\n",
      "s_med_2                  0\n",
      "v_mean_2                 0\n",
      "v_std_2                  0\n",
      "v_med_2                  0\n",
      "is_grayscale_2           0\n",
      "aspect_ratio_2           0\n",
      "size_per_pixel_2         0\n",
      "dtype: int64\n",
      "1038828\n"
     ]
    }
   ],
   "source": [
    "# we remove the nulls after the join, could also be done before\n",
    "train_pairs = train_pairs[~train_pairs['pixelsx_1'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['pixelsx_2'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['size_bytes_1'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['size_bytes_2'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['h_mean_1'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['h_mean_2'].isnull()]\n",
    "\n",
    "print(train_pairs.isnull().sum())\n",
    "print(train_pairs.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check no nulls in submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image1              0\n",
      "image2              0\n",
      "filename_x          0\n",
      "pixelsx_1           0\n",
      "pixelsy_1           0\n",
      "size_bytes_1        0\n",
      "r_mean_1            0\n",
      "r_med_1             0\n",
      "r_std_1             0\n",
      "g_mean_1            0\n",
      "g_med_1             0\n",
      "g_std_1             0\n",
      "b_mean_1            0\n",
      "b_med_1             0\n",
      "b_std_1             0\n",
      "h_mean_1            0\n",
      "h_var_1             0\n",
      "s_mean_1            0\n",
      "s_std_1             0\n",
      "s_med_1             0\n",
      "v_mean_1            0\n",
      "v_std_1             0\n",
      "v_med_1             0\n",
      "is_grayscale_1      0\n",
      "aspect_ratio_1      0\n",
      "size_per_pixel_1    0\n",
      "filename_y          0\n",
      "pixelsx_2           0\n",
      "pixelsy_2           0\n",
      "size_bytes_2        0\n",
      "r_mean_2            0\n",
      "r_med_2             0\n",
      "r_std_2             0\n",
      "g_mean_2            0\n",
      "g_med_2             0\n",
      "g_std_2             0\n",
      "b_mean_2            0\n",
      "b_med_2             0\n",
      "b_std_2             0\n",
      "h_mean_2            0\n",
      "h_var_2             0\n",
      "s_mean_2            0\n",
      "s_std_2             0\n",
      "s_med_2             0\n",
      "v_mean_2            0\n",
      "v_std_2             0\n",
      "v_med_2             0\n",
      "is_grayscale_2      0\n",
      "aspect_ratio_2      0\n",
      "size_per_pixel_2    0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(test_pairs.isnull().sum())\n",
    "print(test_pairs.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature processing - add diff features to pairs matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## try training on diffs instead of aboslute values\n",
    "\n",
    "def addPairFeatures(pairs):\n",
    "    diff_feature_base = [ \n",
    "                     'r_mean', 'r_med', 'r_std',\n",
    "                     'g_mean', 'g_med', 'g_std',\n",
    "                     'b_mean', 'b_med', 'b_std',\n",
    "                     'h_mean', 'h_var',\n",
    "                     's_mean', 's_med', 's_std',\n",
    "                     'v_mean', 'v_med', 'v_std', ]\n",
    "\n",
    "    diff_feature_names = [ temp_feature + '_diff' for temp_feature in diff_feature_base]\n",
    "\n",
    "    for diff_feature in diff_feature_base:\n",
    "        pairs[diff_feature + '_diff'] = ( pairs[ diff_feature + '_1'] - pairs[ diff_feature + '_2'] ).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addPairFeatures(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addPairFeatures(train_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computePredictStats(y_prob, y_true, threshold = 0.5):\n",
    "    \"\"\" compute accuracy, precision, recall, negative precision, specificity, and auc roc\n",
    "        Args:\n",
    "            y_prob: array of floats from 0.0 - 1.0\n",
    "            y_true: array of booleans\n",
    "            threshold: true/false threshold value, between 0.0-1.0\n",
    "        Returns:\n",
    "            dict of classification metrics\n",
    "    \"\"\"\n",
    "    # y_pred = np.array([True, True, False, False])\n",
    "    # y_true = np.array([True, True, True, True])\n",
    "    y_pred = y_prob > threshold\n",
    "    \n",
    "    total = len(y_prob)\n",
    "    true_pos = sum( (y_pred == True) & (y_true == True) )\n",
    "    true_neg = sum( (y_pred == False) & (y_true == False) )\n",
    "    false_pos = sum( (y_pred == True) & (y_true == False) )\n",
    "    false_neg = sum( (y_pred == False ) & (y_true == True) )\n",
    "    \n",
    "    accuracy = (true_pos + true_neg) / total\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    npp = true_neg / (true_neg + false_neg) #negative prediction value\n",
    "    specificity = true_neg / (true_neg + false_pos)\n",
    "    roc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    return { 'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'npp': npp,\n",
    "            'specificity': specificity,\n",
    "            'roc': roc,\n",
    "            'true_pos': true_pos,\n",
    "            'true_neg': true_neg,\n",
    "            'false_pos': false_pos,\n",
    "            'false_neg': false_neg,\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist1', 'image1', 'artist2', 'image2', 'sameArtist', 'filename_x',\n",
       "       'artist_x', 'title_x', 'style_x', 'genre_x', 'date_x', 'pixelsx_1',\n",
       "       'pixelsy_1', 'size_bytes_1', 'r_mean_1', 'r_med_1', 'r_std_1',\n",
       "       'g_mean_1', 'g_med_1', 'g_std_1', 'b_mean_1', 'b_med_1', 'b_std_1',\n",
       "       'h_mean_1', 'h_var_1', 's_mean_1', 's_std_1', 's_med_1', 'v_mean_1',\n",
       "       'v_std_1', 'v_med_1', 'is_grayscale_1', 'aspect_ratio_1',\n",
       "       'size_per_pixel_1', 'filename_y', 'artist_y', 'title_y', 'style_y',\n",
       "       'genre_y', 'date_y', 'pixelsx_2', 'pixelsy_2', 'size_bytes_2',\n",
       "       'r_mean_2', 'r_med_2', 'r_std_2', 'g_mean_2', 'g_med_2', 'g_std_2',\n",
       "       'b_mean_2', 'b_med_2', 'b_std_2', 'h_mean_2', 'h_var_2', 's_mean_2',\n",
       "       's_std_2', 's_med_2', 'v_mean_2', 'v_std_2', 'v_med_2',\n",
       "       'is_grayscale_2', 'aspect_ratio_2', 'size_per_pixel_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureHelper(feature_name):\n",
    "    include = ( 'pixel' in feature_name\n",
    "               #or 'aspect_ratio' in feature_name\n",
    "               #or '_diff' in feature_name\n",
    "               or 'size_bytes' in feature_name\n",
    "               or 'size_per_pixel' in feature_name\n",
    "              )\n",
    "    \n",
    "    if include:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get list of X columns, they are ones with '_1' or '_2' in the name\n",
    "allCols = train_pairs.columns\n",
    "isX = list(map(featureHelper, allCols))\n",
    "X_columns = allCols[isX]\n",
    "\n",
    "# split X and Y data\n",
    "train_X = train_pairs[X_columns]\n",
    "train_Y = train_pairs['sameArtist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allCols = test_pairs.columns\n",
    "isX = list(map(featureHelper, allCols))\n",
    "X_columns = allCols[isX]\n",
    "\n",
    "test_X = test_pairs[X_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pixelsx_1', 'pixelsy_1', 'size_bytes_1', 'size_per_pixel_1',\n",
       "       'pixelsx_2', 'pixelsy_2', 'size_bytes_2', 'size_per_pixel_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pixelsx_1', 'pixelsy_1', 'size_bytes_1', 'size_per_pixel_1',\n",
       "       'pixelsx_2', 'pixelsy_2', 'size_bytes_2', 'size_per_pixel_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(test_X).sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kFoldCV(train_X, train_Y, k, numFoldsToTest):\n",
    "    \"\"\" Perform k-fold cross validation. Will modify train_pairs (shuffle rows)\n",
    "        Args:\n",
    "            train_pairs: Dataframe containing training image pairs with features. Should have no nulls.\n",
    "            k: k, at least 2\n",
    "            numFoldsToTest: how many folds to actually test, at most k\n",
    "        Returns:\n",
    "            dataframe with CV results\n",
    "    \"\"\"\n",
    "\n",
    "    numFoldsToTest = min(k, numFoldsToTest)\n",
    "    k = max(2, k)\n",
    "    \n",
    "    # shuffle rows\n",
    "    #train_pairs = train_pairs.iloc[np.random.permutation(len(train_pairs))]\n",
    "\n",
    "    # get list of X columns, they are ones with '_1' or '_2' in the name\n",
    "    #allCols = train_pairs.columns\n",
    "    #isX = list(map(lambda x: ('_1' in x) or ('_2' in x), allCols))\n",
    "    #X_columns = allCols[isX]\n",
    "    \n",
    "    # split X and Y data\n",
    "    #CV_X = train_pairs[X_columns]\n",
    "    #CV_Y = train_pairs['sameArtist']\n",
    "    \n",
    "    # define which indices belong to each fold\n",
    "    foldLocsList = [] #list of Index objects, one for each fold\n",
    "    \n",
    "    foldSize = int(len(train_X)/5)\n",
    "        \n",
    "    for foldNum in range(k):\n",
    "        if foldNum == k-1:\n",
    "            foldLocsList.append( train_X.index[foldNum*foldSize : len(train_X)] )\n",
    "        else:\n",
    "            foldLocsList.append( train_X.index[foldNum*foldSize : (foldNum+1)*(foldSize) ] )\n",
    "    \n",
    "    # set up dataframe for collecting results\n",
    "    columnsList = list(itertools.product(('train', 'test'), ('roc', 'precision', 'recall', 'npp', 'specificity')))\n",
    "    results = pd.DataFrame(index = range(numFoldsToTest), columns = pd.MultiIndex.from_tuples(columnsList))\n",
    "    \n",
    "    # test each fold\n",
    "    for testNum in range(numFoldsToTest):\n",
    "\n",
    "        # indices of training data\n",
    "        trainLocs = pd.Index([])\n",
    "        for foldNum in range(k):\n",
    "            if foldNum != testNum:\n",
    "                trainLocs = trainLocs.append( foldLocsList[foldNum] )\n",
    "        \n",
    "        # indices of test data\n",
    "        testLocs = foldLocsList[testNum]\n",
    "\n",
    "        #print(trainLocs)\n",
    "        # set up Xs\n",
    "        CV_train_X = train_X.loc[trainLocs]\n",
    "        CV_test_X = train_X.loc[testLocs]\n",
    "\n",
    "        # set up Ys\n",
    "        CV_train_Y = train_Y.loc[trainLocs]\n",
    "        CV_test_Y = train_Y.loc[testLocs]\n",
    "        \n",
    "        # fit model\n",
    "        clf = RandomForestClassifier(n_estimators=50, min_samples_split = 15, n_jobs=30)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        print('starting fit.. ', end='')\n",
    "\n",
    "        clf.fit(CV_train_X, CV_train_Y)\n",
    "\n",
    "        end = time.time()\n",
    "                               \n",
    "        print('total training time: %s' % (end - start) )\n",
    "\n",
    "        # get in-sample and out-of-sample results\n",
    "                               \n",
    "        pred_train = clf.predict_proba(CV_train_X)[:,1]\n",
    "        train_results = computePredictStats( pred_train, CV_train_Y)\n",
    "\n",
    "        pred_test = clf.predict_proba(CV_test_X)[:,1]\n",
    "        test_results = computePredictStats( pred_test, CV_test_Y)\n",
    "       \n",
    "        for stat in ('roc', 'precision', 'recall', 'npp', 'specificity'):\n",
    "            results.loc[testNum, ('train', stat)] = train_results[stat]\n",
    "            results.loc[testNum, ('test', stat)] = test_results[stat]\n",
    "        \n",
    "        #print(list(zip(CV_train_X.columns, clf.feature_importances_)))\n",
    "            \n",
    "    return results              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run k-fold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fit.. total training time: 18.400565147399902\n",
      "      train      test\n",
      "        roc       roc\n",
      "0  0.991157  0.865105\n",
      "train  roc    0.991157\n",
      "test   roc    0.865105\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "numFoldsToTest = 1\n",
    "temp_X = train_X.iloc[0:600000].copy()\n",
    "temp_Y = train_Y.iloc[0:600000].copy()\n",
    "\n",
    "results = kFoldCV(train_X, train_Y, k, numFoldsToTest)\n",
    "\n",
    "print(results[ [('train', 'roc'), ('test', 'roc')]])\n",
    "\n",
    "print(results[ [('train', 'roc'), ('test', 'roc')]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1997446"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3971668     True\n",
       "6516366    False\n",
       "3162886     True\n",
       "26492       True\n",
       "6509114    False\n",
       "3792170     True\n",
       "7686620    False\n",
       "816199     False\n",
       "4731108    False\n",
       "8577883     True\n",
       "4310747     True\n",
       "5744312    False\n",
       "1543219    False\n",
       "7599995     True\n",
       "8887572     True\n",
       "5856454     True\n",
       "4697968     True\n",
       "998308     False\n",
       "2887861     True\n",
       "4249195     True\n",
       "6263214     True\n",
       "8816829    False\n",
       "583428     False\n",
       "6884377    False\n",
       "1787909    False\n",
       "2662779    False\n",
       "203534     False\n",
       "1898273     True\n",
       "2803991     True\n",
       "1482595    False\n",
       "           ...  \n",
       "7523755    False\n",
       "545249     False\n",
       "7916729    False\n",
       "7937393     True\n",
       "8508417    False\n",
       "7129101    False\n",
       "7636851     True\n",
       "9248563    False\n",
       "4118804    False\n",
       "6997358     True\n",
       "6012088     True\n",
       "9271512     True\n",
       "8162212    False\n",
       "5599927    False\n",
       "4773303    False\n",
       "6911696    False\n",
       "3946205    False\n",
       "6211267    False\n",
       "3803618     True\n",
       "6175038     True\n",
       "3483517    False\n",
       "4194113     True\n",
       "5135775     True\n",
       "5555872     True\n",
       "4707122     True\n",
       "9050879     True\n",
       "282671     False\n",
       "7906140    False\n",
       "5565025    False\n",
       "2764846     True\n",
       "Name: sameArtist, dtype: bool"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fit\n",
      "total training time: 37.411495208740234\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, min_samples_split=15, n_jobs=30)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print('starting fit')\n",
    "#excluding the patient_id column from the fit and prediction\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('total training time: %s' % (end - start) )\n",
    "\n",
    "#columnsList = list(itertools.product(('train', 'test'), ('roc', 'precision', 'recall', 'npp', 'specificity')))\n",
    "#results = pd.DataFrame(index = range(numFoldsToTest), columns = pd.MultiIndex.from_tuples(columnsList))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total saving time: 3.6660020000003897\n"
     ]
    }
   ],
   "source": [
    "##save model\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "with open('my_dumped_classifier.pkl', 'wb') as fid:\n",
    "    pickle.dump(clf, fid) \n",
    "\n",
    "end = time.clock()\n",
    "print('total saving time: %s' % (end - start) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loading time: 0.007420999999339983\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# load it again\n",
    "with open('my_dumped_classifier.pkl', 'rb') as fid:\n",
    "    clf = pickle.load(fid)\n",
    "\n",
    "end = time.clock()\n",
    "print('total loading time: %s' % (end - start) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions = clf.predict_proba(test_X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## prepare submission\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(index = test_pairs.index)\n",
    "submission['sameArtist'] = test_predictions\n",
    "submission.to_csv('/data/notebook/notebooks/my_submission_01.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(index = test_pairs.index)\n",
    "submission['sameArtist'] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sameArtist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.146189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.915134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.395387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sameArtist\n",
       "index            \n",
       "0        0.146189\n",
       "1        0.915134\n",
       "2        0.062293\n",
       "3        0.395387\n",
       "4        0.117785"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21916047"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
