{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/data/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import time\n",
    "import traceback\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import skimage.data\n",
    "import skimage.exposure\n",
    "import skimage.color\n",
    "import skimage.transform\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make training pairs parent func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makePairsParent(train_info, k):\n",
    "\n",
    "    artists = train_info.artist.unique()       \n",
    "    np.random.shuffle(artists)\n",
    "    \n",
    "    chunkSize = int(len(artists)/k)\n",
    "    \n",
    "    artist_list_list = []\n",
    "    \n",
    "    for foldNum in range(k):\n",
    "        if foldNum == k-1:\n",
    "            artist_list_list.append( artists[foldNum*chunkSize : len(artists)] )\n",
    "        else:\n",
    "            artist_list_list.append( artists[foldNum*chunkSize : (foldNum+1)*(chunkSize) ] )\n",
    "        \n",
    "    # define which indices belong to each fold\n",
    "\n",
    "    #foldLocsList = [] #list of Index objects, one for each fold\n",
    "\n",
    "    #foldSize = int(len(train_info)/k)\n",
    "\n",
    "    #for foldNum in range(k):\n",
    "    #    if foldNum == k-1:\n",
    "    #        foldLocsList.append( train_info.index[foldNum*foldSize : len(train_info)] )\n",
    "    #    else:\n",
    "    #        foldLocsList.append( train_info.index[foldNum*foldSize : (foldNum+1)*(foldSize) ] )\n",
    "\n",
    "    # define which indices belong to each fold\n",
    "    argsList = []\n",
    "\n",
    "    num_cores = min( multiprocessing.cpu_count()-2, k)\n",
    "\n",
    "    for foldNum in range(k):\n",
    "        #argsList.append([train_info.loc[foldLocsList[foldNum]]])\n",
    "        argsList.append( [ train_info[train_info.artist.isin(artist_list_list[foldNum])], foldNum ] )\n",
    "\n",
    "    print('Launching %s jobs to make pairs' % k)\n",
    "\n",
    "    startTime = time.time()\n",
    "\n",
    "    pool = multiprocessing.Pool(num_cores)\n",
    "    train_pairs_list = pool.starmap(make_pairs, argsList)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    endTime = time.time()\n",
    "\n",
    "    print(\"making pairs complete, time taken = %.2f minutes\" % ((endTime - startTime) / 60.0))\n",
    "    \n",
    "    return pd.concat(train_pairs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_pairs(train_info, foldNum):\n",
    "    \"\"\"Creates training data from the supplied training image information file\"\"\"\n",
    "    artists = train_info.artist.unique()\n",
    "\n",
    "    n = train_info.groupby('artist').size()\n",
    "    n = (2*n**2).sum() \n",
    "    t = pd.DataFrame(np.zeros((n, 4)), columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    for artist in artists:\n",
    "\n",
    "        #artist info is Ax2 matrix of artist, filename\n",
    "        artistInfo = train_info[train_info.artist==artist][['artist', 'filename']].values\n",
    "        \n",
    "        use = train_info[train_info.artist != artist ].index.values\n",
    "        np.random.shuffle(use)\n",
    "        \n",
    "        #nm = np.min([a.shape[0]**2, train_info[train_info.artist != m].shape[0] ])\n",
    "        numExamples = np.min([len(artistInfo)**2, sum(train_info.artist != artist) ])\n",
    "        use = use[0:numExamples]\n",
    "        \n",
    "        #diffArtistInfo a Bx2 matrix of artist, filename\n",
    "        diffArtistInfo = train_info[train_info.artist!=artist][['artist', 'filename']].ix[use, :].values\n",
    "\n",
    "        \n",
    "        toAdd_SameArtist = pd.DataFrame(np.concatenate([  np.repeat(artistInfo[:, 0], len(artistInfo)).reshape((-1,1)), #artist\n",
    "                                            np.repeat(artistInfo[:, 1],\n",
    "                                            artistInfo.shape[0]).reshape((-1,1)),\n",
    "                                            np.tile(artistInfo, (len(artistInfo), 1))],\n",
    "                                         axis=1),\n",
    "                          columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "        toAdd_SameArtist = toAdd_SameArtist.loc[0:numExamples, :]\n",
    "        \n",
    "        toAdd_DiffArtist = pd.DataFrame(np.concatenate([np.tile(artistInfo,\n",
    "                                                  (len(artistInfo), 1))[0:len(diffArtistInfo), :],\n",
    "                                          diffArtistInfo], axis=1),\n",
    "                          columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "        toAdd_DiffArtist = toAdd_DiffArtist.loc[0:numExamples, :]\n",
    "        \n",
    "        #print(j, i, a2.shape[0], b2.shape[0])\n",
    "        #print(b2)\n",
    "        t.iloc[i:i+len(toAdd_SameArtist), :] = toAdd_SameArtist.values\n",
    "        t.iloc[i+len(toAdd_SameArtist):i+len(toAdd_SameArtist)+len(toAdd_DiffArtist), :] = toAdd_DiffArtist.values\n",
    "        \n",
    "        i += len(toAdd_SameArtist) + len(toAdd_DiffArtist)\n",
    "        j += 1\n",
    "        if j%100==0:\n",
    "            print('finished %s of %s artists'%(j, len(artists)))\n",
    "\n",
    "    print('make pairs completed')\n",
    "    t = t[~t.image2.isin([np.nan, 0])]\n",
    "    \n",
    "    t['sameArtist'] = ( t['artist1'] == t['artist2'] )\n",
    "    t['foldNum'] = foldNum\n",
    "    \n",
    "    return t[t.image1 > t.image2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Image List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def prepImageList(image_info, isTest):\n",
    "#     \"\"\"given the train_image_info or submission_info, returns a dataframe with a single column containing filenames of images\"\"\"\n",
    "#     if isTest:\n",
    "#         images = list(set(list(image_info.image1.unique()) + list(image_info.image2.unique())))\n",
    "#         result = pd.DataFrame(np.array(images).reshape((-1, 1)), columns = ['filename'])\n",
    "#     else:\n",
    "#         result = pd.DataFrame(columns = ['filename'], data = image_info['filename'] )\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features Parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeaturesParent(isTest):\n",
    "    \"\"\"Creates features for training and test images. This function utilizes multiprocessing.\n",
    "    Args:\n",
    "        isTest: bool to fetch training or test data\n",
    "    Returns:\n",
    "        pandas DataFrame containing features\n",
    "    \"\"\"\n",
    "    \n",
    "    num_cores = multiprocessing.cpu_count() - 2\n",
    "    \n",
    "    argsList = []\n",
    "    \n",
    "    for jobNum in range(num_cores):\n",
    "        argsList.append((isTest, jobNum, num_cores))\n",
    "        \n",
    "\n",
    "    print('Launching %s jobs' % (num_cores))\n",
    "    startTime = time.time()\n",
    "    \n",
    "    pool = multiprocessing.Pool(num_cores)\n",
    "    image_features_list = pool.starmap(getFeaturesWorker, argsList)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    image_features = pd.concat(image_features_list)\n",
    "    \n",
    "    endTime = time.time()\n",
    "    \n",
    "    print(\"collecting features complete, time taken = %.2f minutes\" % ((endTime - startTime) / 60.0))\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFeaturesWorker(isTest, jobNum, totalJobs):\n",
    "    \"\"\"Child function for computing image features, only to be called by getFeaturesParent\n",
    "    Args:\n",
    "        isTest: whether to compute features for test or training images\n",
    "        jobNum: which job number this is\n",
    "        totalJobs: total number of jobs\n",
    "    Returns:\n",
    "        pandas dataframe containing a data for a fraction of the training or test images\n",
    "    \"\"\"\n",
    "    if isTest:\n",
    "        mydir = r'/data/test_data/test'\n",
    "        info = pd.read_csv(r'/data/test_data/submission_info.csv', index_col = 0)\n",
    "    else:\n",
    "        mydir = r'/data/training_data/train'\n",
    "        info = pd.read_csv(r'/data/training_data/train_info.csv', index_col = 0)\n",
    "    \n",
    "    totalNumImages = len(info)\n",
    "    \n",
    "    chunkSize = np.int(totalNumImages/totalJobs)\n",
    "    \n",
    "    if jobNum == totalJobs - 1:\n",
    "        startInd = jobNum * chunkSize\n",
    "        endInd = totalNumImages\n",
    "    else:\n",
    "        startInd = jobNum * chunkSize\n",
    "        endInd = (jobNum + 1) * chunkSize\n",
    "        \n",
    "    info = info.iloc[startInd:endInd]\n",
    "    \n",
    "    info['pixelsx'] = np.nan\n",
    "    info['pixelsy'] = np.nan\n",
    "    info['size_bytes'] = np.nan\n",
    "    \n",
    "    info['r_mean'] = np.nan\n",
    "    info['r_10_pct'] = np.nan\n",
    "    info['r_25_pct'] = np.nan\n",
    "    info['r_50_pct'] = np.nan\n",
    "    info['r_75_pct'] = np.nan\n",
    "    info['r_90_pct'] = np.nan\n",
    "    \n",
    "    info['g_mean'] = np.nan\n",
    "    info['g_std'] = np.nan\n",
    "    info['g_10_pct'] = np.nan\n",
    "    info['g_25_pct'] = np.nan\n",
    "    info['g_50_pct'] = np.nan\n",
    "    info['g_75_pct'] = np.nan\n",
    "    info['g_90_pct'] = np.nan\n",
    "    \n",
    "    info['b_mean'] = np.nan\n",
    "    info['b_std'] = np.nan\n",
    "    info['b_10_pct'] = np.nan\n",
    "    info['b_25_pct'] = np.nan\n",
    "    info['b_50_pct'] = np.nan\n",
    "    info['b_75_pct'] = np.nan\n",
    "    info['b_90_pct'] = np.nan\n",
    "    \n",
    "    info['h_mean'] = np.nan\n",
    "    info['h_var'] = np.nan\n",
    "    \n",
    "    info['s_mean'] = np.nan\n",
    "    info['s_std'] = np.nan\n",
    "    info['s_10_pct'] = np.nan \n",
    "    info['s_25_pct'] = np.nan \n",
    "    info['s_50_pct'] = np.nan \n",
    "    info['s_75_pct'] = np.nan \n",
    "    info['s_90_pct'] = np.nan \n",
    "    \n",
    "    info['v_mean'] = np.nan\n",
    "    info['v_std'] = np.nan\n",
    "    info['v_10_pct'] = np.nan \n",
    "    info['v_25_pct'] = np.nan \n",
    "    info['v_50_pct'] = np.nan\n",
    "    info['v_75_pct'] = np.nan \n",
    "    info['v_90_pct'] = np.nan \n",
    "    \n",
    "    info['v_10_pct'] = np.nan \n",
    "    info['v_25_pct'] = np.nan \n",
    "    info['v_50_pct'] = np.nan\n",
    "    info['v_75_pct'] = np.nan \n",
    "    info['v_90_pct'] = np.nan \n",
    "   \n",
    "    info['h_cx_05_pct'] = np.nan \n",
    "    info['h_cx_10_pct'] = np.nan \n",
    "    info['h_cx_25_pct'] = np.nan \n",
    "    info['h_cx_50_pct'] = np.nan\n",
    "    info['h_cx_75_pct'] = np.nan \n",
    "    info['h_cx_90_pct'] = np.nan \n",
    "    info['h_cx_95_pct'] = np.nan \n",
    "    \n",
    "    info['s_cx_05_pct'] = np.nan \n",
    "    info['s_cx_10_pct'] = np.nan \n",
    "    info['s_cx_25_pct'] = np.nan \n",
    "    info['s_cx_50_pct'] = np.nan\n",
    "    info['s_cx_75_pct'] = np.nan \n",
    "    info['s_cx_90_pct'] = np.nan \n",
    "    info['s_cx_95_pct'] = np.nan\n",
    "    \n",
    "    info['v_cx_05_pct'] = np.nan \n",
    "    info['v_cx_10_pct'] = np.nan \n",
    "    info['v_cx_25_pct'] = np.nan \n",
    "    info['v_cx_50_pct'] = np.nan\n",
    "    info['v_cx_75_pct'] = np.nan \n",
    "    info['v_cx_90_pct'] = np.nan \n",
    "    info['v_cx_95_pct'] = np.nan\n",
    "    \n",
    "    info['is_grayscale'] = np.nan\n",
    "      \n",
    "    print('Job %s, starting getting image info for images %s-%s' % (jobNum, startInd, endInd-1))\n",
    "    startTime = time.clock()\n",
    "    \n",
    "    for ind, i in enumerate(info.index.values):\n",
    "        try:       \n",
    "            #im = Image.open(mydir+'/'+info.loc[i, 'filename'])\n",
    "            #info.loc[i, 'pixelsx'], info.loc[i, 'pixelsy'] = im.size\n",
    "            \n",
    "            im = skimage.data.imread(mydir + '/' + info.loc[i, 'filename'])\n",
    "                \n",
    "            info.loc[i, 'pixelsx'] = pixelsx = im.shape[1]\n",
    "            info.loc[i, 'pixelsy'] = pixelsy = im.shape[0]\n",
    "            \n",
    "            info.loc[i, 'is_grayscale' ] = grayscale = (len(im.shape) == 2)\n",
    "            \n",
    "            # get sample dimensions\n",
    "            yxRatio = (pixelsy/pixelsx)\n",
    "\n",
    "            base_size = 200\n",
    "            \n",
    "            if yxRatio < 1.0:\n",
    "                num_y_samp = base_size + 2\n",
    "                num_x_samp = np.int( num_y_samp / yxRatio )\n",
    "            else:\n",
    "                num_x_samp = base_size + 2\n",
    "                num_y_samp = np.int( num_x_samp * yxRatio)\n",
    "\n",
    "            #print('x and y: %i %i' %(pixelsx, pixelsy))\n",
    "            #sample\n",
    "            #x_space = np.round(np.linspace(0, pixelsx-1, num_x_samp)).astype(int)\n",
    "            #y_space = np.round(np.linspace(0, pixelsy-1, num_y_samp)).astype(int)\n",
    "\n",
    "            #samp_im = np.take(im, x_space, axis=1)\n",
    "            #samp_im = np.take(samp_im, y_space, axis=0)\n",
    "            \n",
    "            #im = samp_im\n",
    "            im = skimage.transform.resize(im, [num_y_samp, num_x_samp])\n",
    "                \n",
    "            #convert grayscale to rgb\n",
    "            if grayscale:\n",
    "                temp = np.zeros([num_y_samp, num_x_samp, 3])\n",
    "                #temp = np.zeros([pixelsy, pixelsx, 3])\n",
    "                for temp_ind in range(3):\n",
    "                    temp[:,:,temp_ind] = im\n",
    "                im = temp    \n",
    "              \n",
    "            # rgb \n",
    "            info.loc[i, 'r_mean'] = im[:,:,0].mean()\n",
    "            info.loc[i, 'g_mean'] = im[:,:,1].mean()\n",
    "            info.loc[i, 'b_mean'] = im[:,:,2].mean()\n",
    "            \n",
    "            r_pcts = np.percentile(im[:,:,0],[10, 25, 50, 75, 90])\n",
    "            b_pcts = np.percentile(im[:,:,1],[10, 25, 50, 75, 90])\n",
    "            g_pcts = np.percentile(im[:,:,2],[10, 25, 50, 75, 90])\n",
    "            \n",
    "            for temp_ind, percentile in enumerate([10, 25, 50, 75, 90]):\n",
    "                info.loc[i, 'r_%.2i_pct' % percentile] = r_pcts[temp_ind]\n",
    "                info.loc[i, 'g_%.2i_pct' % percentile] = g_pcts[temp_ind]\n",
    "                info.loc[i, 'b_%.2i_pct' % percentile] = b_pcts[temp_ind]\n",
    "            \n",
    "            info.loc[i, 'r_std'] = im[:,:,0].std()\n",
    "            info.loc[i, 'g_std'] = im[:,:,1].std()\n",
    "            info.loc[i, 'b_std'] = im[:,:,2].std()\n",
    "\n",
    "            #if it is in RGBA, we don't handle it for now\n",
    "            if (len(im.shape) == 3) and im.shape[2] == 4:\n",
    "                print('%s is rgba' % info.loc[i, 'filename'])\n",
    "            else:     \n",
    "                # convert image to hue/saturation/value\n",
    "                hsvImage = skimage.color.rgb2hsv(im)\n",
    "                h_angles = hsvImage[:,:,0] * 2.0 * np.pi\n",
    "\n",
    "                # average hue is converting the (0-1) hue value to unit vector coordinates\n",
    "                # and finding the average direction\n",
    "                sinSum = np.sin(h_angles).sum()\n",
    "                cosSum = np.cos(h_angles).sum()\n",
    "                info.loc[i, 'h_mean'] = np.arctan(sinSum/cosSum)\n",
    "\n",
    "                # use the variance formula for a circulator distribution\n",
    "                R2 = np.power(sinSum, 2) + np.power(cosSum, 2)\n",
    "                numPixels = info.loc[i, 'pixelsx'] * info.loc[i, 'pixelsy']\n",
    "                R_bar = np.sqrt(R2)/numPixels\n",
    "                info.loc[i, 'h_var'] = 1 - R_bar\n",
    "\n",
    "                info.loc[i, 's_mean'] = hsvImage[:,:,1].mean()\n",
    "                info.loc[i, 's_std'] = hsvImage[:,:,1].std()\n",
    "\n",
    "                info.loc[i, 'v_mean'] = hsvImage[:,:,2].mean()\n",
    "                info.loc[i, 'v_std'] = hsvImage[:,:,2].std()\n",
    "                \n",
    "                s_pcts = np.percentile(im[:,:,1],[10, 25, 50, 75, 90])\n",
    "                v_pcts = np.percentile(im[:,:,2],[10, 25, 50, 75, 90])\n",
    "\n",
    "                for temp_ind, percentile in enumerate([10, 25, 50, 75, 90]):\n",
    "                    info.loc[i, 's_%.2i_pct' % percentile] = r_pcts[temp_ind]\n",
    "                    info.loc[i, 'v_%.2i_pct' % percentile] = g_pcts[temp_ind]\n",
    "\n",
    "                #complexity metrics\n",
    "                \n",
    "                #print('samp im shape' % samp_im.shape)\n",
    "                \n",
    "                # go from hue to angles              \n",
    "                samp_h_angles = hsvImage[:,:,0] * 2.0 * np.pi\n",
    "                #samp_h_angles = samp_im[:,:,0] * 2.0 * np.pi\n",
    "                \n",
    "                #compute gradients\n",
    "                hsv_x_grad = np.zeros([num_y_samp-2, num_x_samp-2, 3])\n",
    "                hsv_y_grad = np.zeros([num_y_samp-2, num_x_samp-2, 3])\n",
    "                \n",
    "                hsv_x_grad[:,:,0] = np.min(\n",
    "                        [ np.abs(h_angles[1:-1,0:num_x_samp-2] - h_angles[1:-1,1:num_x_samp-1]),\n",
    "                        2.0 * np.pi - np.abs( h_angles[1:-1,0:num_x_samp-2] - h_angles[1:-1,1:num_x_samp-1])\n",
    "                        ],\n",
    "                        axis = 0\n",
    "                      )\n",
    "                hsv_y_grad[:,:,0] = np.min(\n",
    "                        [ np.abs(h_angles[0:num_y_samp-2,1:-1] - h_angles[1:num_y_samp-1,1:-1]),\n",
    "                        2.0 * np.pi - np.abs( h_angles[0:num_y_samp-2,1:-1] - h_angles[1:num_y_samp-1,1:-1])\n",
    "                        ],\n",
    "                        axis = 0\n",
    "                      )\n",
    "\n",
    "                hsv_x_grad[:,:,1:3] = np.abs(hsvImage[1:-1,0:num_x_samp-2,1:3] - hsvImage[1:-1,1:num_x_samp-1,1:3])\n",
    "                hsv_y_grad[:,:,1:3] = np.abs(hsvImage[0:num_y_samp-2,1:-1,1:3] - hsvImage[1:num_y_samp-1,1:-1,1:3])\n",
    "\n",
    "                hsv_grad_mag = np.sqrt(np.power(hsv_x_grad,2) + np.power(hsv_y_grad,2))\n",
    "                \n",
    "                h_pcts = np.percentile(hsv_grad_mag[:,:,0], [5,10,25,50,75,90,95])\n",
    "                s_pcts = np.percentile(hsv_grad_mag[:,:,1], [5,10,25,50,75,90,95])\n",
    "                v_pcts = np.percentile(hsv_grad_mag[:,:,2], [5,10,25,50,75,90,95])\n",
    "                \n",
    "                for temp_ind, percentile in enumerate([5, 10, 25, 50, 75, 90, 95]):\n",
    "                    info.loc[i, 'h_cx_%.2i_pct' % percentile] = h_pcts[temp_ind]\n",
    "                    info.loc[i, 's_cx_%.2i_pct' % percentile] = s_pcts[temp_ind]\n",
    "                    info.loc[i, 'v_cx_%.2i_pct' % percentile] = v_pcts[temp_ind]\n",
    "\n",
    "            #im = cv2.imread(dir+'/'+info.loc[i, 'new_filename'])\n",
    "            #info.loc[i, 'pixelsx'], info.loc[i, 'pixelsy'] = im.shape[0:2]\n",
    "            info.loc[i, 'size_bytes'] = os.path.getsize(mydir+'/'+info.loc[i, 'filename']) \n",
    "\n",
    "            if (ind+1)%100==0:\n",
    "                currentTime = time.clock()\n",
    "                print('Job %s, finished %s of %s, total time = %.2f min' %\n",
    "                     (jobNum, (ind+1), len(info), (currentTime - startTime)/60.0))\n",
    "        except:\n",
    "            print('job %s - error in %s' % (jobNum, mydir+'/'+info.loc[i, 'filename']))\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    currentTime = time.clock()\n",
    "    print('- Job %s, finished getting image info, total time = %.2f min' % ( jobNum, (currentTime - startTime) / 60.0))\n",
    "    \n",
    "    return info\n",
    "\n",
    "    #return info.rename(columns={'filename' : 'new_filename'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load image info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load training info\n",
    "train_info = pd.read_csv(r'/data/training_data/train_info.csv', index_col=0)\n",
    "submission_info = pd.read_csv(r'/data/test_data/submission_info.csv', index_col=0)\n",
    "\n",
    "#shuffle and save info\n",
    "#train_info = train_info.iloc[np.random.permutation(len(train_info))]\n",
    "#submission_info = submission_info.iloc[np.random.permutation(len(submission_info))]\n",
    "\n",
    "#train_info.to_csv(r'/data/training_data/train_info.csv')\n",
    "#submission_info.to_csv(r'/data/test_data/submission_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create submission image info from submission pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission image data is a bunch of images pairs, but we may want to work with a list of test images instead\n",
    "\n",
    "#submission_pairs = pd.read_csv(r'/data/test_data/submission_pairs.csv')\n",
    "#images = list(set(list(submission_info.image1.unique()) + list(submission_info.image2.unique())))\n",
    "#submission_info = pd.DataFrame(data=images, columns=['filename'])\n",
    "#submission_info = pd.read_csv(r'/data/test_data/submission_info.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pairs = pd.read_csv(r'/data/test_data/submission_pairs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 5 jobs to make pairs\n",
      "finished 100 of 316 artists\n",
      "finished 100 of 316 artists\n",
      "finished 100 of 320 artists\n",
      "finished 200 of 316 artists\n",
      "finished 200 of 316 artists\n",
      "finished 100 of 316 artists\n",
      "finished 100 of 316 artists\n",
      "finished 200 of 320 artists\n",
      "finished 300 of 316 artists\n",
      "make pairs completed\n",
      "finished 300 of 316 artists\n",
      "finished 200 of 316 artists\n",
      "finished 300 of 320 artists\n",
      "finished 200 of 316 artists\n",
      "make pairs completed\n",
      "make pairs completed\n",
      "finished 300 of 316 artists\n",
      "make pairs completed\n",
      "finished 300 of 316 artists\n",
      "make pairs completed\n",
      "making pairs complete, time taken = 0.32 minutes\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "train_pairs = makePairsParent(train_info, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to /data/training_data/train_pairs.csv \n"
     ]
    }
   ],
   "source": [
    "#save as csv\n",
    "filepath = r'/data/training_data/train_pairs.csv'\n",
    "train_pairs.to_csv(filepath)\n",
    "print('saving to %s ' % filepath  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load pairs\n",
    "train_pairs = pd.read_csv(r'/data/training_data/train_pairs.csv', index_col = 0)\n",
    "#submission_pairs = pd.read_csv(r'/data/test_data/submission_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pairs = train_pairs.iloc[np.random.permutation(len(train_pairs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pairs=train_pairs[0:2000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin computing features\n",
      "Launching 38 jobs\n",
      "Job 36, starting getting image info for images 22536-23161\n",
      "Job 0, starting getting image info for images 0-625\n",
      "Job 29, starting getting image info for images 18154-18779\n",
      "Job 21, starting getting image info for images 13146-13771\n",
      "Job 27, starting getting image info for images 16902-17527\n",
      "Job 9, starting getting image info for images 5634-6259\n",
      "Job 32, starting getting image info for images 20032-20657\n",
      "Job 10, starting getting image info for images 6260-6885\n",
      "Job 13, starting getting image info for images 8138-8763\n",
      "Job 4, starting getting image info for images 2504-3129\n",
      "Job 14, starting getting image info for images 8764-9389\n",
      "Job 17, starting getting image info for images 10642-11267\n",
      "Job 28, starting getting image info for images 17528-18153\n",
      "Job 37, starting getting image info for images 23162-23816\n",
      "Job 11, starting getting image info for images 6886-7511\n",
      "Job 22, starting getting image info for images 13772-14397\n",
      "Job 19, starting getting image info for images 11894-12519\n",
      "Job 15, starting getting image info for images 9390-10015\n",
      "Job 24, starting getting image info for images 15024-15649\n",
      "Job 7, starting getting image info for images 4382-5007\n",
      "Job 23, starting getting image info for images 14398-15023\n",
      "Job 12, starting getting image info for images 7512-8137\n",
      "Job 20, starting getting image info for images 12520-13145\n",
      "Job 1, starting getting image info for images 626-1251\n",
      "Job 2, starting getting image info for images 1252-1877\n",
      "Job 18, starting getting image info for images 11268-11893\n",
      "Job 35, starting getting image info for images 21910-22535\n",
      "Job 31, starting getting image info for images 19406-20031\n",
      "Job 3, starting getting image info for images 1878-2503\n",
      "Job 25, starting getting image info for images 15650-16275\n",
      "Job 26, starting getting image info for images 16276-16901\n",
      "Job 8, starting getting image info for images 5008-5633\n",
      "Job 6, starting getting image info for images 3756-4381\n",
      "Job 34, starting getting image info for images 21284-21909\n",
      "Job 30, starting getting image info for images 18780-19405\n",
      "Job 5, starting getting image info for images 3130-3755\n",
      "Job 33, starting getting image info for images 20658-21283\n",
      "Job 16, starting getting image info for images 10016-10641\n",
      "17888.jpg is rgba\n",
      "Job 30, finished 100 of 626, total time = 0.41 min\n",
      "Job 33, finished 100 of 626, total time = 0.43 min\n",
      "Job 37, finished 100 of 655, total time = 0.45 min\n",
      "Job 11, finished 100 of 626, total time = 0.43 min\n",
      "Job 28, finished 100 of 626, total time = 0.47 min\n",
      "Job 25, finished 100 of 626, total time = 0.45 min\n",
      "Job 22, finished 100 of 626, total time = 0.47 min\n",
      "Job 14, finished 100 of 626, total time = 0.47 min\n",
      "Job 29, finished 100 of 626, total time = 0.50 min\n",
      "Job 24, finished 100 of 626, total time = 0.49 min\n",
      "Job 12, finished 100 of 626, total time = 0.48 min\n",
      "Job 36, finished 100 of 626, total time = 0.53 min\n",
      "Job 21, finished 100 of 626, total time = 0.52 min\n",
      "Job 35, finished 100 of 626, total time = 0.53 min\n",
      "Job 34, finished 100 of 626, total time = 0.54 min\n",
      "Job 13, finished 100 of 626, total time = 0.52 min\n",
      "Job 26, finished 100 of 626, total time = 0.53 min\n",
      "Job 20, finished 100 of 626, total time = 0.53 min\n",
      "Job 9, finished 100 of 626, total time = 0.51 min\n",
      "Job 18, finished 100 of 626, total time = 0.53 min\n",
      "Job 1, finished 100 of 626, total time = 0.50 min\n",
      "Job 8, finished 100 of 626, total time = 0.52 min\n",
      "Job 16, finished 100 of 626, total time = 0.55 min\n",
      "Job 23, finished 100 of 626, total time = 0.57 min\n",
      "Job 7, finished 100 of 626, total time = 0.55 min\n",
      "Job 10, finished 100 of 626, total time = 0.55 min\n",
      "Job 2, finished 100 of 626, total time = 0.53 min\n",
      "Job 15, finished 100 of 626, total time = 0.56 min\n",
      "Job 6, finished 100 of 626, total time = 0.56 min\n",
      "Job 27, finished 100 of 626, total time = 0.60 min\n",
      "Job 3, finished 100 of 626, total time = 0.55 min\n",
      "Job 32, finished 100 of 626, total time = 0.62 min\n",
      "Job 17, finished 100 of 626, total time = 0.60 min\n",
      "Job 19, finished 100 of 626, total time = 0.61 min\n",
      "25416.jpg is rgba\n",
      "Job 31, finished 100 of 626, total time = 0.65 min\n",
      "Job 5, finished 100 of 626, total time = 0.62 min\n",
      "69828.jpg is rgba\n",
      "Job 4, finished 100 of 626, total time = 0.78 min\n",
      "Job 0, finished 100 of 626, total time = 0.80 min\n",
      "30623.jpg is rgba\n",
      "75551.jpg is rgba\n",
      "Job 30, finished 200 of 626, total time = 0.89 min\n",
      "39101.jpg is rgba\n",
      "Job 12, finished 200 of 626, total time = 0.94 min\n",
      "Job 28, finished 200 of 626, total time = 0.98 min\n",
      "Job 24, finished 200 of 626, total time = 0.98 min\n",
      "Job 25, finished 200 of 626, total time = 0.99 min\n",
      "Job 35, finished 200 of 626, total time = 1.01 min\n",
      "Job 33, finished 200 of 626, total time = 1.01 min\n",
      "job 19 - error in /data/test_data/test/100532.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/Image.py\", line 1151, in getdata\n",
      "    self.load()\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/ImageFile.py\", line 218, in load\n",
      "    \"(%d bytes not processed)\" % len(b))\n",
      "OSError: image file is truncated (57 bytes not processed)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-7-739a9955c249>\", line 116, in getFeaturesWorker\n",
      "    im = skimage.data.imread(mydir + '/' + info.loc[i, 'filename'])\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 61, in pil_to_ndarray\n",
      "    raise ValueError(error_message)\n",
      "ValueError: Could not load \"\" \n",
      "Reason: \"image file is truncated (57 bytes not processed)\"\n",
      "Please see documentation at: http://pillow.readthedocs.org/en/latest/installation.html#external-libraries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 13, finished 200 of 626, total time = 1.00 min\n",
      "Job 22, finished 200 of 626, total time = 1.02 min\n",
      "Job 29, finished 200 of 626, total time = 1.05 min\n",
      "Job 14, finished 200 of 626, total time = 1.01 min\n",
      "Job 34, finished 200 of 626, total time = 1.05 min\n",
      "Job 36, finished 200 of 626, total time = 1.06 min\n",
      "Job 21, finished 200 of 626, total time = 1.04 min\n",
      "Job 37, finished 200 of 655, total time = 1.07 min\n",
      "Job 6, finished 200 of 626, total time = 1.03 min\n",
      "Job 10, finished 200 of 626, total time = 1.05 min\n",
      "Job 11, finished 200 of 626, total time = 1.06 min\n",
      "Job 23, finished 200 of 626, total time = 1.10 min\n",
      "Job 16, finished 200 of 626, total time = 1.09 min\n",
      "Job 8, finished 200 of 626, total time = 1.08 min\n",
      "Job 19, finished 200 of 626, total time = 1.11 min\n",
      "Job 26, finished 200 of 626, total time = 1.12 min\n",
      "Job 20, finished 200 of 626, total time = 1.11 min\n",
      "Job 32, finished 200 of 626, total time = 1.14 min\n",
      "Job 18, finished 200 of 626, total time = 1.11 min\n",
      "Job 5, finished 200 of 626, total time = 1.09 min\n",
      "Job 1, finished 200 of 626, total time = 1.09 min\n",
      "32071.jpg is rgba\n",
      "Job 3, finished 200 of 626, total time = 1.08 min\n",
      "Job 7, finished 200 of 626, total time = 1.10 min\n",
      "Job 2, finished 200 of 626, total time = 1.08 min\n",
      "Job 15, finished 200 of 626, total time = 1.14 min\n",
      "Job 17, finished 200 of 626, total time = 1.18 min\n",
      "Job 27, finished 200 of 626, total time = 1.22 min\n",
      "Job 31, finished 200 of 626, total time = 1.21 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (133026477 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 9, finished 200 of 626, total time = 1.23 min\n",
      "Job 30, finished 300 of 626, total time = 1.39 min\n",
      "Job 4, finished 200 of 626, total time = 1.38 min\n",
      "Job 24, finished 300 of 626, total time = 1.45 min\n",
      "Job 25, finished 300 of 626, total time = 1.46 min\n",
      "job 8 - error in /data/test_data/test/20153.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/Image.py\", line 1151, in getdata\n",
      "    self.load()\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/ImageFile.py\", line 218, in load\n",
      "    \"(%d bytes not processed)\" % len(b))\n",
      "OSError: image file is truncated (0 bytes not processed)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-7-739a9955c249>\", line 116, in getFeaturesWorker\n",
      "    im = skimage.data.imread(mydir + '/' + info.loc[i, 'filename'])\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 61, in pil_to_ndarray\n",
      "    raise ValueError(error_message)\n",
      "ValueError: Could not load \"\" \n",
      "Reason: \"image file is truncated (0 bytes not processed)\"\n",
      "Please see documentation at: http://pillow.readthedocs.org/en/latest/installation.html#external-libraries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 36, finished 300 of 626, total time = 1.52 min\n",
      "Job 13, finished 300 of 626, total time = 1.48 min\n",
      "Job 34, finished 300 of 626, total time = 1.54 min\n",
      "Job 28, finished 300 of 626, total time = 1.55 min\n",
      "Job 12, finished 300 of 626, total time = 1.53 min\n",
      "Job 35, finished 300 of 626, total time = 1.58 min\n",
      "Job 18, finished 300 of 626, total time = 1.56 min\n",
      "Job 29, finished 300 of 626, total time = 1.59 min\n",
      "Job 5, finished 300 of 626, total time = 1.54 min\n",
      "Job 19, finished 300 of 626, total time = 1.58 min\n",
      "Job 8, finished 300 of 626, total time = 1.56 min\n",
      "Job 7, finished 300 of 626, total time = 1.56 min\n",
      "Job 0, finished 200 of 626, total time = 1.57 min\n",
      "Job 14, finished 300 of 626, total time = 1.59 min\n",
      "Job 1, finished 300 of 626, total time = 1.56 min\n",
      "Job 6, finished 300 of 626, total time = 1.58 min\n",
      "Job 16, finished 300 of 626, total time = 1.62 min\n",
      "Job 11, finished 300 of 626, total time = 1.60 min\n",
      "Job 22, finished 300 of 626, total time = 1.64 min\n",
      "Job 20, finished 300 of 626, total time = 1.64 min\n",
      "Job 37, finished 300 of 655, total time = 1.67 min\n",
      "Job 3, finished 300 of 626, total time = 1.60 min\n",
      "Job 33, finished 300 of 626, total time = 1.66 min\n",
      "Job 2, finished 300 of 626, total time = 1.59 min\n",
      "Job 10, finished 300 of 626, total time = 1.63 min\n",
      "89073.jpg is rgba\n",
      "Job 21, finished 300 of 626, total time = 1.67 min\n",
      "93262.jpg is rgba\n",
      "Job 15, finished 300 of 626, total time = 1.67 min\n",
      "Job 23, finished 300 of 626, total time = 1.69 min\n",
      "Job 32, finished 300 of 626, total time = 1.71 min\n",
      "Job 31, finished 300 of 626, total time = 1.77 min\n",
      "Job 9, finished 300 of 626, total time = 1.75 min\n",
      "69423.jpg is rgba\n",
      "job 31 - error in /data/test_data/test/72610.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-7-739a9955c249>\", line 118, in getFeaturesWorker\n",
      "    info.loc[i, 'pixelsx'] = pixelsx = im.shape[1]\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 26, finished 300 of 626, total time = 1.92 min\n",
      "Job 17, finished 300 of 626, total time = 1.92 min\n",
      "job 5 - error in /data/test_data/test/18649.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/Image.py\", line 1151, in getdata\n",
      "    self.load()\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/PIL/ImageFile.py\", line 218, in load\n",
      "    \"(%d bytes not processed)\" % len(b))\n",
      "OSError: image file is truncated (79 bytes not processed)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-7-739a9955c249>\", line 116, in getFeaturesWorker\n",
      "    im = skimage.data.imread(mydir + '/' + info.loc[i, 'filename'])\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/data/anaconda/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 61, in pil_to_ndarray\n",
      "    raise ValueError(error_message)\n",
      "ValueError: Could not load \"\" \n",
      "Reason: \"image file is truncated (79 bytes not processed)\"\n",
      "Please see documentation at: http://pillow.readthedocs.org/en/latest/installation.html#external-libraries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 4, finished 300 of 626, total time = 1.94 min\n",
      "91447.jpg is rgba\n",
      "Job 30, finished 400 of 626, total time = 1.98 min\n",
      "Job 27, finished 300 of 626, total time = 2.01 min\n",
      "Job 12, finished 400 of 626, total time = 1.98 min\n",
      "Job 35, finished 400 of 626, total time = 2.03 min\n",
      "Job 13, finished 400 of 626, total time = 1.99 min\n",
      "64004.jpg is rgba\n",
      "Job 34, finished 400 of 626, total time = 2.04 min\n",
      "Job 24, finished 400 of 626, total time = 2.04 min\n",
      "Job 29, finished 400 of 626, total time = 2.06 min\n",
      "Job 36, finished 400 of 626, total time = 2.08 min\n",
      "Job 11, finished 400 of 626, total time = 2.04 min\n",
      "Job 6, finished 400 of 626, total time = 2.05 min\n",
      "Job 25, finished 400 of 626, total time = 2.09 min\n",
      "Job 7, finished 400 of 626, total time = 2.06 min\n",
      "Job 33, finished 400 of 626, total time = 2.12 min\n",
      "Job 28, finished 400 of 626, total time = 2.12 min\n",
      "Job 3, finished 400 of 626, total time = 2.06 min\n",
      "Job 1, finished 400 of 626, total time = 2.07 min\n",
      "Job 2, finished 400 of 626, total time = 2.07 min\n",
      "Job 18, finished 400 of 626, total time = 2.13 min\n",
      "Job 20, finished 400 of 626, total time = 2.13 min\n",
      "Job 14, finished 400 of 626, total time = 2.13 min\n",
      "Job 8, finished 400 of 626, total time = 2.12 min\n",
      "Job 21, finished 400 of 626, total time = 2.16 min\n",
      "Job 22, finished 400 of 626, total time = 2.17 min\n",
      "Job 16, finished 400 of 626, total time = 2.17 min\n",
      "Job 19, finished 400 of 626, total time = 2.17 min\n",
      "Job 15, finished 400 of 626, total time = 2.18 min\n",
      "Job 5, finished 400 of 626, total time = 2.18 min\n",
      "Job 9, finished 400 of 626, total time = 2.21 min\n",
      "Job 10, finished 400 of 626, total time = 2.21 min\n",
      "Job 32, finished 400 of 626, total time = 2.27 min\n",
      "Job 37, finished 400 of 655, total time = 2.27 min\n",
      "Job 23, finished 400 of 626, total time = 2.28 min\n",
      "Job 0, finished 300 of 626, total time = 2.26 min\n",
      "Job 31, finished 400 of 626, total time = 2.31 min\n",
      "16469.jpg is rgba\n",
      "Job 26, finished 400 of 626, total time = 2.41 min\n",
      "Job 17, finished 400 of 626, total time = 2.45 min\n",
      "Job 24, finished 500 of 626, total time = 2.47 min\n",
      "Job 4, finished 400 of 626, total time = 2.45 min\n",
      "35962.jpg is rgba\n",
      "Job 34, finished 500 of 626, total time = 2.50 min\n",
      "Job 12, finished 500 of 626, total time = 2.47 min\n",
      "Job 13, finished 500 of 626, total time = 2.49 min\n",
      "Job 36, finished 500 of 626, total time = 2.55 min\n",
      "Job 11, finished 500 of 626, total time = 2.49 min\n",
      "Job 29, finished 500 of 626, total time = 2.57 min\n",
      "Job 30, finished 500 of 626, total time = 2.56 min\n",
      "Job 6, finished 500 of 626, total time = 2.53 min\n",
      "Job 33, finished 500 of 626, total time = 2.60 min\n",
      "Job 28, finished 500 of 626, total time = 2.60 min\n",
      "Job 35, finished 500 of 626, total time = 2.63 min\n",
      "Job 27, finished 400 of 626, total time = 2.67 min\n",
      "Job 16, finished 500 of 626, total time = 2.66 min\n",
      "Job 7, finished 500 of 626, total time = 2.63 min\n",
      "Job 2, finished 500 of 626, total time = 2.60 min\n",
      "Job 14, finished 500 of 626, total time = 2.66 min\n",
      "Job 20, finished 500 of 626, total time = 2.67 min\n",
      "Job 25, finished 500 of 626, total time = 2.69 min\n",
      "Job 15, finished 500 of 626, total time = 2.67 min\n",
      "Job 10, finished 500 of 626, total time = 2.66 min\n",
      "Job 3, finished 500 of 626, total time = 2.63 min\n",
      "Job 21, finished 500 of 626, total time = 2.70 min\n",
      "Job 1, finished 500 of 626, total time = 2.64 min\n",
      "Job 18, finished 500 of 626, total time = 2.69 min\n",
      "Job 19, finished 500 of 626, total time = 2.71 min\n",
      "Job 9, finished 500 of 626, total time = 2.71 min\n",
      "Job 37, finished 500 of 655, total time = 2.78 min\n",
      "Job 5, finished 500 of 626, total time = 2.71 min\n",
      "Job 32, finished 500 of 626, total time = 2.81 min\n",
      "Job 8, finished 500 of 626, total time = 2.78 min\n",
      "Job 22, finished 500 of 626, total time = 2.83 min\n",
      "Job 23, finished 500 of 626, total time = 2.83 min\n",
      "Job 0, finished 400 of 626, total time = 2.83 min\n",
      "Job 31, finished 500 of 626, total time = 2.90 min\n",
      "Job 26, finished 500 of 626, total time = 2.90 min\n",
      "Job 34, finished 600 of 626, total time = 2.95 min\n",
      "Job 17, finished 500 of 626, total time = 3.00 min\n",
      "Job 4, finished 500 of 626, total time = 2.97 min\n",
      "Job 33, finished 600 of 626, total time = 3.04 min\n",
      "Job 13, finished 600 of 626, total time = 3.01 min\n",
      "Job 24, finished 600 of 626, total time = 3.05 min\n",
      "Job 12, finished 600 of 626, total time = 3.03 min\n",
      "Job 29, finished 600 of 626, total time = 3.08 min\n",
      "Job 28, finished 600 of 626, total time = 3.09 min\n",
      "- Job 34, finished getting image info, total time = 3.10 min\n",
      "Job 16, finished 600 of 626, total time = 3.08 min\n",
      "Job 36, finished 600 of 626, total time = 3.13 min\n",
      "Job 6, finished 600 of 626, total time = 3.07 min\n",
      "- Job 33, finished getting image info, total time = 3.16 min\n",
      "Job 11, finished 600 of 626, total time = 3.11 min\n",
      "Job 15, finished 600 of 626, total time = 3.14 min\n",
      "Job 30, finished 600 of 626, total time = 3.17 min\n",
      "- Job 29, finished getting image info, total time = 3.19 min\n",
      "- Job 13, finished getting image info, total time = 3.16 min\n",
      "Job 20, finished 600 of 626, total time = 3.18 min\n",
      "Job 27, finished 500 of 626, total time = 3.22 min\n",
      "- Job 24, finished getting image info, total time = 3.19 min\n",
      "- Job 16, finished getting image info, total time = 3.18 min\n",
      "- Job 12, finished getting image info, total time = 3.17 min\n",
      "Job 9, finished 600 of 626, total time = 3.18 min\n",
      "Job 14, finished 600 of 626, total time = 3.19 min\n",
      "Job 19, finished 600 of 626, total time = 3.21 min\n",
      "Job 32, finished 600 of 626, total time = 3.24 min\n",
      "Job 5, finished 600 of 626, total time = 3.17 min\n",
      "Job 10, finished 600 of 626, total time = 3.20 min\n",
      "- Job 11, finished getting image info, total time = 3.20 min\n",
      "- Job 6, finished getting image info, total time = 3.21 min\n",
      "- Job 36, finished getting image info, total time = 3.29 min\n",
      "- Job 15, finished getting image info, total time = 3.24 min\n",
      "- Job 28, finished getting image info, total time = 3.27 min\n",
      "Job 21, finished 600 of 626, total time = 3.26 min\n",
      "Job 1, finished 600 of 626, total time = 3.20 min\n",
      "- Job 30, finished getting image info, total time = 3.28 min\n",
      "Job 35, finished 600 of 626, total time = 3.30 min\n",
      "Job 23, finished 600 of 626, total time = 3.29 min\n",
      "Job 3, finished 600 of 626, total time = 3.22 min\n",
      "Job 25, finished 600 of 626, total time = 3.30 min\n",
      "- Job 14, finished getting image info, total time = 3.28 min\n",
      "- Job 9, finished getting image info, total time = 3.28 min\n",
      "Job 22, finished 600 of 626, total time = 3.32 min\n",
      "- Job 20, finished getting image info, total time = 3.31 min\n",
      "Job 7, finished 600 of 626, total time = 3.28 min\n",
      "- Job 19, finished getting image info, total time = 3.31 min\n",
      "Job 8, finished 600 of 626, total time = 3.29 min\n",
      "Job 0, finished 500 of 626, total time = 3.29 min\n",
      "- Job 32, finished getting image info, total time = 3.37 min\n",
      "- Job 5, finished getting image info, total time = 3.29 min\n",
      "- Job 10, finished getting image info, total time = 3.32 min\n",
      "- Job 23, finished getting image info, total time = 3.37 min\n",
      "- Job 35, finished getting image info, total time = 3.39 min\n",
      "Job 26, finished 600 of 626, total time = 3.38 min\n",
      "- Job 25, finished getting image info, total time = 3.38 min\n",
      "Job 31, finished 600 of 626, total time = 3.39 min\n",
      "- Job 22, finished getting image info, total time = 3.38 min\n",
      "Job 17, finished 600 of 626, total time = 3.38 min\n",
      "- Job 3, finished getting image info, total time = 3.32 min\n",
      "Job 37, finished 600 of 655, total time = 3.42 min\n",
      "Job 2, finished 600 of 626, total time = 3.31 min\n",
      "- Job 1, finished getting image info, total time = 3.34 min\n",
      "Job 18, finished 600 of 626, total time = 3.39 min\n",
      "- Job 7, finished getting image info, total time = 3.36 min\n",
      "- Job 21, finished getting image info, total time = 3.41 min\n",
      "- Job 8, finished getting image info, total time = 3.37 min\n",
      "- Job 26, finished getting image info, total time = 3.44 min\n",
      "- Job 31, finished getting image info, total time = 3.44 min\n",
      "- Job 18, finished getting image info, total time = 3.44 min\n",
      "Job 4, finished 600 of 626, total time = 3.42 min\n",
      "- Job 2, finished getting image info, total time = 3.38 min\n",
      "- Job 17, finished getting image info, total time = 3.48 min\n",
      "Job 27, finished 600 of 626, total time = 3.55 min\n",
      "- Job 37, finished getting image info, total time = 3.55 min\n",
      "- Job 4, finished getting image info, total time = 3.49 min\n",
      "- Job 27, finished getting image info, total time = 3.59 min\n",
      "Job 0, finished 600 of 626, total time = 3.65 min\n",
      "- Job 0, finished getting image info, total time = 3.70 min\n",
      "collecting features complete, time taken = 3.85 minutes\n",
      "Finished computing features, time taken = 3.85 min\n"
     ]
    }
   ],
   "source": [
    "print('Begin computing features')\n",
    "startTime = time.time()\n",
    "\n",
    "test_features = getFeaturesParent(True)\n",
    "\n",
    "endTime = time.time()\n",
    "print(\"Finished computing features, time taken = %.2f min\" % ((endTime-startTime)/60.0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_features.to_csv(r'/data/training_data/train_features_40000_end.csv')\n",
    "test_features.to_csv(r'/data/test_data/test_features.csv')\n",
    "#y = pd.read_csv(r'/data/test_data/test_features.csv', index_col=0)\n",
    "#test_features_sorted = test_features_sorted.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_features.to_csv(r'/data/training_data/train_features_40000_end.csv')\n",
    "#test_features_sorted.to_csv(r'/data/test_data/test_features.csv')\n",
    "#y = pd.read_csv(r'/data/test_data/test_features.csv', index_col=0)\n",
    "#test_features_sorted = test_features_sorted.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#load features\n",
    "train_features_0 = pd.read_csv(r'/data/training_data/train_features_0_40000.csv', index_col = 0)\n",
    "train_features_1 = pd.read_csv(r'/data/training_data/train_features_40000_end.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = pd.concat([train_features_0, train_features_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = pd.read_csv(r'/data/test_data/test_features.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill nulls\n",
    "cols = test_features.columns.copy()\n",
    "\n",
    "cols.drop('is_grayscale')\n",
    "\n",
    "test_features = test_features[cols].fillna(test_features[cols].mean())\n",
    "\n",
    "test_features.loc[test_features['is_grayscale'].isnull(), 'is_grayscale'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional processing on feature - remove extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'pixelsx', 'pixelsy', 'size_bytes', 'r_mean', 'r_10_pct',\n",
       "       'r_25_pct', 'r_50_pct', 'r_75_pct', 'r_90_pct', 'g_mean', 'g_std',\n",
       "       'g_10_pct', 'g_25_pct', 'g_50_pct', 'g_75_pct', 'g_90_pct', 'b_mean',\n",
       "       'b_std', 'b_10_pct', 'b_25_pct', 'b_50_pct', 'b_75_pct', 'b_90_pct',\n",
       "       'h_mean', 'h_var', 's_mean', 's_std', 's_10_pct', 's_25_pct',\n",
       "       's_50_pct', 's_75_pct', 's_90_pct', 'v_mean', 'v_std', 'v_10_pct',\n",
       "       'v_25_pct', 'v_50_pct', 'v_75_pct', 'v_90_pct', 'h_cx_05_pct',\n",
       "       'h_cx_10_pct', 'h_cx_25_pct', 'h_cx_50_pct', 'h_cx_75_pct',\n",
       "       'h_cx_90_pct', 'h_cx_95_pct', 's_cx_05_pct', 's_cx_10_pct',\n",
       "       's_cx_25_pct', 's_cx_50_pct', 's_cx_75_pct', 's_cx_90_pct',\n",
       "       's_cx_95_pct', 'v_cx_05_pct', 'v_cx_10_pct', 'v_cx_25_pct',\n",
       "       'v_cx_50_pct', 'v_cx_75_pct', 'v_cx_90_pct', 'v_cx_95_pct',\n",
       "       'is_grayscale', 'r_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saved features are straight from the feature functions with no handling of nulls, etc\n",
    "# these have to be addressed prior to training/predicting\n",
    "\n",
    "#rgb_features = ['r_mean', 'r_med', 'r_std', 'g_mean', 'g_med',\n",
    "#                'g_std', 'b_mean', 'b_med', 'b_std',]\n",
    "\n",
    "#size_features =  [ 'pixelsx',\n",
    "#       'pixelsy', 'size_bytes' ]\n",
    "\n",
    "\n",
    "# take out unnecessary columns\n",
    "def removeColumns(features):\n",
    "#     feature_names = ['pixelsx', 'pixelsy', 'size_bytes',\n",
    "#                      'r_mean', 'r_med', 'r_std',\n",
    "#                      'g_mean', 'g_med', 'g_std',\n",
    "#                      'b_mean', 'b_med', 'b_std',\n",
    "#                      'h_mean', 'h_var',\n",
    "#                      's_mean', 's_med', 's_std',\n",
    "#                      'v_mean', 'v_med', 'v_std',\n",
    "#                      'is_grayscale']\n",
    "\n",
    "    #features = features[ ['filename'] + feature_names ]\n",
    "    features = features.drop(['artist', 'title', 'style', 'genre', 'date'], axis=1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = removeColumns(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'pixelsx', 'pixelsy', 'size_bytes', 'r_mean', 'r_10_pct',\n",
       "       'r_25_pct', 'r_50_pct', 'r_75_pct', 'r_90_pct', 'g_mean', 'g_std',\n",
       "       'g_10_pct', 'g_25_pct', 'g_50_pct', 'g_75_pct', 'g_90_pct', 'b_mean',\n",
       "       'b_std', 'b_10_pct', 'b_25_pct', 'b_50_pct', 'b_75_pct', 'b_90_pct',\n",
       "       'h_mean', 'h_var', 's_mean', 's_std', 's_10_pct', 's_25_pct',\n",
       "       's_50_pct', 's_75_pct', 's_90_pct', 'v_mean', 'v_std', 'v_10_pct',\n",
       "       'v_25_pct', 'v_50_pct', 'v_75_pct', 'v_90_pct', 'h_cx_05_pct',\n",
       "       'h_cx_10_pct', 'h_cx_25_pct', 'h_cx_50_pct', 'h_cx_75_pct',\n",
       "       'h_cx_90_pct', 'h_cx_95_pct', 's_cx_05_pct', 's_cx_10_pct',\n",
       "       's_cx_25_pct', 's_cx_50_pct', 's_cx_75_pct', 's_cx_90_pct',\n",
       "       's_cx_95_pct', 'v_cx_05_pct', 'v_cx_10_pct', 'v_cx_25_pct',\n",
       "       'v_cx_50_pct', 'v_cx_75_pct', 'v_cx_90_pct', 'v_cx_95_pct',\n",
       "       'is_grayscale', 'r_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature processing - add image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def addImageFeatures(features):\n",
    "    \"\"\"modifies in place\"\"\"\n",
    "    features['aspect_ratio'] = features['pixelsx']/features['pixelsy']\n",
    "    features['size_per_pixel'] = features['size_bytes']/features['pixelsx']/features['pixelsy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addImageFeatures(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addImageFeatures(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join features to pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#join pair data to image features\n",
    "\n",
    "def joinPairsToFeatures(pairs, features):\n",
    "    \n",
    "    feature_base_names = ['pixelsx', 'pixelsy', 'size_bytes', 'aspect_ratio', 'size_per_pixel',\n",
    "                     'r_mean', 'r_std',\n",
    "                     'g_mean', 'g_std',\n",
    "                     'b_mean', 'b_std',\n",
    "                     'h_mean', 'h_var',\n",
    "                     's_mean', 's_std',\n",
    "                     'v_mean', 'v_std', \n",
    "                     'is_grayscale' ]\n",
    "    \n",
    "    for dim in ['r', 'g', 'b', 's', 'v']:\n",
    "        for pct in [10, 25, 50, 75, 90]:\n",
    "            feature_base_names.append( '%s_%.2i_pct' % (dim, pct))\n",
    "            \n",
    "    for dim in ['h', 's', 'v']:\n",
    "        for pct in [5, 10, 25, 50, 75, 90, 95]:\n",
    "            feature_base_names.append( '%s_cx_%.2i_pct' % (dim, pct))\n",
    "\n",
    "    col_dict_1 = {}\n",
    "    col_dict_2 = {}\n",
    "\n",
    "    for feature in feature_base_names:\n",
    "        col_dict_1[feature] = '%s_1' % feature\n",
    "        col_dict_2[feature] = '%s_2' % feature\n",
    "\n",
    "    pairs = pairs.merge(features,\n",
    "                        left_on='image1', right_on='filename')\n",
    "    pairs.rename( columns = col_dict_1,\n",
    "                          inplace=True)\n",
    "    pairs = pairs.merge(features,\n",
    "                        left_on='image2', right_on='filename')\n",
    "    pairs.rename( columns = col_dict_2,\n",
    "                          inplace=True)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pairs = joinPairsToFeatures(train_pairs, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pairs = joinPairsToFeatures(test_pairs, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pairs get out of order after merging, so re-sort\n",
    "test_pairs = test_pairs.sort_values(by='index')\n",
    "test_pairs.set_index('index', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove nulls in training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nulls\n"
     ]
    }
   ],
   "source": [
    "# we remove the nulls after the join, could also be done before\n",
    "train_pairs = train_pairs[~train_pairs['pixelsx_1'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['pixelsx_2'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['size_bytes_1'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['size_bytes_2'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['h_mean_1'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['h_mean_2'].isnull()]\n",
    "\n",
    "#print(train_pairs.isnull().sum())\n",
    "print('%i nulls' % (train_pairs.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check no nulls in submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#print(test_pairs.isnull().sum())\n",
    "print(test_pairs.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature processing - add diff features to pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## try training on diffs instead of aboslute values\n",
    "\n",
    "def addPairFeatures(pairs):\n",
    "    diff_feature_base = [ \n",
    "                     'r_mean', 'r_std',\n",
    "                     'g_mean', 'g_std',\n",
    "                     'b_mean', 'b_std',\n",
    "                     #'h_mean', \n",
    "                     'h_var',\n",
    "                     's_mean', 's_std',\n",
    "                     'v_mean', 'v_std', ]\n",
    "\n",
    "    diff_feature_names = [ temp_feature + '_diff' for temp_feature in diff_feature_base]\n",
    "\n",
    "    for diff_feature in diff_feature_base:\n",
    "        pairs[diff_feature + '_diff'] = ( pairs[ diff_feature + '_1'] - pairs[ diff_feature + '_2'] ).abs()\n",
    "    \n",
    "    pairs['h_mean_diff'] = np.min( [ np.abs( pairs['h_mean_1'] - pairs['h_mean_2'] ),\n",
    "                                    2.0 * np.pi - np.abs( pairs['h_mean_1'] - pairs['h_mean_2'] ),\n",
    "                                   ],\n",
    "                                  axis = 0\n",
    "                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addPairFeatures(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addPairFeatures(train_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computePredictStats(y_prob, y_true, threshold = 0.5):\n",
    "    \"\"\" compute accuracy, precision, recall, negative precision, specificity, and auc roc\n",
    "        Args:\n",
    "            y_prob: array of floats from 0.0 - 1.0\n",
    "            y_true: array of booleans\n",
    "            threshold: true/false threshold value, between 0.0-1.0\n",
    "        Returns:\n",
    "            dict of classification metrics\n",
    "    \"\"\"\n",
    "    # y_pred = np.array([True, True, False, False])\n",
    "    # y_true = np.array([True, True, True, True])\n",
    "    y_pred = y_prob > threshold\n",
    "    \n",
    "    total = len(y_prob)\n",
    "    true_pos = sum( (y_pred == True) & (y_true == True) )\n",
    "    true_neg = sum( (y_pred == False) & (y_true == False) )\n",
    "    false_pos = sum( (y_pred == True) & (y_true == False) )\n",
    "    false_neg = sum( (y_pred == False ) & (y_true == True) )\n",
    "    \n",
    "    accuracy = (true_pos + true_neg) / total\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    npp = true_neg / (true_neg + false_neg) #negative prediction value\n",
    "    specificity = true_neg / (true_neg + false_pos)\n",
    "    roc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    return { 'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'npp': npp,\n",
    "            'specificity': specificity,\n",
    "            'roc': roc,\n",
    "            'true_pos': true_pos,\n",
    "            'true_neg': true_neg,\n",
    "            'false_pos': false_pos,\n",
    "            'false_neg': false_neg,\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureHelper(feature_name):\n",
    "\n",
    "    #FEATURE SET 02\n",
    "    \n",
    "    v_pct_match = re.search(\"v_\\d*_pct\", feature_name)\n",
    "    s_pct_match = re.search(\"s_\\d*_pct\", feature_name)\n",
    "    \n",
    "    h_cx_pct_match = re.search(\"h_cx_\\d*_pct\", feature_name)\n",
    "    s_cx_pct_match = re.search(\"s_cx_\\d*_pct\", feature_name)\n",
    "    v_cx_pct_match = re.search(\"v_cx_\\d*_pct\", feature_name)\n",
    "    \n",
    "    include = ( 'foldNum' in feature_name\n",
    "               or 'pixelsx' in feature_name\n",
    "               or 'pixelsy' in feature_name\n",
    "               or 'aspect_ratio' in feature_name\n",
    "               or 'size_bytes' in feature_name\n",
    "               or 'size_per_pixel' in feature_name\n",
    "               \n",
    "               #or 'r_' in feature_name\n",
    "               #or 'g_' in feature_name\n",
    "               #or 'b_' in feature_name\n",
    "               \n",
    "               or 'h_var_diff' in feature_name\n",
    "               \n",
    "               or 's_mean_diff' in feature_name\n",
    "               or 's_std_diff' in feature_name\n",
    "               \n",
    "               or 'v_mean_diff' in feature_name\n",
    "               or 'v_std_diff' in feature_name\n",
    "               \n",
    "               or 's_10_pct' in feature_name\n",
    "               or 's_50_pct' in feature_name\n",
    "               or 's_90_pct' in feature_name\n",
    "               \n",
    "               or 'v_10_pct' in feature_name\n",
    "               or 'v_50_pct' in feature_name\n",
    "               or 'v_90_pct' in feature_name\n",
    "               \n",
    "               #or 'h_cx_10_pct' in feature_name\n",
    "               #or 'h_cx_50_pct' in feature_name\n",
    "               #or 'h_cx_90_pct' in feature_name\n",
    "               #or 'h_cx_95_pct' in feature_name\n",
    "               \n",
    "               or 's_cx_10_pct' in feature_name\n",
    "               or 's_cx_50_pct' in feature_name\n",
    "               or 's_cx_90_pct' in feature_name\n",
    "               or 's_cx_95_pct' in feature_name\n",
    "               \n",
    "               or 'v_cx_10_pct' in feature_name\n",
    "               or 'v_cx_50_pct' in feature_name\n",
    "               or 'v_cx_90_pct' in feature_name\n",
    "               or 's_cx_95_pct' in feature_name\n",
    "               #or v_pct_match is not None\n",
    "               #or s_pct_match is not None\n",
    "               \n",
    "               #or h_cx_pct_match is not None\n",
    "               #or s_cx_pct_match is not None\n",
    "               #or v_cx_pct_match is not None\n",
    "              )\n",
    "    \n",
    "    if include:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featureHelper(feature_name):\n",
    "\n",
    "    v_pct_match = re.search(\"v_\\d*_pct\", feature_name)\n",
    "    s_pct_match = re.search(\"s_\\d*_pct\", feature_name)\n",
    "    \n",
    "    h_cx_pct_match = re.search(\"h_cx_\\d*_pct\", feature_name)\n",
    "    s_cx_pct_match = re.search(\"s_cx_\\d*_pct\", feature_name)\n",
    "    v_cx_pct_match = re.search(\"v_cx_\\d*_pct\", feature_name)\n",
    "    \n",
    "    include = ( 'foldNum' in feature_name\n",
    "               or 'pixelsx' in feature_name\n",
    "               or 'pixelsy' in feature_name\n",
    "               or 'aspect_ratio' in feature_name\n",
    "               or 'size_bytes' in feature_name\n",
    "               or 'size_per_pixel' in feature_name\n",
    "               \n",
    "               #or 'r_' in feature_name\n",
    "               #or 'g_' in feature_name\n",
    "               #or 'b_' in feature_name\n",
    "               \n",
    "               or 'h_var_diff' in feature_name\n",
    "               \n",
    "               or 's_mean_diff' in feature_name\n",
    "               or 's_std_diff' in feature_name\n",
    "               \n",
    "               or 'v_mean_diff' in feature_name\n",
    "               or 'v_std_diff' in feature_name\n",
    "               \n",
    "               or v_pct_match is not None\n",
    "               or s_pct_match is not None\n",
    "               \n",
    "               or h_cx_pct_match is not None\n",
    "               or s_cx_pct_match is not None\n",
    "               or v_cx_pct_match is not None\n",
    "              )\n",
    "    \n",
    "    if include:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for foldNum, train_pairs in enumerate(train_pairs_list):\n",
    "#    train_pairs_list[foldNum] = train_pairs.iloc[np.random.permutation(len(train_pairs))]\n",
    "\n",
    "# get list of X columns, they are ones with '_1' or '_2' in the name\n",
    "allCols = train_pairs.columns\n",
    "isX = list(map(featureHelper, allCols))\n",
    "X_columns = allCols[isX]\n",
    "\n",
    "train_X = train_pairs[X_columns]\n",
    "train_Y = train_pairs[['sameArtist', 'foldNum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allCols = test_pairs.columns\n",
    "isX = list(map(featureHelper, allCols))\n",
    "X_columns = allCols[isX]\n",
    "\n",
    "test_X = test_pairs[X_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(test_X).sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kFoldCV(train_X, train_Y, k, numFoldsToTest):\n",
    "    \"\"\" Perform k-fold cross validation. Will modify train_pairs (shuffle rows)\n",
    "        Args:\n",
    "            train_pairs: Dataframe containing training image pairs with features. Should have no nulls.\n",
    "            k: k, at least 2\n",
    "            numFoldsToTest: how many folds to actually test, at most k\n",
    "        Returns:\n",
    "            dataframe with CV results\n",
    "    \"\"\"\n",
    "    numFoldsToTest = min(k, numFoldsToTest)\n",
    "    \n",
    "    # shuffle rows\n",
    "    #train_pairs = train_pairs.iloc[np.random.permutation(len(train_pairs))]\n",
    "\n",
    "    # get list of X columns, they are ones with '_1' or '_2' in the name\n",
    "    #allCols = train_pairs.columns\n",
    "    #isX = list(map(lambda x: ('_1' in x) or ('_2' in x), allCols))\n",
    "    #X_columns = allCols[isX]\n",
    "    \n",
    "    # split X and Y data\n",
    "    #CV_X = train_pairs[X_columns]\n",
    "    #CV_Y = train_pairs['sameArtist']\n",
    "    \n",
    "    # define which indices belong to each fold\n",
    "    foldLocsList = [] #list of Index objects, one for each fold\n",
    "    \n",
    "    #foldSize = int(len(train_X)/k)\n",
    "    #    \n",
    "    #for foldNum in range(k):\n",
    "    #    if foldNum == k-1:\n",
    "    #        foldLocsList.append( train_X.index[foldNum*foldSize : len(train_X)] )\n",
    "    #    else:\n",
    "    #        foldLocsList.append( train_X.index[foldNum*foldSize : (foldNum+1)*(foldSize) ] )\n",
    "    \n",
    "    # set up dataframe for collecting results\n",
    "    columnsList = list(itertools.product(('train', 'test'), ('roc', 'precision', 'recall', 'npp', 'specificity')))\n",
    "    results = pd.DataFrame(index = range(numFoldsToTest), columns = pd.MultiIndex.from_tuples(columnsList))\n",
    "    \n",
    "    # test each fold\n",
    "    for testFold in range(numFoldsToTest):\n",
    "        \n",
    "        CV_training_folds = np.arange(k)\n",
    "        CV_training_folds = np.delete(CV_training_folds, np.where(CV_training_folds == testFold))\n",
    "\n",
    "        # set up Xs\n",
    "        CV_train_X = train_X[ train_X['foldNum'].isin(CV_training_folds) ]   \n",
    "        CV_test_X = train_X[ train_X['foldNum'] == testFold ]   \n",
    "        \n",
    "        CV_train_X = CV_train_X.drop(['foldNum'], axis=1)\n",
    "        CV_test_X = CV_test_X.drop(['foldNum'], axis=1)\n",
    "\n",
    "        # set up Ys\n",
    "        CV_train_Y = train_Y[train_X['foldNum'].isin(CV_training_folds) ]\n",
    "        CV_test_Y = train_Y[ train_Y['foldNum'] == testFold ]   \n",
    "        \n",
    "        CV_train_Y = CV_train_Y['sameArtist']\n",
    "        CV_test_Y = CV_test_Y['sameArtist']\n",
    "\n",
    "        shuffleInds = np.random.permutation(len(CV_train_X))\n",
    "        CV_train_X = CV_train_X.iloc[shuffleInds]\n",
    "        CV_train_Y = CV_train_Y.iloc[shuffleInds]\n",
    "        \n",
    "        #CV_train_X = CV_train_X.iloc[0:300000]\n",
    "        #CV_train_Y = CV_train_Y.iloc[0:300000]\n",
    "        \n",
    "        # fit model\n",
    "        n_jobs = max( multiprocessing.cpu_count() - 10, 1)\n",
    "        clf = RandomForestClassifier(n_estimators=500, n_jobs=n_jobs, min_samples_split=8, oob_score = True)\n",
    "        #clf = ExtraTreesClassifier(n_estimators=300, n_jobs=n_jobs, min_samples_split=5)\n",
    "        #clf = GradientBoostingClassifier(n_estimators = 5)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        print('starting fit with %s jobs.. ' % n_jobs, end='')\n",
    "\n",
    "        clf.fit(CV_train_X, CV_train_Y)\n",
    "\n",
    "        end = time.time()\n",
    "                               \n",
    "        print('total training time: %s' % (end - start) )\n",
    "\n",
    "        # get in-sample and out-of-sample results\n",
    "                               \n",
    "        pred_train = clf.predict_proba(CV_train_X)[:,1]\n",
    "        train_results = computePredictStats( pred_train, CV_train_Y)\n",
    "\n",
    "        pred_test = clf.predict_proba(CV_test_X)[:,1]\n",
    "        test_results = computePredictStats( pred_test, CV_test_Y)\n",
    "       \n",
    "        for stat in ('roc', 'accuracy', 'precision', 'recall', 'npp', 'specificity'):\n",
    "            results.loc[testFold, ('train', stat)] = train_results[stat]\n",
    "            results.loc[testFold, ('test', stat)] = test_results[stat]\n",
    "        \n",
    "        #results.loc[testFold, ('train', 'oob')] = clf.oob_score_\n",
    "        \n",
    "        columnToImportance = list(zip(CV_train_X.columns, clf.feature_importances_))\n",
    "        columnToImportance = sorted(columnToImportance, key=lambda x: x[1], reverse=True)\n",
    "        importanceDF = pd.DataFrame(data = columnToImportance)\n",
    "            \n",
    "    return results, importanceDF    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run k-fold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fit with 54 jobs.. total training time: 484.06285214424133\n",
      "starting fit with 54 jobs.. total training time: 472.72594022750854\n",
      "  train      test     train      test\n",
      "    roc       roc  accuracy  accuracy\n",
      "0     1  0.752695  0.999759  0.680868\n",
      "1     1  0.739002  0.999766  0.671421\n",
      "train  roc         1.000000\n",
      "test   roc         0.745849\n",
      "train  accuracy    0.999762\n",
      "test   accuracy    0.676145\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "numFoldsToTest = 2\n",
    "\n",
    "results, importance = kFoldCV(train_X, train_Y, k, numFoldsToTest)\n",
    "\n",
    "#print(results[ [('train', 'roc'), ('test', 'roc'), ('train', 'oob'),  ('test', 'accuracy')]])\n",
    "#print(results[ [('train', 'roc'), ('test', 'roc'), ('train', 'oob'),  ('test', 'accuracy')]].mean())\n",
    "print(results[ [('train', 'roc'), ('test', 'roc'), ('train', 'accuracy'), ('test', 'accuracy')]])\n",
    "print(results[ [('train', 'roc'), ('test', 'roc'), ('train', 'accuracy'), ('test', 'accuracy')]].mean())\n",
    "#print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0         1\n",
      "0        v_mean_diff  0.042899\n",
      "1         h_var_diff  0.039640\n",
      "2         s_std_diff  0.031706\n",
      "3        s_mean_diff  0.030775\n",
      "4          pixelsy_1  0.028729\n",
      "5         v_std_diff  0.028493\n",
      "6          pixelsx_1  0.027658\n",
      "7          pixelsy_2  0.026942\n",
      "8   size_per_pixel_1  0.026475\n",
      "9   size_per_pixel_2  0.026139\n",
      "10         pixelsx_2  0.025563\n",
      "11      size_bytes_1  0.025357\n",
      "12    aspect_ratio_1  0.024669\n",
      "13     v_cx_90_pct_1  0.024661\n",
      "14    aspect_ratio_2  0.024534\n",
      "15      size_bytes_2  0.024482\n",
      "16     v_cx_50_pct_1  0.024383\n",
      "17     v_cx_90_pct_2  0.024289\n",
      "18     v_cx_50_pct_2  0.023707\n",
      "19     v_cx_10_pct_1  0.023462\n",
      "20     v_cx_10_pct_2  0.022598\n",
      "21        v_50_pct_1  0.022428\n",
      "22        v_50_pct_2  0.021881\n",
      "23     s_cx_50_pct_1  0.021875\n",
      "24        v_10_pct_1  0.021846\n",
      "25        s_50_pct_1  0.021746\n",
      "26        v_90_pct_1  0.021652\n",
      "27        s_10_pct_1  0.021470\n",
      "28        v_10_pct_2  0.021450\n",
      "29        s_90_pct_1  0.021390\n",
      "30        s_50_pct_2  0.021331\n",
      "31        v_90_pct_2  0.021213\n",
      "32        s_90_pct_2  0.021147\n",
      "33     s_cx_95_pct_1  0.020937\n",
      "34     s_cx_90_pct_1  0.020877\n",
      "35        s_10_pct_2  0.020785\n",
      "36     s_cx_50_pct_2  0.020630\n",
      "37     s_cx_10_pct_1  0.020341\n",
      "38     s_cx_95_pct_2  0.020273\n",
      "39     s_cx_90_pct_2  0.020000\n",
      "40     s_cx_10_pct_2  0.019571\n"
     ]
    }
   ],
   "source": [
    "#print(results[ [('train', 'roc'), ('test', 'roc'), ('train', 'accuracy'), ('test', 'accuracy')]])\n",
    "#print(results[ [('train', 'roc'), ('test', 'roc'), ('train', 'accuracy'), ('test', 'accuracy')]].mean())\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_Y_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1997446"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fit\n",
      "total training time: 318.94555592536926\n"
     ]
    }
   ],
   "source": [
    "n_jobs = max( multiprocessing.cpu_count() - 2, 1)\n",
    "clf = RandomForestClassifier(n_estimators=500, min_samples_split=8, n_jobs=n_jobs)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print('starting fit')\n",
    "#excluding the patient_id column from the fit and prediction\n",
    "\n",
    "shuffleInds = np.random.permutation(len(train_X))\n",
    "train_X = train_X.iloc[shuffleInds]\n",
    "train_Y = train_Y.iloc[shuffleInds]\n",
    "\n",
    "full_train_X = train_X.iloc[shuffleInds].drop(['foldNum'], axis=1).iloc[0:2000000]\n",
    "full_train_Y = train_Y.iloc[shuffleInds]['sameArtist'].iloc[0:2000000]\n",
    "\n",
    "clf.fit(full_train_X, full_train_Y)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('total training time: %s' % (end - start) )\n",
    "\n",
    "#columnsList = list(itertools.product(('train', 'test'), ('roc', 'precision', 'recall', 'npp', 'specificity')))\n",
    "#results = pd.DataFrame(index = range(numFoldsToTest), columns = pd.MultiIndex.from_tuples(columnsList))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### make sure real modle works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testFold = 0\n",
    "\n",
    "CV_test_X = train_X[ train_X['foldNum'] == testFold ]   \n",
    "CV_test_Y = train_Y[ train_Y['foldNum'] == testFold ] \n",
    "\n",
    "CV_test_X = CV_test_X.drop(['foldNum'], axis=1)\n",
    "CV_test_Y = CV_test_Y['sameArtist'] \n",
    "\n",
    "pred_test = clf.predict_proba(CV_test_X)[:,1]\n",
    "test_results = computePredictStats( pred_test, CV_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'specificity': 0.99968876126985406, 'roc': 0.99999963828481087, 'accuracy': 0.99975084561488281, 'npp': 0.99981423744471054, 'false_pos': 62, 'true_pos': 198103, 'true_neg': 199142, 'precision': 0.99968712941235838, 'false_neg': 37, 'recall': 0.99981326334914711}\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-c3528f20e056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submission_02.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "##save model\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "with open('submission_02.pkl', 'wb') as fid:\n",
    "    pickle.dump(clf, fid) \n",
    "\n",
    "end = time.clock()\n",
    "print('total saving time: %s' % (end - start) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-80e98a8ae7ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# load it again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submission_02.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# load it again\n",
    "with open('submission_02.pkl', 'rb') as fid:\n",
    "    clf = pickle.load(fid)\n",
    "\n",
    "end = time.clock()\n",
    "print('total loading time: %s' % (end - start) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting predictions\n",
      "total predictions time: 200.39063477516174\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "print('starting predictions')\n",
    "#excluding the patient_id column from the fit and prediction\n",
    "\n",
    "test_predictions_0 = clf.predict_proba(test_X[0:5000000])[:,1]\n",
    "test_predictions_1 = clf.predict_proba(test_X[5000000:10000000])[:,1]\n",
    "test_predictions_2 = clf.predict_proba(test_X[10000000:15000000])[:,1]\n",
    "test_predictions_3 = clf.predict_proba(test_X[15000000:20000000])[:,1]\n",
    "test_predictions_4 = clf.predict_proba(test_X[20000000:])[:,1]\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('total predictions time: %s' % (end - start) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## prepare submission\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(index = test_pairs.index)\n",
    "submission['sameArtist'] = test_predictions\n",
    "submission.to_csv('/data/notebook/notebooks/my_submission_02.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(index = test_pairs.index)\n",
    "submission['sameArtist'] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21916047"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21916047"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
