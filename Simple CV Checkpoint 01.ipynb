{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "#from matplotlib import pyplot as plt\n",
    "\n",
    "#import networkx as nx\n",
    "#from networkx.utils import cuthill_mckee_ordering\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_pairs(train_info):\n",
    "    artists = train_info.artist.unique()\n",
    "\n",
    "    n = train_info.groupby('artist').size()\n",
    "    n = (2*n**2).sum() \n",
    "    t = pd.DataFrame(np.zeros((n, 4)), columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for artist in artists:\n",
    "\n",
    "        #artist info is Ax2 matrix of artist, filename\n",
    "        artistInfo = train_info[train_info.artist==artist][['artist', 'filename']].values\n",
    "        use = train_info[train_info.artist != artist ].index.values\n",
    "        np.random.shuffle(use)\n",
    "        #nm = np.min([a.shape[0]**2, train_info[train_info.artist != m].shape[0] ])\n",
    "        numExamples = np.min([len(artistInfo)**2, sum(train_info.artist != artist) ])\n",
    "        use = use[0:numExamples]\n",
    "        \n",
    "        #diffArtistInfo a Bx2 matrix of artist, filename\n",
    "        diffArtistInfo = train_info[train_info.artist!=artist][['artist', 'filename']].ix[use, :].values\n",
    "\n",
    "        \n",
    "        toAdd_SameArtist = pd.DataFrame(np.concatenate([  np.repeat(artistInfo[:, 0], len(artistInfo)).reshape((-1,1)), #artist\n",
    "                                            np.repeat(artistInfo[:, 1],\n",
    "                                            artistInfo.shape[0]).reshape((-1,1)),\n",
    "                                            np.tile(artistInfo, (artistInfo.shape[0], 1))],\n",
    "                                         axis=1),\n",
    "                          columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "        toAdd_SameArtist = toAdd_SameArtist.loc[0:numExamples, :]\n",
    "        toAdd_DiffArtist = pd.DataFrame(np.concatenate([np.tile(artistInfo,\n",
    "                                                  (len(artistInfo), 1))[0:diffArtistInfo.shape[0], :],\n",
    "                                          diffArtistInfo], axis=1),\n",
    "                          columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "        toAdd_DiffArtist = toAdd_DiffArtist.loc[0:numExamples, :]\n",
    "        \n",
    "        #print(j, i, a2.shape[0], b2.shape[0])\n",
    "        #print(b2)\n",
    "        t.iloc[i:i+len(toAdd_SameArtist), :] = toAdd_SameArtist\n",
    "        t.iloc[i+len(toAdd_SameArtist):i+len(toAdd_SameArtist)+len(toAdd_DiffArtist), :] = toAdd_DiffArtist.values\n",
    "        \n",
    "        i += len(toAdd_SameArtist) + len(toAdd_DiffArtist)\n",
    "        j += 1\n",
    "        if j%100==0:\n",
    "            print('finished %s of %s artists'%(j, len(artists)))\n",
    "\n",
    "    print('make pairs completed')\n",
    "    t = t[~t.image2.isin([np.nan, 0])]\n",
    "    return t[t.image1 > t.image2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Image Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_info(test_info, mydir):\n",
    "    if mydir == r'/data/test_data/test':\n",
    "        images = list(set(list(test_info.image1.unique()) + list(test_info.image2.unique())))\n",
    "        info = pd.DataFrame(np.array(images).reshape((-1, 1)), columns = ['filename'])\n",
    "    else:\n",
    "        info = test_info\n",
    "    \n",
    "    info['pixelsx'] = np.nan\n",
    "    info['pixelsy'] = np.nan\n",
    "    info['size_bytes'] = np.nan\n",
    "    \n",
    "    \n",
    "    for ind, i in enumerate(info.index.values):\n",
    "        try:\n",
    "            im = Image.open(mydir+'/'+info.loc[i, 'filename'])\n",
    "            info.loc[i, 'pixelsx'], info.loc[i, 'pixelsy'] = im.size\n",
    "            #im = cv2.imread(dir+'/'+info.loc[i, 'new_filename'])\n",
    "            #info.loc[i, 'pixelsx'], info.loc[i, 'pixelsy'] = im.shape[0:2]\n",
    "            info.loc[i, 'size_bytes'] = os.path.getsize(mydir+'/'+info.loc[i, 'filename']) \n",
    "            if ind%10000==0:\n",
    "                print('finished %s of %s'%(ind, len(info)))\n",
    "        except:\n",
    "            print(mydir+'/'+info.loc[i, 'filename'])\n",
    "        \n",
    "    return info.rename(columns={'filename' : 'new_filename'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x_train, y_train, x_cv, y_cv = prep_data([train_info, None], 'cv')    \n",
    "#x_test, y_test = prep_data([None, submission_info], 'test')    \n",
    "def prep_data(input_info, split):\n",
    "    orig_info = input_info[0]\n",
    "    data = input_info[1]\n",
    "    \n",
    "    if split=='cv':\n",
    "        artists = info.artist.unique()\n",
    "        np.random.shuffle(artists)\n",
    "        \n",
    "        info = get_image_info(orig_info, r'/data/training_data/train')\n",
    "        info['bytes_per_pixel'] = 1.0*info['size_bytes']/(info['pixelsx']*info['pixelsy'])\n",
    "        info['aspect_ratio'] = 1.0*info['pixelsx']/info['pixelsy']\n",
    "        train_artists = artists[0:int(0.8*len(artists))]\n",
    "        test_artists = artists[int(0.8*len(artists)):]    \n",
    "        \n",
    "        train = make_pairs(info[info.artist.isin(train_artists)])\n",
    "        test = make_pairs(info[info.artist.isin(test_artists)])\n",
    "        train['in_train'] = True\n",
    "        test['in_train'] = False\n",
    "        data = train.append(test)\n",
    "        data['sameArtist'] = data['artist1'] == data['artist2']\n",
    "        \n",
    "    if split=='test':\n",
    "\n",
    "        info = get_image_info(data, r'/data/test_data/test')\n",
    "        info['bytes_per_pixel'] = 1.0*info['size_bytes']/(info['pixelsx']*info['pixelsy'])\n",
    "        info['aspect_ratio'] = 1.0*info['pixelsx']/info['pixelsy']\n",
    "        \n",
    "        data['in_train'] = False\n",
    "    \n",
    "        if 'artist1' in data.columns:\n",
    "            data['sameArtist'] = data['artist1'] == data['artist2']\n",
    "\n",
    "    \n",
    "    data2 = pd.merge(data, info[['new_filename', 'pixelsx', 'pixelsy', 'size_bytes', 'bytes_per_pixel', 'aspect_ratio']], how='left', left_on='image1', right_on='new_filename')\n",
    "    data2.drop('new_filename', 1, inplace=True)\n",
    "    \n",
    "    data2 = pd.merge(data2, info[['new_filename', 'pixelsx', 'pixelsy', 'size_bytes', 'bytes_per_pixel', 'aspect_ratio']], how='left', left_on='image2', right_on='new_filename')\n",
    "    data2.drop('new_filename', 1, inplace=True)\n",
    "    \n",
    "    x_train = data2[data2.in_train==True][['pixelsx_x', 'pixelsy_x', 'size_bytes_x', 'bytes_per_pixel_x', 'aspect_ratio_x', 'pixelsx_y', 'pixelsy_y', 'size_bytes_y', 'bytes_per_pixel_y', 'aspect_ratio_y']].values\n",
    "    x_test = data2[data2.in_train==False][['pixelsx_x', 'pixelsy_x', 'size_bytes_x', 'bytes_per_pixel_x', 'aspect_ratio_x', 'pixelsx_y', 'pixelsy_y', 'size_bytes_y', 'bytes_per_pixel_y', 'aspect_ratio_y']].values\n",
    "    \n",
    "    \n",
    "    if 'artist1' in data.columns: \n",
    "        y_train = data2[data2.in_train==True]['sameArtist'].values\n",
    "        y_test = data2[data2.in_train==False]['sameArtist'].values\n",
    "    else:\n",
    "        y_test = None    \n",
    "    \n",
    "    if split=='cv':        \n",
    "        return x_train, y_train, x_test, y_test  \n",
    "    if split=='test':\n",
    "        return x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_classifier(x_train, y_train, x_cv, y_cv):    \n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    \n",
    "    #clf = xgb.XGBClassifier(n_estimators=10000, learning_rate=0.025, max_depth=4)\n",
    "    print('starting fit')\n",
    "    #excluding the patient_id column from the fit and prediction\n",
    "    clf.fit(x_train[::5], y_train[::5])\n",
    "    print('starting pred')\n",
    "    \n",
    "    y_pred = np.zeros(x_cv.shape[0])\n",
    "    for i in xrange(4):\n",
    "        y_pred[i::4] = clf.predict_proba(x_cv[i::4])[:,1] \n",
    "    \n",
    "    if not y_cv is None:\n",
    "        print(roc_auc_score(y_cv, y_pred))\n",
    "    \n",
    "    return y_pred, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_submission():\n",
    "    train_info = pd.read_csv(r'/data/training_data/train_info.csv')\n",
    "    submission_info = pd.read_csv(r'/data/test_data/submission_info.csv')\n",
    "    print('prepping training and cv data')\n",
    "    x_train, y_train, x_cv, y_cv = prep_data([train_info, None], 'cv')    \n",
    "    print('prepping test data')\n",
    "    x_test, y_test = prep_data([None, submission_info], 'test')    \n",
    "    \n",
    "    print('starting classifier')\n",
    "    y_pred, clf = train_classifier(x_train, y_train, x_test, y_test) \n",
    "\n",
    "    submission = submission_info[['index']]\n",
    "    submission['sameArtist'] = y_pred\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (107327830 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (99962094 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0 of 79433\n",
      "finished 500 of 79433\n",
      "finished 1000 of 79433\n",
      "finished 1500 of 79433\n",
      "finished 2000 of 79433\n",
      "finished 2500 of 79433\n",
      "finished 3000 of 79433\n",
      "finished 3500 of 79433\n",
      "finished 4000 of 79433\n",
      "finished 4500 of 79433\n",
      "finished 5000 of 79433\n",
      "finished 5500 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (669000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 6000 of 79433\n",
      "finished 6500 of 79433\n",
      "finished 7000 of 79433\n",
      "finished 7500 of 79433\n",
      "finished 8000 of 79433\n",
      "finished 8500 of 79433\n",
      "finished 9000 of 79433\n",
      "finished 9500 of 79433\n",
      "finished 10000 of 79433\n",
      "finished 10500 of 79433\n",
      "finished 11000 of 79433\n",
      "finished 11500 of 79433\n",
      "finished 12000 of 79433\n",
      "finished 12500 of 79433\n",
      "finished 13000 of 79433\n",
      "finished 13500 of 79433\n",
      "finished 14000 of 79433\n",
      "finished 14500 of 79433\n",
      "finished 15000 of 79433\n",
      "finished 15500 of 79433\n",
      "finished 16000 of 79433\n",
      "finished 16500 of 79433\n",
      "finished 17000 of 79433\n",
      "finished 17500 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (888150000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 18000 of 79433\n",
      "finished 18500 of 79433\n",
      "finished 19000 of 79433\n",
      "finished 19500 of 79433\n",
      "finished 20000 of 79433\n",
      "finished 20500 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (94435468 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 21000 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (698700000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 21500 of 79433\n",
      "finished 22000 of 79433\n",
      "finished 22500 of 79433\n",
      "finished 23000 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (131790400 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 23500 of 79433\n",
      "finished 24000 of 79433\n",
      "finished 24500 of 79433\n",
      "finished 25000 of 79433\n",
      "finished 25500 of 79433\n",
      "finished 26000 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (680730000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 26500 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (636480000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 27000 of 79433\n",
      "finished 27500 of 79433\n",
      "finished 28000 of 79433\n",
      "finished 28500 of 79433\n",
      "finished 29000 of 79433\n",
      "finished 29500 of 79433\n",
      "finished 30000 of 79433\n",
      "finished 30500 of 79433\n",
      "finished 31000 of 79433\n",
      "finished 31500 of 79433\n",
      "finished 32000 of 79433\n",
      "finished 32500 of 79433\n",
      "/data/training_data/train/42359.jpg\n",
      "finished 33000 of 79433\n",
      "finished 33500 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (145486286 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 34000 of 79433\n",
      "finished 34500 of 79433\n",
      "finished 35000 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (95799284 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 35500 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (129097476 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (129086580 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 36000 of 79433\n",
      "finished 36500 of 79433\n",
      "finished 37000 of 79433\n",
      "finished 37500 of 79433\n",
      "finished 38000 of 79433\n",
      "finished 38500 of 79433\n",
      "finished 39000 of 79433\n",
      "finished 39500 of 79433\n",
      "finished 40000 of 79433\n",
      "finished 40500 of 79433\n",
      "finished 41000 of 79433\n",
      "finished 41500 of 79433\n",
      "finished 42000 of 79433\n",
      "finished 42500 of 79433\n",
      "finished 43000 of 79433\n",
      "finished 43500 of 79433\n",
      "finished 44000 of 79433\n",
      "finished 44500 of 79433\n",
      "finished 45000 of 79433\n",
      "finished 45500 of 79433\n",
      "finished 46000 of 79433\n",
      "finished 46500 of 79433\n",
      "finished 47000 of 79433\n",
      "finished 47500 of 79433\n",
      "finished 48000 of 79433\n",
      "finished 48500 of 79433\n",
      "finished 49000 of 79433\n",
      "finished 49500 of 79433\n",
      "finished 50000 of 79433\n",
      "finished 50500 of 79433\n",
      "finished 51000 of 79433\n",
      "finished 51500 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (283327979 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 52000 of 79433\n",
      "finished 52500 of 79433\n",
      "finished 53000 of 79433\n",
      "finished 53500 of 79433\n",
      "finished 54000 of 79433\n",
      "finished 54500 of 79433\n",
      "finished 55000 of 79433\n",
      "finished 55500 of 79433\n",
      "finished 56000 of 79433\n",
      "finished 56500 of 79433\n",
      "finished 57000 of 79433\n",
      "finished 57500 of 79433\n",
      "finished 58000 of 79433\n",
      "finished 58500 of 79433\n",
      "finished 59000 of 79433\n",
      "finished 59500 of 79433\n",
      "finished 60000 of 79433\n",
      "finished 60500 of 79433\n",
      "finished 61000 of 79433\n",
      "finished 61500 of 79433\n",
      "finished 62000 of 79433\n",
      "finished 62500 of 79433\n",
      "finished 63000 of 79433\n",
      "finished 63500 of 79433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (746700000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 64000 of 79433\n",
      "finished 64500 of 79433\n",
      "finished 65000 of 79433\n",
      "finished 65500 of 79433\n",
      "finished 66000 of 79433\n",
      "finished 66500 of 79433\n",
      "finished 67000 of 79433\n",
      "finished 67500 of 79433\n",
      "finished 68000 of 79433\n",
      "finished 68500 of 79433\n",
      "finished 69000 of 79433\n",
      "finished 69500 of 79433\n",
      "finished 70000 of 79433\n",
      "finished 70500 of 79433\n",
      "finished 71000 of 79433\n",
      "finished 71500 of 79433\n",
      "finished 72000 of 79433\n",
      "finished 72500 of 79433\n",
      "finished 73000 of 79433\n",
      "finished 73500 of 79433\n",
      "finished 74000 of 79433\n",
      "finished 74500 of 79433\n",
      "finished 75000 of 79433\n",
      "finished 75500 of 79433\n",
      "finished 76000 of 79433\n",
      "finished 76500 of 79433\n",
      "finished 77000 of 79433\n",
      "finished 77500 of 79433\n",
      "finished 78000 of 79433\n",
      "finished 78500 of 79433\n",
      "finished 79000 of 79433\n"
     ]
    }
   ],
   "source": [
    "#load training info\n",
    "train_image_info = pd.read_csv(r'/data/training_data/train_info.csv')\n",
    "submission_info = pd.read_csv(r'/data/test_data/submission_info.csv')\n",
    "\n",
    "#make training pairs\n",
    "#train_pairs = make_pairs(train_info)\n",
    "#train_pairs[ 'sameArtist' ] = train_pairs[ 'artist1' ]== train_pairs[ 'artist2' ]\n",
    "\n",
    "#save as csv\n",
    "#train_pairs.to_csv(r'/data/training_data/train_pairs.csv')\n",
    "\n",
    "#load pairs\n",
    "train_pairs = pd.read_csv(r'/data/training_data/train_pairs.csv', index_col = 0)\n",
    "\n",
    "#get raw training data features\n",
    "# raw_train_image_info = get_image_info(train_image_info, r'/data/training_data/train')\n",
    "# raw_train_image_info['bytes_per_pixel'] =CV_all_image_info['size_bytes']/(CV_all_image_info['pixelsx']*CV_all_image_info['pixelsy'])\n",
    "# raw_train_image_info['aspect_ratio'] = CV_all_image_info['pixelsx']/CV_all_image_info['pixelsy']\n",
    "\n",
    "#save raw_train_image_info\n",
    "#raw_train_image_info.to_csv(r'/data/training_data/raw_train_image_info.csv')\n",
    "\n",
    "#load raw_train_image_info\n",
    "raw_train_image_info = pd.read_csv(r'/data/training_data/raw_train_image_info.csv', index_col = 0)\n",
    "\n",
    "\n",
    "#join pair data to image features\n",
    "raw_train_trimmed_image_info = raw_train_image_info[['new_filename',\n",
    "                                                      'pixelsx',\n",
    "                                                      'pixelsy',\n",
    "                                                      'bytes_per_pixel',\n",
    "                                                      'aspect_ratio']]\n",
    "train_pairs = train_pairs.merge(raw_train_trimmed_image_info,\n",
    "                                left_on='image1', right_on='new_filename')\n",
    "train_pairs.rename( columns = {'pixelsx': 'pixelsx_1',\n",
    "                    'pixelsy': 'pixelsy_1',\n",
    "                    'bytes_per_pixel' : 'bytes_per_pixel_1',\n",
    "                    'aspect_ratio':'aspect_ratio_1'},\n",
    "                      inplace=True)\n",
    "train_pairs = train_pairs.merge(raw_train_trimmed_image_info,\n",
    "                                left_on='image2', right_on='new_filename')\n",
    "train_pairs.rename( columns = {'pixelsx': 'pixelsx_2',\n",
    "                    'pixelsy': 'pixelsy_2',\n",
    "                    'bytes_per_pixel' : 'bytes_per_pixel_2',\n",
    "                    'aspect_ratio':'aspect_ratio_2'},\n",
    "                      inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80/20 CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### perform 80/20 cross-validation\n",
    "\n",
    "# declare X columns\n",
    "base_columns = [ 'pixelsx',\n",
    "            'pixelsy',\n",
    "            'bytes_per_pixel',\n",
    "            'aspect_ratio']\n",
    "\n",
    "X_columns = [ col+'_1' for col in base_columns] + [ col+'_2' for col in base_columns]\n",
    "\n",
    "# shuffle rows\n",
    "train_pairs = train_pairs.iloc[np.random.permutation(len(train_pairs))]\n",
    "\n",
    "#split pair data into train and test\n",
    "foldSize = int(len(train_pairs)/5)\n",
    "\n",
    "CV_pairs_train = train_pairs.iloc[0:4*foldSize]\n",
    "CV_pairs_test = train_pairs.iloc[4*foldSize:len(train_pairs)]\n",
    "\n",
    "#set up Xs\n",
    "CV_train_X = CV_pairs_train[X_columns]\n",
    "CV_test_X = CV_pairs_test[X_columns]\n",
    "\n",
    "#set up Ys\n",
    "CV_train_Y = CV_pairs_train['sameArtist']\n",
    "CV_test_Y = CV_pairs_test['sameArtist']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pixelsx_1', 'pixelsy_1', 'bytes_per_pixel_1', 'aspect_ratio_1',\n",
       "       'pixelsx_2', 'pixelsy_2', 'bytes_per_pixel_2', 'aspect_ratio_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixelsx_x',\n",
       " 'pixelsy_x',\n",
       " 'bytes_per_pixel_x',\n",
       " 'aspect_ratio_x',\n",
       " 'pixelsx_y',\n",
       " 'pixelsy_y',\n",
       " 'bytes_per_pixel_y',\n",
       " 'aspect_ratio_y']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### perform 5-fold cross validation\n",
    "\n",
    "# shuffle rows\n",
    "# train_pairs = train_pairs.iloc[np.random.permutation(len(train_pairs))]\n",
    "\n",
    "# for cv_num in range(0,5):\n",
    "#     len(train_pairs)/5 = chunkSize\n",
    "#     if cv_num > 0:\n",
    "#         test_start = i*chunkSize\n",
    "#         test_end = (i+1)*chunkSize\n",
    "#         train_start\n",
    "#         train_end\n",
    "#split training examples into 5 groups\n",
    "\n",
    "\n",
    "#split training examples into CV_Train_X and CV_Train_Y, also create CV_Test"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
