{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/data/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "from PIL import Image\n",
    "import skimage.data\n",
    "import skimage.exposure\n",
    "import skimage.color\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_pairs(train_info):\n",
    "    \"\"\"Creates training data from the supplied training image information file\"\"\"\n",
    "    artists = train_info.artist.unique()\n",
    "\n",
    "    n = train_info.groupby('artist').size()\n",
    "    n = (2*n**2).sum() \n",
    "    t = pd.DataFrame(np.zeros((n, 4)), columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    for artist in artists:\n",
    "\n",
    "        #artist info is Ax2 matrix of artist, filename\n",
    "        artistInfo = train_info[train_info.artist==artist][['artist', 'filename']].values\n",
    "        \n",
    "        use = train_info[train_info.artist != artist ].index.values\n",
    "        np.random.shuffle(use)\n",
    "        \n",
    "        #nm = np.min([a.shape[0]**2, train_info[train_info.artist != m].shape[0] ])\n",
    "        numExamples = np.min([len(artistInfo)**2, sum(train_info.artist != artist) ])\n",
    "        use = use[0:numExamples]\n",
    "        \n",
    "        #diffArtistInfo a Bx2 matrix of artist, filename\n",
    "        diffArtistInfo = train_info[train_info.artist!=artist][['artist', 'filename']].ix[use, :].values\n",
    "\n",
    "        \n",
    "        toAdd_SameArtist = pd.DataFrame(np.concatenate([  np.repeat(artistInfo[:, 0], len(artistInfo)).reshape((-1,1)), #artist\n",
    "                                            np.repeat(artistInfo[:, 1],\n",
    "                                            artistInfo.shape[0]).reshape((-1,1)),\n",
    "                                            np.tile(artistInfo, (len(artistInfo), 1))],\n",
    "                                         axis=1),\n",
    "                          columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "        toAdd_SameArtist = toAdd_SameArtist.loc[0:numExamples, :]\n",
    "        \n",
    "        toAdd_DiffArtist = pd.DataFrame(np.concatenate([np.tile(artistInfo,\n",
    "                                                  (len(artistInfo), 1))[0:len(diffArtistInfo), :],\n",
    "                                          diffArtistInfo], axis=1),\n",
    "                          columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "        toAdd_DiffArtist = toAdd_DiffArtist.loc[0:numExamples, :]\n",
    "        \n",
    "        #print(j, i, a2.shape[0], b2.shape[0])\n",
    "        #print(b2)\n",
    "        t.iloc[i:i+len(toAdd_SameArtist), :] = toAdd_SameArtist.values\n",
    "        t.iloc[i+len(toAdd_SameArtist):i+len(toAdd_SameArtist)+len(toAdd_DiffArtist), :] = toAdd_DiffArtist.values\n",
    "        \n",
    "        i += len(toAdd_SameArtist) + len(toAdd_DiffArtist)\n",
    "        j += 1\n",
    "        if j%100==0:\n",
    "            print('finished %s of %s artists'%(j, len(artists)))\n",
    "\n",
    "    print('make pairs completed')\n",
    "    t = t[~t.image2.isin([np.nan, 0])]\n",
    "    return t[t.image1 > t.image2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Image List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def prepImageList(image_info, isTest):\n",
    "#     \"\"\"given the train_image_info or submission_info, returns a dataframe with a single column containing filenames of images\"\"\"\n",
    "#     if isTest:\n",
    "#         images = list(set(list(image_info.image1.unique()) + list(image_info.image2.unique())))\n",
    "#         result = pd.DataFrame(np.array(images).reshape((-1, 1)), columns = ['filename'])\n",
    "#     else:\n",
    "#         result = pd.DataFrame(columns = ['filename'], data = image_info['filename'] )\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features Parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeaturesParent(isTest):\n",
    "    \"\"\"Creates features for training and test images. This function utilizes multiprocessing.\n",
    "    Args:\n",
    "        isTest: bool to fetch training or test data\n",
    "    Returns:\n",
    "        pandas DataFrame containing features\n",
    "    \"\"\"\n",
    "    \n",
    "    num_cores = multiprocessing.cpu_count() - 5\n",
    "    \n",
    "    argsList = []\n",
    "    \n",
    "    for jobNum in range(num_cores):\n",
    "        argsList.append((isTest, jobNum, num_cores))\n",
    "        \n",
    "\n",
    "    print('Launching %s jobs' % (num_cores))\n",
    "    startTime = time.time()\n",
    "    \n",
    "    pool = multiprocessing.Pool(num_cores)\n",
    "    image_features_list = pool.starmap(getFeaturesWorker, argsList)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    image_features = pd.concat(image_features_list)\n",
    "    \n",
    "    endTime = time.time()\n",
    "    \n",
    "    print(\"collecting features complete, time taken = %.2f minutes\" % ((endTime - startTime) / 60.0))\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFeaturesWorker(isTest, jobNum, totalJobs):\n",
    "    \"\"\"Child function for computing image features, only to be called by getFeaturesParent\n",
    "    Args:\n",
    "        isTest: whether to compute features for test or training images\n",
    "        jobNum: which job number this is\n",
    "        totalJobs: total number of jobs\n",
    "    Returns:\n",
    "        pandas dataframe containing a data for a fraction of the training or test images\n",
    "    \"\"\"\n",
    "    if isTest:\n",
    "        mydir = r'/data/test_data/test'\n",
    "        info = pd.read_csv(r'/data/test_data/submission_info.csv', index_col = 0)\n",
    "    else:\n",
    "        mydir = r'/data/training_data/train'\n",
    "        info = pd.read_csv(r'/data/training_data/train_info.csv', index_col = 0)\n",
    "    \n",
    "    info = info.iloc[40000:]\n",
    "    \n",
    "    totalNumImages = len(info)\n",
    "    \n",
    "    chunkSize = np.int(totalNumImages/totalJobs)\n",
    "    \n",
    "    if jobNum == totalJobs - 1:\n",
    "        startInd = jobNum * chunkSize\n",
    "        endInd = totalNumImages\n",
    "    else:\n",
    "        startInd = jobNum * chunkSize\n",
    "        endInd = (jobNum + 1) * chunkSize\n",
    "        \n",
    "    info = info.iloc[startInd:endInd]\n",
    "    \n",
    "    info['pixelsx'] = np.nan\n",
    "    info['pixelsy'] = np.nan\n",
    "    info['size_bytes'] = np.nan\n",
    "    \n",
    "    info['r_mean'] = np.nan\n",
    "    info['r_med'] = np.nan\n",
    "    info['r_std'] = np.nan\n",
    "    \n",
    "    info['g_mean'] = np.nan\n",
    "    info['g_med'] = np.nan\n",
    "    info['g_std'] = np.nan\n",
    "    \n",
    "    info['b_mean'] = np.nan\n",
    "    info['b_med'] = np.nan\n",
    "    info['b_std'] = np.nan\n",
    "    \n",
    "    info['h_mean'] = np.nan\n",
    "    info['h_var'] = np.nan\n",
    "    \n",
    "    info['s_mean'] = np.nan\n",
    "    info['s_std'] = np.nan\n",
    "    info['s_med'] = np.nan\n",
    "    \n",
    "    info['v_mean'] = np.nan\n",
    "    info['v_std'] = np.nan\n",
    "    info['v_med'] = np.nan\n",
    "    \n",
    "    info['is_grayscale'] = np.nan\n",
    "      \n",
    "    print('Job %s, starting getting image info for images %s-%s' % (jobNum, startInd, endInd-1))\n",
    "    startTime = time.clock()\n",
    "    \n",
    "    for ind, i in enumerate(info.index.values):\n",
    "        try:       \n",
    "            #im = Image.open(mydir+'/'+info.loc[i, 'filename'])\n",
    "            #info.loc[i, 'pixelsx'], info.loc[i, 'pixelsy'] = im.size\n",
    "            \n",
    "            im = skimage.data.imread(mydir + '/' + info.loc[i, 'filename'])\n",
    "                \n",
    "            info.loc[i, 'pixelsx'] = im.shape[1]\n",
    "            info.loc[i, 'pixelsy'] = im.shape[0]\n",
    "            \n",
    "            grayscale = (len(im.shape) == 2)\n",
    "            \n",
    "            if grayscale:\n",
    "                info.loc[i, 'r_mean'] = im.mean()\n",
    "                info.loc[i, 'g_mean'] = info.loc[i, 'b_mean'] = info.loc[i, 'r_mean']\n",
    "                \n",
    "                info.loc[i, 'r_med'] = np.median(im)\n",
    "                info.loc[i, 'g_med'] = info.loc[i, 'b_med'] = info.loc[i, 'r_med']\n",
    "                \n",
    "                info.loc[i, 'r_std'] = im.std()\n",
    "                info.loc[i, 'g_std'] = info.loc[i, 'b_std'] = info.loc[i, 'r_std']\n",
    "                \n",
    "                info.loc[i, 'is_grayscale' ] = 1\n",
    "                \n",
    "                info.loc[i, 'h_mean'] = 0\n",
    "                info.loc[i, 'h_var'] = 0\n",
    "                info.loc[i, 's_mean'] = 0\n",
    "                info.loc[i, 's_std'] = 0\n",
    "                info.loc[i, 's_med'] = 0\n",
    "                info.loc[i, 'v_mean'] = info.loc[i, 'r_mean']/256.0\n",
    "                info.loc[i, 'v_std'] = info.loc[i, 'r_std']/256.0\n",
    "                info.loc[i, 'v_med'] = info.loc[i, 'r_med']/256.0\n",
    "                \n",
    "            else:\n",
    "                info.loc[i, 'r_mean'] = im[:,:,0].mean()\n",
    "                info.loc[i, 'g_mean'] = im[:,:,1].mean()\n",
    "                info.loc[i, 'b_mean'] = im[:,:,2].mean()\n",
    "                info.loc[i, 'r_med'] = np.median(im[:,:,0])\n",
    "                info.loc[i, 'g_med'] = np.median(im[:,:,1])\n",
    "                info.loc[i, 'b_med'] = np.median(im[:,:,2])\n",
    "                info.loc[i, 'r_std'] = im[:,:,0].std()\n",
    "                info.loc[i, 'g_std'] = im[:,:,1].std()\n",
    "                info.loc[i, 'b_std'] = im[:,:,2].std()\n",
    "                info.loc[i, 'is_grayscale' ] = 0\n",
    "                \n",
    "                #if it is in RGBA, we don't handle it for now\n",
    "                if (len(im.shape) == 3) and im.shape[2] == 4:\n",
    "                    print('%s is rgba' % info.loc[i, 'filename'])\n",
    "                else:     \n",
    "                    # convert image to hue/saturation/value\n",
    "                    hsvImage = skimage.color.rgb2hsv(im)\n",
    "                    angles = hsvImage[:,:,0] * 2.0 * np.pi\n",
    "\n",
    "                    # average hue is converting the (0-1) hue value to unit vector coordinates\n",
    "                    # and finding the average direction\n",
    "                    sinSum = np.sin(angles).sum()\n",
    "                    cosSum = np.cos(angles).sum()\n",
    "                    info.loc[i, 'h_mean'] = np.arctan(sinSum/cosSum)\n",
    "\n",
    "                    # use the variance formula for a circulator distribution\n",
    "                    R2 = np.power(sinSum, 2) + np.power(cosSum, 2)\n",
    "                    numPixels = info.loc[i, 'pixelsx'] * info.loc[i, 'pixelsy']\n",
    "                    R_bar = np.sqrt(R2)/numPixels\n",
    "                    info.loc[i, 'h_var'] = 1 - R_bar\n",
    "\n",
    "                    info.loc[i, 's_mean'] = hsvImage[:,:,1].mean()\n",
    "                    info.loc[i, 's_std'] = np.median(hsvImage[:,:,1])\n",
    "                    info.loc[i, 's_med'] = hsvImage[:,:,1].std()\n",
    "                    info.loc[i, 'v_mean'] = hsvImage[:,:,2].mean()\n",
    "                    info.loc[i, 'v_std'] = np.median(hsvImage[:,:,2])\n",
    "                    info.loc[i, 'v_med'] = hsvImage[:,:,2].std()\n",
    "                \n",
    "            #im = cv2.imread(dir+'/'+info.loc[i, 'new_filename'])\n",
    "            #info.loc[i, 'pixelsx'], info.loc[i, 'pixelsy'] = im.shape[0:2]\n",
    "            info.loc[i, 'size_bytes'] = os.path.getsize(mydir+'/'+info.loc[i, 'filename']) \n",
    "            if (ind+1)%100==0:\n",
    "                currentTime = time.clock()\n",
    "                print('Job %s, finished %s of %s, total time = %.2f min' %\n",
    "                     (jobNum, (ind+1), len(info), (currentTime - startTime)/60.0))\n",
    "        except:\n",
    "            print('job %s - error in %s' % (jobNum, mydir+'/'+info.loc[i, 'filename']))\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    currentTime = time.clock()\n",
    "    print('- Job %s, finished getting image info, total time = %.2f min' % ( jobNum, (currentTime - startTime) / 60.0))\n",
    "    \n",
    "    return info\n",
    "\n",
    "    #return info.rename(columns={'filename' : 'new_filename'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load image info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load training info\n",
    "train_info = pd.read_csv(r'/data/training_data/train_info.csv', index_col=0)\n",
    "submission_info = pd.read_csv(r'/data/test_data/submission_info.csv', index_col=0)\n",
    "\n",
    "#shuffle and save info\n",
    "#train_info = train_info.iloc[np.random.permutation(len(train_info))]\n",
    "#submission_info = submission_info.iloc[np.random.permutation(len(submission_info))]\n",
    "\n",
    "#train_info.to_csv(r'/data/training_data/train_info.csv')\n",
    "#submission_info.to_csv(r'/data/test_data/submission_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-eae200a03a63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_info' is not defined"
     ]
    }
   ],
   "source": [
    "len(train_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create submission image info from submission pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission image data is a bunch of images pairs, but we may want to work with a list of test images instead\n",
    "\n",
    "#submission_pairs = pd.read_csv(r'/data/test_data/submission_pairs.csv')\n",
    "#images = list(set(list(submission_info.image1.unique()) + list(submission_info.image2.unique())))\n",
    "#submission_info = pd.DataFrame(data=images, columns=['filename'])\n",
    "#submission_info = pd.read_csv(r'/data/test_data/submission_info.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make training pairs\n",
    "#train_pairs = make_pairs(train_image_info)\n",
    "#train_pairs[ 'sameArtist' ] = train_pairs[ 'artist1' ] == train_pairs[ 'artist2' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save as csv\n",
    "#train_pairs.to_csv(r'/data/training_data/train_pairs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load pairs\n",
    "train_pairs = pd.read_csv(r'/data/training_data/train_pairs.csv', index_col = 0)\n",
    "#submission_pairs = pd.read_csv(r'/data/test_data/submission_pairs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shuffle pairs, reduce number if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pairs = train_pairs.iloc[np.random.permutation(len(train_pairs))]\n",
    "train_pairs = train_pairs.iloc[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin computing features\n",
      "Launching 35 jobs\n",
      "Job 32, starting getting image info for images 36032-37157\n",
      "Job 18, starting getting image info for images 20268-21393\n",
      "Job 21, starting getting image info for images 23646-24771\n",
      "Job 25, starting getting image info for images 28150-29275\n",
      "Job 34, starting getting image info for images 38284-39432\n",
      "Job 11, starting getting image info for images 12386-13511\n",
      "Job 0, starting getting image info for images 0-1125\n",
      "Job 16, starting getting image info for images 18016-19141\n",
      "Job 30, starting getting image info for images 33780-34905\n",
      "Job 23, starting getting image info for images 25898-27023\n",
      "Job 28, starting getting image info for images 31528-32653\n",
      "Job 31, starting getting image info for images 34906-36031\n",
      "Job 26, starting getting image info for images 29276-30401\n",
      "Job 19, starting getting image info for images 21394-22519\n",
      "Job 29, starting getting image info for images 32654-33779\n",
      "Job 13, starting getting image info for images 14638-15763\n",
      "Job 12, starting getting image info for images 13512-14637\n",
      "Job 24, starting getting image info for images 27024-28149\n",
      "Job 27, starting getting image info for images 30402-31527\n",
      "Job 10, starting getting image info for images 11260-12385\n",
      "Job 22, starting getting image info for images 24772-25897\n",
      "Job 2, starting getting image info for images 2252-3377\n",
      "Job 33, starting getting image info for images 37158-38283\n",
      "Job 1, starting getting image info for images 1126-2251\n",
      "Job 20, starting getting image info for images 22520-23645\n",
      "Job 7, starting getting image info for images 7882-9007\n",
      "Job 14, starting getting image info for images 15764-16889\n",
      "Job 9, starting getting image info for images 10134-11259\n",
      "Job 17, starting getting image info for images 19142-20267\n",
      "Job 8, starting getting image info for images 9008-10133\n",
      "Job 15, starting getting image info for images 16890-18015\n",
      "Job 4, starting getting image info for images 4504-5629\n",
      "Job 5, starting getting image info for images 5630-6755\n",
      "Job 6, starting getting image info for images 6756-7881\n",
      "Job 3, starting getting image info for images 3378-4503\n",
      "Job 20, finished 100 of 1126, total time = 1.38 min\n",
      "Job 32, finished 100 of 1126, total time = 1.40 min\n",
      "Job 27, finished 100 of 1126, total time = 1.48 min\n",
      "Job 28, finished 100 of 1126, total time = 1.57 min\n",
      "Job 15, finished 100 of 1126, total time = 1.72 min\n",
      "Job 26, finished 100 of 1126, total time = 1.77 min\n",
      "Job 0, finished 100 of 1126, total time = 1.80 min\n",
      "Job 8, finished 100 of 1126, total time = 1.83 min\n",
      "Job 5, finished 100 of 1126, total time = 1.85 min\n",
      "Job 7, finished 100 of 1126, total time = 1.88 min\n",
      "Job 2, finished 100 of 1126, total time = 1.90 min\n",
      "Job 4, finished 100 of 1126, total time = 1.90 min\n",
      "Job 29, finished 100 of 1126, total time = 1.92 min\n",
      "Job 18, finished 100 of 1126, total time = 1.94 min\n",
      "Job 25, finished 100 of 1126, total time = 1.96 min\n",
      "Job 16, finished 100 of 1126, total time = 1.99 min\n",
      "Job 21, finished 100 of 1126, total time = 2.04 min\n",
      "Job 11, finished 100 of 1126, total time = 2.07 min\n",
      "Job 30, finished 100 of 1126, total time = 2.13 min\n",
      "Job 13, finished 100 of 1126, total time = 2.13 min\n",
      "Job 23, finished 100 of 1126, total time = 2.18 min\n",
      "Job 10, finished 100 of 1126, total time = 2.17 min\n",
      "Job 6, finished 100 of 1126, total time = 2.26 min\n",
      "Job 34, finished 100 of 1149, total time = 2.40 min\n",
      "Job 3, finished 100 of 1126, total time = 2.38 min\n",
      "Job 24, finished 100 of 1126, total time = 2.40 min\n",
      "Job 19, finished 100 of 1126, total time = 2.46 min\n",
      "Job 22, finished 100 of 1126, total time = 2.50 min\n",
      "Job 9, finished 100 of 1126, total time = 2.51 min\n",
      "Job 1, finished 100 of 1126, total time = 2.56 min\n",
      "Job 33, finished 100 of 1126, total time = 2.62 min\n",
      "Job 14, finished 100 of 1126, total time = 2.61 min\n",
      "Job 17, finished 100 of 1126, total time = 2.74 min\n",
      "Job 20, finished 200 of 1126, total time = 2.79 min\n",
      "2881.jpg is rgba\n",
      "Job 31, finished 100 of 1126, total time = 3.02 min\n",
      "Job 12, finished 100 of 1126, total time = 3.18 min\n",
      "Job 8, finished 200 of 1126, total time = 3.30 min\n",
      "Job 26, finished 200 of 1126, total time = 3.36 min\n",
      "Job 29, finished 200 of 1126, total time = 3.40 min\n",
      "Job 4, finished 200 of 1126, total time = 3.42 min\n",
      "Job 32, finished 200 of 1126, total time = 3.53 min\n",
      "Job 5, finished 200 of 1126, total time = 3.55 min\n",
      "Job 15, finished 200 of 1126, total time = 3.60 min\n",
      "Job 13, finished 200 of 1126, total time = 3.62 min\n",
      "17624.jpg is rgba\n",
      "Job 27, finished 200 of 1126, total time = 3.68 min\n",
      "Job 10, finished 200 of 1126, total time = 3.72 min\n",
      "Job 0, finished 200 of 1126, total time = 3.74 min\n",
      "Job 28, finished 200 of 1126, total time = 3.76 min\n",
      "Job 7, finished 200 of 1126, total time = 3.75 min\n",
      "Job 18, finished 200 of 1126, total time = 3.82 min\n",
      "Job 21, finished 200 of 1126, total time = 3.89 min\n",
      "Job 25, finished 200 of 1126, total time = 3.95 min\n",
      "Job 23, finished 200 of 1126, total time = 3.97 min\n",
      "Job 19, finished 200 of 1126, total time = 4.03 min\n",
      "Job 2, finished 200 of 1126, total time = 4.09 min\n",
      "Job 16, finished 200 of 1126, total time = 4.13 min\n",
      "Job 22, finished 200 of 1126, total time = 4.28 min\n",
      "Job 9, finished 200 of 1126, total time = 4.32 min\n",
      "Job 24, finished 200 of 1126, total time = 4.36 min\n",
      "Job 11, finished 200 of 1126, total time = 4.53 min\n",
      "Job 30, finished 200 of 1126, total time = 4.63 min\n",
      "Job 6, finished 200 of 1126, total time = 4.64 min\n",
      "Job 1, finished 200 of 1126, total time = 4.76 min\n",
      "Job 3, finished 200 of 1126, total time = 4.82 min\n",
      "Job 14, finished 200 of 1126, total time = 5.06 min\n",
      "Job 34, finished 200 of 1149, total time = 5.08 min\n",
      "Job 12, finished 200 of 1126, total time = 5.12 min\n",
      "Job 4, finished 300 of 1126, total time = 5.13 min\n",
      "Job 20, finished 300 of 1126, total time = 5.16 min\n",
      "Job 17, finished 200 of 1126, total time = 5.20 min\n",
      "Job 33, finished 200 of 1126, total time = 5.24 min\n",
      "Job 8, finished 300 of 1126, total time = 5.25 min\n",
      "Job 7, finished 300 of 1126, total time = 5.34 min\n",
      "Job 28, finished 300 of 1126, total time = 5.46 min\n",
      "Job 29, finished 300 of 1126, total time = 5.46 min\n",
      "Job 5, finished 300 of 1126, total time = 5.50 min\n",
      "Job 31, finished 200 of 1126, total time = 5.58 min\n",
      "Job 25, finished 300 of 1126, total time = 5.59 min\n",
      "Job 0, finished 300 of 1126, total time = 5.59 min\n",
      "Job 15, finished 300 of 1126, total time = 5.78 min\n",
      "Job 21, finished 300 of 1126, total time = 5.80 min\n",
      "Job 10, finished 300 of 1126, total time = 5.85 min\n",
      "Job 27, finished 300 of 1126, total time = 5.90 min\n",
      "Job 9, finished 300 of 1126, total time = 5.96 min\n",
      "Job 13, finished 300 of 1126, total time = 6.05 min\n",
      "Job 26, finished 300 of 1126, total time = 6.11 min\n",
      "Job 1, finished 300 of 1126, total time = 6.18 min\n",
      "Job 32, finished 300 of 1126, total time = 6.20 min\n",
      "Job 18, finished 300 of 1126, total time = 6.22 min\n",
      "Job 30, finished 300 of 1126, total time = 6.26 min\n",
      "Job 19, finished 300 of 1126, total time = 6.25 min\n",
      "Job 24, finished 300 of 1126, total time = 6.29 min\n",
      "Job 2, finished 300 of 1126, total time = 6.37 min\n",
      "Job 16, finished 300 of 1126, total time = 6.41 min\n",
      "Job 11, finished 300 of 1126, total time = 6.53 min\n",
      "Job 23, finished 300 of 1126, total time = 6.56 min\n",
      "Job 6, finished 300 of 1126, total time = 6.54 min\n",
      "Job 8, finished 400 of 1126, total time = 6.74 min\n",
      "Job 22, finished 300 of 1126, total time = 6.80 min\n",
      "Job 12, finished 300 of 1126, total time = 6.85 min\n",
      "Job 28, finished 400 of 1126, total time = 6.93 min\n",
      "49997.jpg is rgba\n",
      "Job 34, finished 300 of 1149, total time = 7.17 min\n",
      "Job 14, finished 300 of 1126, total time = 7.22 min\n",
      "Job 7, finished 400 of 1126, total time = 7.28 min\n",
      "Job 25, finished 400 of 1126, total time = 7.38 min\n",
      "Job 4, finished 400 of 1126, total time = 7.40 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/lib/python3.5/site-packages/PIL/Image.py:2238: DecompressionBombWarning: Image size (107327830 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 33, finished 300 of 1126, total time = 7.46 min\n",
      "Job 17, finished 300 of 1126, total time = 7.48 min\n",
      "Job 5, finished 400 of 1126, total time = 7.48 min\n",
      "Job 3, finished 300 of 1126, total time = 7.48 min\n",
      "Job 31, finished 300 of 1126, total time = 7.57 min\n",
      "Job 21, finished 400 of 1126, total time = 7.78 min\n",
      "47419.jpg is rgba\n",
      "Job 20, finished 400 of 1126, total time = 7.83 min\n",
      "90205.jpg is rgba\n",
      "Job 15, finished 400 of 1126, total time = 7.84 min\n",
      "Job 29, finished 400 of 1126, total time = 7.87 min\n",
      "Job 10, finished 400 of 1126, total time = 7.97 min\n",
      "Job 27, finished 400 of 1126, total time = 7.98 min\n",
      "54305.jpg is rgba\n",
      "Job 13, finished 400 of 1126, total time = 8.02 min\n",
      "Job 32, finished 400 of 1126, total time = 8.04 min\n",
      "Job 1, finished 400 of 1126, total time = 8.04 min\n",
      "Job 24, finished 400 of 1126, total time = 8.08 min\n",
      "Job 9, finished 400 of 1126, total time = 8.19 min\n",
      "Job 26, finished 400 of 1126, total time = 8.24 min\n",
      "Job 19, finished 400 of 1126, total time = 8.37 min\n",
      "Job 18, finished 400 of 1126, total time = 8.39 min\n",
      "Job 28, finished 500 of 1126, total time = 8.46 min\n",
      "Job 23, finished 400 of 1126, total time = 8.48 min\n",
      "Job 8, finished 500 of 1126, total time = 8.54 min\n",
      "Job 11, finished 400 of 1126, total time = 8.59 min\n",
      "Job 2, finished 400 of 1126, total time = 8.63 min\n",
      "Job 16, finished 400 of 1126, total time = 8.65 min\n",
      "Job 0, finished 400 of 1126, total time = 8.69 min\n",
      "Job 4, finished 500 of 1126, total time = 8.78 min\n",
      "Job 6, finished 400 of 1126, total time = 9.02 min\n",
      "Job 25, finished 500 of 1126, total time = 9.06 min\n",
      "Job 22, finished 400 of 1126, total time = 9.13 min\n",
      "Job 3, finished 400 of 1126, total time = 9.19 min\n",
      "Job 7, finished 500 of 1126, total time = 9.20 min\n",
      "Job 12, finished 400 of 1126, total time = 9.28 min\n",
      "Job 33, finished 400 of 1126, total time = 9.31 min\n",
      "Job 31, finished 400 of 1126, total time = 9.38 min\n",
      "Job 17, finished 400 of 1126, total time = 9.54 min\n",
      "Job 10, finished 500 of 1126, total time = 9.56 min\n",
      "Job 29, finished 500 of 1126, total time = 9.72 min\n",
      "Job 32, finished 500 of 1126, total time = 9.79 min\n",
      "Job 5, finished 500 of 1126, total time = 9.78 min\n",
      "Job 14, finished 400 of 1126, total time = 9.89 min\n",
      "Job 20, finished 500 of 1126, total time = 9.89 min\n",
      "Job 27, finished 500 of 1126, total time = 9.95 min\n",
      "Job 24, finished 500 of 1126, total time = 10.02 min\n",
      "Job 15, finished 500 of 1126, total time = 10.04 min\n",
      "Job 30, finished 400 of 1126, total time = 10.08 min\n",
      "Job 34, finished 400 of 1149, total time = 10.12 min\n",
      "Job 0, finished 500 of 1126, total time = 10.16 min\n",
      "Job 26, finished 500 of 1126, total time = 10.20 min\n",
      "Job 19, finished 500 of 1126, total time = 10.21 min\n",
      "Job 9, finished 500 of 1126, total time = 10.24 min\n",
      "Job 1, finished 500 of 1126, total time = 10.33 min\n",
      "Job 23, finished 500 of 1126, total time = 10.43 min\n",
      "Job 25, finished 600 of 1126, total time = 10.46 min\n",
      "Job 4, finished 600 of 1126, total time = 10.50 min\n",
      "Job 21, finished 500 of 1126, total time = 10.57 min\n",
      "Job 28, finished 600 of 1126, total time = 10.70 min\n",
      "Job 11, finished 500 of 1126, total time = 10.72 min\n",
      "Job 7, finished 600 of 1126, total time = 10.76 min\n",
      "Job 16, finished 500 of 1126, total time = 10.82 min\n",
      "Job 18, finished 500 of 1126, total time = 10.89 min\n",
      "Job 2, finished 500 of 1126, total time = 10.93 min\n",
      "Job 6, finished 500 of 1126, total time = 11.01 min\n",
      "Job 12, finished 500 of 1126, total time = 11.07 min\n",
      "Job 8, finished 600 of 1126, total time = 11.08 min\n",
      "Job 17, finished 500 of 1126, total time = 11.21 min\n",
      "Job 3, finished 500 of 1126, total time = 11.29 min\n",
      "Job 13, finished 500 of 1126, total time = 11.44 min\n",
      "Job 34, finished 500 of 1149, total time = 11.47 min\n",
      "Job 15, finished 600 of 1126, total time = 11.55 min\n",
      "Job 30, finished 500 of 1126, total time = 11.62 min\n",
      "Job 10, finished 600 of 1126, total time = 11.61 min\n",
      "Job 22, finished 500 of 1126, total time = 11.78 min\n",
      "Job 29, finished 600 of 1126, total time = 11.82 min\n",
      "Job 5, finished 600 of 1126, total time = 11.81 min\n",
      "Job 14, finished 500 of 1126, total time = 11.85 min\n",
      "Job 0, finished 600 of 1126, total time = 11.91 min\n",
      "Job 32, finished 600 of 1126, total time = 11.99 min\n",
      "Job 33, finished 500 of 1126, total time = 12.10 min\n",
      "Job 9, finished 600 of 1126, total time = 12.12 min\n",
      "Job 4, finished 700 of 1126, total time = 12.14 min\n",
      "Job 21, finished 600 of 1126, total time = 12.19 min\n",
      "Job 24, finished 600 of 1126, total time = 12.19 min\n",
      "103084.jpg is rgba\n",
      "Job 19, finished 600 of 1126, total time = 12.24 min\n",
      "Job 1, finished 600 of 1126, total time = 12.32 min\n",
      "Job 2, finished 600 of 1126, total time = 12.36 min\n",
      "Job 7, finished 700 of 1126, total time = 12.43 min\n",
      "job 28 - error in /data/training_data/train/29675.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-2a43c68ab209>\", line 71, in getFeaturesWorker\n",
      "    info.loc[i, 'pixelsx'] = im.shape[1]\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 20, finished 600 of 1126, total time = 12.55 min\n",
      "Job 27, finished 600 of 1126, total time = 12.67 min\n",
      "Job 26, finished 600 of 1126, total time = 12.69 min\n",
      "Job 23, finished 600 of 1126, total time = 12.79 min\n",
      "Job 31, finished 500 of 1126, total time = 12.84 min\n",
      "Job 25, finished 700 of 1126, total time = 12.83 min\n",
      "Job 16, finished 600 of 1126, total time = 12.96 min\n",
      "Job 8, finished 700 of 1126, total time = 12.97 min\n",
      "Job 30, finished 600 of 1126, total time = 13.21 min\n",
      "Job 11, finished 600 of 1126, total time = 13.23 min\n",
      "69691.jpg is rgba\n",
      "Job 3, finished 600 of 1126, total time = 13.41 min\n",
      "Job 15, finished 700 of 1126, total time = 13.42 min\n",
      "Job 18, finished 600 of 1126, total time = 13.45 min\n",
      "Job 5, finished 700 of 1126, total time = 13.60 min\n",
      "Job 6, finished 600 of 1126, total time = 13.61 min\n",
      "Job 21, finished 700 of 1126, total time = 13.71 min\n",
      "Job 29, finished 700 of 1126, total time = 13.73 min\n",
      "Job 34, finished 600 of 1149, total time = 13.84 min\n",
      "Job 4, finished 800 of 1126, total time = 13.86 min\n",
      "Job 17, finished 600 of 1126, total time = 13.90 min\n",
      "Job 24, finished 700 of 1126, total time = 13.90 min\n",
      "Job 0, finished 700 of 1126, total time = 13.97 min\n",
      "Job 12, finished 600 of 1126, total time = 14.03 min\n",
      "Job 13, finished 600 of 1126, total time = 14.07 min\n",
      "Job 32, finished 700 of 1126, total time = 14.10 min\n",
      "Job 22, finished 600 of 1126, total time = 14.22 min\n",
      "Job 7, finished 800 of 1126, total time = 14.25 min\n",
      "Job 19, finished 700 of 1126, total time = 14.28 min\n",
      "Job 33, finished 600 of 1126, total time = 14.33 min\n",
      "31713.jpg is rgba\n",
      "Job 14, finished 600 of 1126, total time = 14.47 min\n",
      "Job 10, finished 700 of 1126, total time = 14.48 min\n",
      "Job 2, finished 700 of 1126, total time = 14.49 min\n",
      "102290.jpg is rgba\n",
      "Job 27, finished 700 of 1126, total time = 14.62 min\n",
      "Job 20, finished 700 of 1126, total time = 14.64 min\n",
      "Job 28, finished 800 of 1126, total time = 14.66 min\n",
      "Job 16, finished 700 of 1126, total time = 14.73 min\n",
      "Job 30, finished 700 of 1126, total time = 14.84 min\n",
      "Job 1, finished 700 of 1126, total time = 14.88 min\n",
      "Job 25, finished 800 of 1126, total time = 14.95 min\n",
      "Job 9, finished 700 of 1126, total time = 14.95 min\n",
      "Job 18, finished 700 of 1126, total time = 15.03 min\n",
      "Job 26, finished 700 of 1126, total time = 15.07 min\n",
      "Job 8, finished 800 of 1126, total time = 15.16 min\n",
      "Job 23, finished 700 of 1126, total time = 15.22 min\n",
      "Job 11, finished 700 of 1126, total time = 15.30 min\n",
      "Job 31, finished 600 of 1126, total time = 15.47 min\n",
      "Job 15, finished 800 of 1126, total time = 15.49 min\n",
      "Job 21, finished 800 of 1126, total time = 15.60 min\n",
      "Job 13, finished 700 of 1126, total time = 15.73 min\n",
      "Job 12, finished 700 of 1126, total time = 15.74 min\n",
      "Job 29, finished 800 of 1126, total time = 15.79 min\n",
      "Job 0, finished 800 of 1126, total time = 15.87 min\n",
      "Job 6, finished 700 of 1126, total time = 15.92 min\n",
      "Job 19, finished 800 of 1126, total time = 16.04 min\n",
      "Job 4, finished 900 of 1126, total time = 16.03 min\n",
      "Job 34, finished 700 of 1149, total time = 16.08 min\n",
      "Job 17, finished 700 of 1126, total time = 16.11 min\n",
      "Job 10, finished 800 of 1126, total time = 16.14 min\n",
      "77740.jpg is rgba\n",
      "Job 24, finished 800 of 1126, total time = 16.27 min\n",
      "Job 32, finished 800 of 1126, total time = 16.32 min\n",
      "Job 5, finished 800 of 1126, total time = 16.36 min\n",
      "Job 16, finished 800 of 1126, total time = 16.42 min\n",
      "Job 33, finished 700 of 1126, total time = 16.44 min\n",
      "Job 2, finished 800 of 1126, total time = 16.42 min\n",
      "Job 27, finished 800 of 1126, total time = 16.48 min\n",
      "Job 7, finished 900 of 1126, total time = 16.60 min\n",
      "Job 3, finished 700 of 1126, total time = 16.66 min\n",
      "Job 22, finished 700 of 1126, total time = 16.68 min\n",
      "Job 28, finished 900 of 1126, total time = 16.69 min\n",
      "Job 26, finished 800 of 1126, total time = 16.77 min\n",
      "Job 1, finished 800 of 1126, total time = 16.79 min\n",
      "Job 9, finished 800 of 1126, total time = 16.85 min\n",
      "Job 25, finished 900 of 1126, total time = 16.87 min\n",
      "job 5 - error in /data/training_data/train/32721.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-2a43c68ab209>\", line 71, in getFeaturesWorker\n",
      "    info.loc[i, 'pixelsx'] = im.shape[1]\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 30, finished 800 of 1126, total time = 17.13 min\n",
      "Job 14, finished 700 of 1126, total time = 17.17 min\n",
      "Job 31, finished 700 of 1126, total time = 17.23 min\n",
      "Job 18, finished 800 of 1126, total time = 17.35 min\n",
      "Job 23, finished 800 of 1126, total time = 17.37 min\n",
      "Job 20, finished 800 of 1126, total time = 17.37 min\n",
      "Job 15, finished 900 of 1126, total time = 17.46 min\n",
      "Job 8, finished 900 of 1126, total time = 17.52 min\n",
      "Job 21, finished 900 of 1126, total time = 17.61 min\n",
      "Job 4, finished 1000 of 1126, total time = 17.63 min\n",
      "Job 17, finished 800 of 1126, total time = 17.84 min\n",
      "Job 29, finished 900 of 1126, total time = 17.85 min\n",
      "Job 6, finished 800 of 1126, total time = 17.92 min\n",
      "Job 12, finished 800 of 1126, total time = 17.94 min\n",
      "34022.jpg is rgba\n",
      "Job 33, finished 800 of 1126, total time = 17.97 min\n",
      "Job 19, finished 900 of 1126, total time = 17.99 min\n",
      "Job 11, finished 800 of 1126, total time = 18.01 min\n",
      "Job 13, finished 800 of 1126, total time = 18.03 min\n",
      "Job 0, finished 900 of 1126, total time = 18.14 min\n",
      "Job 24, finished 900 of 1126, total time = 18.22 min\n",
      "Job 7, finished 1000 of 1126, total time = 18.26 min\n",
      "Job 10, finished 900 of 1126, total time = 18.29 min\n",
      "Job 5, finished 900 of 1126, total time = 18.31 min\n",
      "Job 27, finished 900 of 1126, total time = 18.37 min\n",
      "Job 25, finished 1000 of 1126, total time = 18.41 min\n",
      "Job 34, finished 800 of 1149, total time = 18.61 min\n",
      "Job 16, finished 900 of 1126, total time = 18.69 min\n",
      "Job 1, finished 900 of 1126, total time = 18.74 min\n",
      "Job 28, finished 1000 of 1126, total time = 18.80 min\n",
      "Job 31, finished 800 of 1126, total time = 18.83 min\n",
      "Job 9, finished 900 of 1126, total time = 18.88 min\n",
      "Job 2, finished 900 of 1126, total time = 18.89 min\n",
      "Job 32, finished 900 of 1126, total time = 18.93 min\n",
      "Job 3, finished 800 of 1126, total time = 18.95 min\n",
      "Job 18, finished 900 of 1126, total time = 19.00 min\n",
      "Job 8, finished 1000 of 1126, total time = 19.11 min\n",
      "Job 22, finished 800 of 1126, total time = 19.15 min\n",
      "Job 30, finished 900 of 1126, total time = 19.17 min\n",
      "Job 14, finished 800 of 1126, total time = 19.42 min\n",
      "Job 4, finished 1100 of 1126, total time = 19.39 min\n",
      "Job 26, finished 900 of 1126, total time = 19.55 min\n",
      "Job 20, finished 900 of 1126, total time = 19.60 min\n",
      "Job 23, finished 900 of 1126, total time = 19.71 min\n",
      "Job 0, finished 1000 of 1126, total time = 19.76 min\n",
      "Job 13, finished 900 of 1126, total time = 19.86 min\n",
      "69110.jpg is rgba\n",
      "Job 17, finished 900 of 1126, total time = 19.90 min\n",
      "Job 10, finished 1000 of 1126, total time = 19.90 min\n",
      "Job 24, finished 1000 of 1126, total time = 20.00 min\n",
      "- Job 4, finished getting image info, total time = 19.98 min\n",
      "Job 27, finished 1000 of 1126, total time = 20.07 min\n",
      "Job 5, finished 1000 of 1126, total time = 20.07 min\n",
      "Job 19, finished 1000 of 1126, total time = 20.16 min\n",
      "Job 12, finished 900 of 1126, total time = 20.23 min\n",
      "Job 15, finished 1000 of 1126, total time = 20.30 min\n",
      "Job 33, finished 900 of 1126, total time = 20.35 min\n",
      "Job 9, finished 1000 of 1126, total time = 20.42 min\n",
      "Job 7, finished 1100 of 1126, total time = 20.45 min\n",
      "Job 11, finished 900 of 1126, total time = 20.50 min\n",
      "Job 21, finished 1000 of 1126, total time = 20.50 min\n",
      "Job 29, finished 1000 of 1126, total time = 20.52 min\n",
      "Job 1, finished 1000 of 1126, total time = 20.51 min\n",
      "Job 34, finished 900 of 1149, total time = 20.60 min\n",
      "Job 2, finished 1000 of 1126, total time = 20.57 min\n",
      "Job 25, finished 1100 of 1126, total time = 20.60 min\n",
      "Job 32, finished 1000 of 1126, total time = 20.69 min\n",
      "Job 6, finished 900 of 1126, total time = 20.68 min\n",
      "Job 3, finished 900 of 1126, total time = 20.80 min\n",
      "Job 31, finished 900 of 1126, total time = 20.89 min\n",
      "- Job 25, finished getting image info, total time = 21.05 min\n",
      "job 1 - error in /data/training_data/train/10692.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-2a43c68ab209>\", line 71, in getFeaturesWorker\n",
      "    info.loc[i, 'pixelsx'] = im.shape[1]\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 28, finished 1100 of 1126, total time = 21.09 min\n",
      "Job 0, finished 1100 of 1126, total time = 21.15 min\n",
      "Job 22, finished 900 of 1126, total time = 21.24 min\n",
      "Job 30, finished 1000 of 1126, total time = 21.27 min\n",
      "Job 18, finished 1000 of 1126, total time = 21.26 min\n",
      "Job 14, finished 900 of 1126, total time = 21.29 min\n",
      "- Job 28, finished getting image info, total time = 21.32 min\n",
      "Job 20, finished 1000 of 1126, total time = 21.34 min\n",
      "- Job 7, finished getting image info, total time = 21.36 min\n",
      "Job 16, finished 1000 of 1126, total time = 21.39 min\n",
      "Job 23, finished 1000 of 1126, total time = 21.49 min\n",
      "Job 27, finished 1100 of 1126, total time = 21.50 min\n",
      "Job 8, finished 1100 of 1126, total time = 21.51 min\n",
      "Job 24, finished 1100 of 1126, total time = 21.60 min\n",
      "Job 15, finished 1100 of 1126, total time = 21.60 min\n",
      "- Job 0, finished getting image info, total time = 21.72 min\n",
      "Job 26, finished 1000 of 1126, total time = 21.82 min\n",
      "- Job 8, finished getting image info, total time = 21.84 min\n",
      "- Job 27, finished getting image info, total time = 21.91 min\n",
      "Job 13, finished 1000 of 1126, total time = 21.92 min\n",
      "95499.jpg is rgba\n",
      "Job 19, finished 1100 of 1126, total time = 21.94 min\n",
      "- Job 24, finished getting image info, total time = 21.98 min\n",
      "Job 29, finished 1100 of 1126, total time = 22.02 min\n",
      "Job 33, finished 1000 of 1126, total time = 22.04 min\n",
      "Job 10, finished 1100 of 1126, total time = 22.04 min\n",
      "Job 11, finished 1000 of 1126, total time = 22.14 min\n",
      "- Job 15, finished getting image info, total time = 22.14 min\n",
      "Job 1, finished 1100 of 1126, total time = 22.15 min\n",
      "Job 5, finished 1100 of 1126, total time = 22.16 min\n",
      "- Job 19, finished getting image info, total time = 22.24 min\n",
      "Job 17, finished 1000 of 1126, total time = 22.26 min\n",
      "- Job 29, finished getting image info, total time = 22.29 min\n",
      "Job 12, finished 1000 of 1126, total time = 22.32 min\n",
      "- Job 10, finished getting image info, total time = 22.38 min\n",
      "Job 2, finished 1100 of 1126, total time = 22.39 min\n",
      "Job 9, finished 1100 of 1126, total time = 22.43 min\n",
      "- Job 1, finished getting image info, total time = 22.44 min\n",
      "- Job 5, finished getting image info, total time = 22.44 min\n",
      "Job 21, finished 1100 of 1126, total time = 22.47 min\n",
      "Job 31, finished 1000 of 1126, total time = 22.60 min\n",
      "Job 34, finished 1000 of 1149, total time = 22.60 min\n",
      "- Job 2, finished getting image info, total time = 22.63 min\n",
      "- Job 21, finished getting image info, total time = 22.67 min\n",
      "Job 16, finished 1100 of 1126, total time = 22.71 min\n",
      "29854.jpg is rgba\n",
      "Job 32, finished 1100 of 1126, total time = 22.74 min\n",
      "job 30 - error in /data/training_data/train/31842.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-38-2a43c68ab209>\", line 71, in getFeaturesWorker\n",
      "    info.loc[i, 'pixelsx'] = im.shape[1]\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Job 9, finished getting image info, total time = 22.75 min\n",
      "Job 20, finished 1100 of 1126, total time = 22.78 min\n",
      "Job 13, finished 1100 of 1126, total time = 22.85 min\n",
      "- Job 16, finished getting image info, total time = 22.86 min\n",
      "Job 6, finished 1000 of 1126, total time = 22.86 min\n",
      "Job 23, finished 1100 of 1126, total time = 22.89 min\n",
      "- Job 13, finished getting image info, total time = 23.01 min\n",
      "- Job 32, finished getting image info, total time = 23.06 min\n",
      "Job 22, finished 1000 of 1126, total time = 23.05 min\n",
      "- Job 20, finished getting image info, total time = 23.04 min\n",
      "Job 26, finished 1100 of 1126, total time = 23.09 min\n",
      "Job 18, finished 1100 of 1126, total time = 23.10 min\n",
      "Job 17, finished 1100 of 1126, total time = 23.12 min\n",
      "Job 14, finished 1000 of 1126, total time = 23.19 min\n",
      "Job 30, finished 1100 of 1126, total time = 23.23 min\n",
      "- Job 23, finished getting image info, total time = 23.25 min\n",
      "- Job 26, finished getting image info, total time = 23.26 min\n",
      "Job 33, finished 1100 of 1126, total time = 23.28 min\n",
      "- Job 18, finished getting image info, total time = 23.28 min\n",
      "Job 12, finished 1100 of 1126, total time = 23.33 min\n",
      "- Job 17, finished getting image info, total time = 23.34 min\n",
      "Job 3, finished 1000 of 1126, total time = 23.34 min\n",
      "- Job 30, finished getting image info, total time = 23.49 min\n",
      "Job 34, finished 1100 of 1149, total time = 23.58 min\n",
      "Job 11, finished 1100 of 1126, total time = 23.65 min\n",
      "- Job 12, finished getting image info, total time = 23.73 min\n",
      "Job 31, finished 1100 of 1126, total time = 23.78 min\n",
      "- Job 33, finished getting image info, total time = 23.80 min\n",
      "- Job 11, finished getting image info, total time = 23.92 min\n",
      "- Job 34, finished getting image info, total time = 23.95 min\n",
      "Job 22, finished 1100 of 1126, total time = 23.94 min\n",
      "Job 6, finished 1100 of 1126, total time = 23.99 min\n",
      "- Job 31, finished getting image info, total time = 24.10 min\n",
      "- Job 22, finished getting image info, total time = 24.18 min\n",
      "83132.jpg is rgba\n",
      "Job 14, finished 1100 of 1126, total time = 24.21 min\n",
      "- Job 6, finished getting image info, total time = 24.26 min\n",
      "- Job 14, finished getting image info, total time = 24.37 min\n",
      "Job 3, finished 1100 of 1126, total time = 24.41 min\n",
      "- Job 3, finished getting image info, total time = 24.71 min\n",
      "collecting features complete, time taken = 24.86 minutes\n",
      "Finished computing features, time taken = 24.86 min\n"
     ]
    }
   ],
   "source": [
    "print('Begin computing features')\n",
    "startTime = time.time()\n",
    "\n",
    "train_features = getFeaturesParent(False)\n",
    "\n",
    "endTime = time.time()\n",
    "print(\"Finished computing features, time taken = %.2f min\" % ((endTime-startTime)/60.0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39433"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_features_sorted.to_csv(r'/data/test_data/test_features.csv')\n",
    "#test_features_sorted.to_csv(r'/data/test_data/test_features.csv')\n",
    "#y = pd.read_csv(r'/data/test_data/test_features.csv', index_col=0)\n",
    "#test_features_sorted = test_features_sorted.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features.to_csv(r'/data/training_data/train_features_40000_end.csv')\n",
    "#test_features_sorted.to_csv(r'/data/test_data/test_features.csv')\n",
    "#y = pd.read_csv(r'/data/test_data/test_features.csv', index_col=0)\n",
    "#test_features_sorted = test_features_sorted.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load features\n",
    "train_features_0 = pd.read_csv(r'/data/training_data/train_features_0_20000.csv', index_col = 0)\n",
    "train_features_1 = pd.read_csv(r'/data/training_data/train_features_20000_40000.csv', index_col = 0)\n",
    "train_features_2 = pd.read_csv(r'/data/training_data/train_features_40000_end.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = pd.concat([train_features_0, train_features_1, train_features_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename            0\n",
       "artist              0\n",
       "title              13\n",
       "style             765\n",
       "genre             893\n",
       "date            20255\n",
       "pixelsx             7\n",
       "pixelsy             7\n",
       "size_bytes         21\n",
       "r_mean              7\n",
       "r_med               7\n",
       "r_std               7\n",
       "g_mean              7\n",
       "g_med               7\n",
       "g_std               7\n",
       "b_mean              7\n",
       "b_med               7\n",
       "b_std               7\n",
       "h_mean             52\n",
       "h_var              52\n",
       "s_mean             52\n",
       "s_std              52\n",
       "s_med              52\n",
       "v_mean             52\n",
       "v_std              52\n",
       "v_med              52\n",
       "is_grayscale        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(train_features).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional processing on feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saved features are straight from the feature functions with no handling of nulls, etc\n",
    "# these have to be addressed prior to training/predicting\n",
    "\n",
    "rgb_features = ['r_mean', 'r_med', 'r_std', 'g_mean', 'g_med',\n",
    "                'g_std', 'b_mean', 'b_med', 'b_std',]\n",
    "\n",
    "size_features =  [ 'pixelsx',\n",
    "       'pixelsy', 'size_bytes' ]\n",
    "\n",
    "\n",
    "# take out unnecessary columns\n",
    "feature_names = ['pixelsx', 'pixelsy', 'size_bytes', \n",
    "                 'r_mean', 'r_med', 'r_std',\n",
    "                 'g_mean', 'g_med', 'g_std',\n",
    "                 'b_mean', 'b_med', 'b_std',\n",
    "                 'h_mean', 'h_var',\n",
    "                 's_mean', 's_med', 's_std',\n",
    "                 'v_mean', 'v_med', 'v_std',\n",
    "                 'is_grayscale']\n",
    "\n",
    "train_features = train_features[ ['filename'] + feature_names ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join training features to training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#join pair data to image features\n",
    "image_feature_names = ['pixelsx', 'pixelsy', 'size_bytes', \n",
    "                 'r_mean', 'r_med', 'r_std',\n",
    "                 'g_mean', 'g_med', 'g_std',\n",
    "                 'b_mean', 'b_med', 'b_std',\n",
    "                 'h_mean', 'h_var',\n",
    "                 's_mean', 's_med', 's_std',\n",
    "                 'v_mean', 'v_med', 'v_std', \n",
    "                 'is_grayscale' ]\n",
    "\n",
    "col_dict_1 = {}\n",
    "col_dict_2 = {}\n",
    "\n",
    "for feature in feature_names:\n",
    "    col_dict_1[feature] = '%s_1' % feature\n",
    "    col_dict_2[feature] = '%s_2' % feature\n",
    "\n",
    "train_pairs = train_pairs.merge(train_features,\n",
    "                                left_on='image1', right_on='filename')\n",
    "train_pairs.rename( columns = col_dict_1,\n",
    "                      inplace=True)\n",
    "train_pairs = train_pairs.merge(train_features,\n",
    "                                left_on='image2', right_on='filename')\n",
    "train_pairs.rename( columns = col_dict_2,\n",
    "                      inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist1           0\n",
      "image1            0\n",
      "artist2           0\n",
      "image2            0\n",
      "sameArtist        0\n",
      "filename_x        0\n",
      "pixelsx_1         0\n",
      "pixelsy_1         0\n",
      "size_bytes_1      0\n",
      "r_mean_1          0\n",
      "r_med_1           0\n",
      "r_std_1           0\n",
      "g_mean_1          0\n",
      "g_med_1           0\n",
      "g_std_1           0\n",
      "b_mean_1          0\n",
      "b_med_1           0\n",
      "b_std_1           0\n",
      "h_mean_1          0\n",
      "h_var_1           0\n",
      "s_mean_1          0\n",
      "s_med_1           0\n",
      "s_std_1           0\n",
      "v_mean_1          0\n",
      "v_med_1           0\n",
      "v_std_1           0\n",
      "is_grayscale_1    0\n",
      "filename_y        0\n",
      "pixelsx_2         0\n",
      "pixelsy_2         0\n",
      "size_bytes_2      0\n",
      "r_mean_2          0\n",
      "r_med_2           0\n",
      "r_std_2           0\n",
      "g_mean_2          0\n",
      "g_med_2           0\n",
      "g_std_2           0\n",
      "b_mean_2          0\n",
      "b_med_2           0\n",
      "b_std_2           0\n",
      "h_mean_2          0\n",
      "h_var_2           0\n",
      "s_mean_2          0\n",
      "s_med_2           0\n",
      "s_std_2           0\n",
      "v_mean_2          0\n",
      "v_med_2           0\n",
      "v_std_2           0\n",
      "is_grayscale_2    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# we remove the nulls after the join, could also be done before\n",
    "train_pairs = train_pairs[~train_pairs['pixelsx_1'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['pixelsx_2'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['size_bytes_1'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['size_bytes_2'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['h_mean_1'].isnull()]\n",
    "train_pairs = train_pairs[~train_pairs['h_mean_2'].isnull()]\n",
    "\n",
    "\n",
    "print(train_pairs.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computePredictStats(y_prob, y_true, threshold = 0.5):\n",
    "    \"\"\" compute accuracy, precision, recall, negative precision, specificity, and auc roc\n",
    "        Args:\n",
    "            y_prob: array of floats from 0.0 - 1.0\n",
    "            y_true: array of booleans\n",
    "            threshold: true/false threshold value, between 0.0-1.0\n",
    "        Returns:\n",
    "            dict of classification metrics\n",
    "    \"\"\"\n",
    "    # y_pred = np.array([True, True, False, False])\n",
    "    # y_true = np.array([True, True, True, True])\n",
    "    y_pred = y_prob > threshold\n",
    "    \n",
    "    total = len(y_prob)\n",
    "    true_pos = sum( (y_pred == True) & (y_true == True) )\n",
    "    true_neg = sum( (y_pred == False) & (y_true == False) )\n",
    "    false_pos = sum( (y_pred == True) & (y_true == False) )\n",
    "    false_neg = sum( (y_pred == False ) & (y_true == True) )\n",
    "    \n",
    "    accuracy = (true_pos + true_neg) / total\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    npp = true_neg / (true_neg + false_neg) #negative prediction value\n",
    "    specificity = true_neg / (true_neg + false_pos)\n",
    "    roc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    return { 'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'npp': npp,\n",
    "            'specificity': specificity,\n",
    "            'roc': roc,\n",
    "            'true_pos': true_pos,\n",
    "            'true_neg': true_neg,\n",
    "            'false_pos': false_pos,\n",
    "            'false_neg': false_neg,\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pairs = train_pairs.iloc[np.random.permutation(len(train_pairs))]\n",
    "\n",
    "# get list of X columns, they are ones with '_1' or '_2' in the name\n",
    "allCols = train_pairs.columns\n",
    "isX = list(map(lambda x: ('_1' in x) or ('_2' in x), allCols))\n",
    "X_columns = allCols[isX]\n",
    "\n",
    "# split X and Y data\n",
    "train_X = train_pairs[X_columns]\n",
    "train_Y = train_pairs['sameArtist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kFoldCV(train_X, train_Y, k, numFoldsToTest):\n",
    "    \"\"\" Perform k-fold cross validation. Will modify train_pairs (shuffle rows)\n",
    "        Args:\n",
    "            train_pairs: Dataframe containing training image pairs with features. Should have no nulls.\n",
    "            k: k, at least 2\n",
    "            numFoldsToTest: how many folds to actually test, at most k\n",
    "        Returns:\n",
    "            dataframe with CV results\n",
    "    \"\"\"\n",
    "\n",
    "    numFoldsToTest = min(k, numFoldsToTest)\n",
    "    k = max(2, k)\n",
    "    \n",
    "    # shuffle rows\n",
    "    #train_pairs = train_pairs.iloc[np.random.permutation(len(train_pairs))]\n",
    "\n",
    "    # get list of X columns, they are ones with '_1' or '_2' in the name\n",
    "    #allCols = train_pairs.columns\n",
    "    #isX = list(map(lambda x: ('_1' in x) or ('_2' in x), allCols))\n",
    "    #X_columns = allCols[isX]\n",
    "    \n",
    "    # split X and Y data\n",
    "    #CV_X = train_pairs[X_columns]\n",
    "    #CV_Y = train_pairs['sameArtist']\n",
    "    \n",
    "    # define which indices belong to each fold\n",
    "    foldLocsList = [] #list of Index objects, one for each fold\n",
    "    \n",
    "    foldSize = int(len(train_X)/5)\n",
    "        \n",
    "    for foldNum in range(k):\n",
    "        if foldNum == k-1:\n",
    "            foldLocsList.append( train_X.index[foldNum*foldSize : len(train_X)] )\n",
    "        else:\n",
    "            foldLocsList.append( train_X.index[foldNum*foldSize : (foldNum+1)*(foldSize) ] )\n",
    "    \n",
    "    # set up dataframe for collecting results\n",
    "    columnsList = list(itertools.product(('train', 'test'), ('roc', 'precision', 'recall', 'npp', 'specificity')))\n",
    "    results = pd.DataFrame(index = range(numFoldsToTest), columns = pd.MultiIndex.from_tuples(columnsList))\n",
    "    \n",
    "    # test each fold\n",
    "    for testNum in range(numFoldsToTest):\n",
    "\n",
    "        # indices of training data\n",
    "        trainLocs = pd.Index([])\n",
    "        for foldNum in range(k):\n",
    "            if foldNum != testNum:\n",
    "                trainLocs = trainLocs.append( foldLocsList[foldNum] )\n",
    "        \n",
    "        # indices of test data\n",
    "        testLocs = foldLocsList[testNum]\n",
    "\n",
    "        print(trainLocs)\n",
    "        # set up Xs\n",
    "        CV_train_X = train_X.loc[trainLocs]\n",
    "        CV_test_X = train_X.loc[testLocs]\n",
    "\n",
    "        # set up Ys\n",
    "        CV_train_Y = train_Y.loc[trainLocs]\n",
    "        CV_test_Y = train_Y.loc[testLocs]\n",
    "        \n",
    "        # fit model\n",
    "        clf = RandomForestClassifier(n_estimators=60, min_samples_split=5, max_depth=10, n_jobs=1)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        print('starting fit')\n",
    "\n",
    "        clf.fit(CV_train_X, CV_train_Y)\n",
    "\n",
    "        end = time.time()\n",
    "                               \n",
    "        print('total training time: %s' % (end - start) )\n",
    "\n",
    "        # get in-sample and out-of-sample results\n",
    "                               \n",
    "        pred_train = clf.predict_proba(CV_train_X)[:,1]\n",
    "        train_results = computePredictStats( pred_train, CV_train_Y)\n",
    "\n",
    "        pred_test = clf.predict_proba(CV_test_X)[:,1]\n",
    "        test_results = computePredictStats( pred_test, CV_test_Y)\n",
    "       \n",
    "        for stat in ('roc', 'precision', 'recall', 'npp', 'specificity'):\n",
    "            results.loc[testNum, ('train', stat)] = train_results[stat]\n",
    "            results.loc[testNum, ('test', stat)] = test_results[stat]\n",
    "        \n",
    "    return results              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run k-fold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([2979102, 4628207,  759591, 2974870, 5156457, 7081573, 4926355,\n",
      "            4024620, 4631563, 6404482,\n",
      "            ...\n",
      "            7744472, 7694105, 4488323, 4104087, 8942494, 4501288, 3584866,\n",
      "            6234599, 7529968, 1365379],\n",
      "           dtype='int64', length=2400000)\n",
      "starting fit\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "numFoldsToTest = 1\n",
    "temp_X = train_X.iloc[0:3000000].copy()\n",
    "temp_Y = train_Y.iloc[0:3000000].copy()\n",
    "\n",
    "results = kFoldCV(temp_X, temp_Y, k, numFoldsToTest)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fit\n",
      "total training time: 917.0945500000003\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, min_samples_split=50, max_depth=8 )\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "print('starting fit')\n",
    "#excluding the patient_id column from the fit and prediction\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "end = time.clock()\n",
    "\n",
    "print('total training time: %s' % (end - start) )\n",
    "\n",
    "columnsList = list(itertools.product(('train', 'test'), ('roc', 'precision', 'recall', 'npp', 'specificity')))\n",
    "results = pd.DataFrame(index = range(numFoldsToTest), columns = pd.MultiIndex.from_tuples(columnsList))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total saving time: 0.012914999999338761\n"
     ]
    }
   ],
   "source": [
    "##save model\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "with open('my_dumped_classifier.pkl', 'wb') as fid:\n",
    "    pickle.dump(clf, fid) \n",
    "\n",
    "end = time.clock()\n",
    "print('total saving time: %s' % (end - start) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loading time: 0.007420999999339983\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# load it again\n",
    "with open('my_dumped_classifier.pkl', 'rb') as fid:\n",
    "    clf = pickle.load(fid)\n",
    "\n",
    "end = time.clock()\n",
    "print('total loading time: %s' % (end - start) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load test set definitions\n",
    "test_pairs = pd.read_csv(r'/data/test_data/submission_info.csv', index_col= 0)\n",
    "\n",
    "#get features\n",
    "#raw_test_image_info = get_image_info(test_pairs, r'/data/test_data/test')\n",
    "\n",
    "#get raw training data features\n",
    "#raw_test_image_info['bytes_per_pixel'] =raw_test_image_info['size_bytes']/(raw_test_image_info['pixelsx']*raw_test_image_info['pixelsy'])\n",
    "#raw_test_image_info['aspect_ratio'] = raw_test_image_info['pixelsx']/raw_test_image_info['pixelsy']\n",
    "\n",
    "#save raw_train_image_info\n",
    "#raw_test_image_info.to_csv(r'/data/test_data/raw_test_image_info.csv')\n",
    "\n",
    "#load raw_train_image_info\n",
    "#raw_test_image_info = pd.read_csv(r'/data/test_data/raw_test_image_info.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join test features to test pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def joinFeaturesToPairs(image_info, image_pairs):\n",
    "    #join pair data to image features\n",
    "    trimmed_image_info = image_info[['new_filename',\n",
    "                                     'pixelsx',\n",
    "                                     'pixelsy',\n",
    "                                     'bytes_per_pixel',\n",
    "                                     'aspect_ratio']]\n",
    "    image_pairs = image_pairs.merge(trimmed_image_info,\n",
    "                              left_on='image1', right_on='new_filename')\n",
    "    image_pairs.rename( columns = {'pixelsx': 'pixelsx_1',\n",
    "                        'pixelsy': 'pixelsy_1',\n",
    "                        'bytes_per_pixel' : 'bytes_per_pixel_1',\n",
    "                        'aspect_ratio':'aspect_ratio_1'})\n",
    "    image_pairs = image_pairs.merge(trimmed_image_info,\n",
    "                                    left_on='image2', right_on='new_filename')\n",
    "    train_pairs.rename( columns = {'pixelsx': 'pixelsx_2',\n",
    "                        'pixelsy': 'pixelsy_2',\n",
    "                        'bytes_per_pixel' : 'bytes_per_pixel_2',\n",
    "                        'aspect_ratio':'aspect_ratio_2'})\n",
    "    return train_pairs\n",
    "\n",
    "test_pairs_final = joinFeaturesToPairs(raw_test_image_info, test_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mymodel.pkl',\n",
       " 'mymodel.pkl_01.npy',\n",
       " 'mymodel.pkl_02.npy',\n",
       " 'mymodel.pkl_03.npy',\n",
       " 'mymodel.pkl_04.npy',\n",
       " 'mymodel.pkl_05.npy',\n",
       " 'mymodel.pkl_06.npy',\n",
       " 'mymodel.pkl_07.npy',\n",
       " 'mymodel.pkl_08.npy',\n",
       " 'mymodel.pkl_09.npy',\n",
       " 'mymodel.pkl_10.npy',\n",
       " 'mymodel.pkl_11.npy',\n",
       " 'mymodel.pkl_12.npy',\n",
       " 'mymodel.pkl_13.npy',\n",
       " 'mymodel.pkl_14.npy',\n",
       " 'mymodel.pkl_15.npy',\n",
       " 'mymodel.pkl_16.npy',\n",
       " 'mymodel.pkl_17.npy',\n",
       " 'mymodel.pkl_18.npy',\n",
       " 'mymodel.pkl_19.npy',\n",
       " 'mymodel.pkl_20.npy',\n",
       " 'mymodel.pkl_21.npy',\n",
       " 'mymodel.pkl_22.npy',\n",
       " 'mymodel.pkl_23.npy',\n",
       " 'mymodel.pkl_24.npy',\n",
       " 'mymodel.pkl_25.npy',\n",
       " 'mymodel.pkl_26.npy',\n",
       " 'mymodel.pkl_27.npy',\n",
       " 'mymodel.pkl_28.npy',\n",
       " 'mymodel.pkl_29.npy',\n",
       " 'mymodel.pkl_30.npy',\n",
       " 'mymodel.pkl_31.npy',\n",
       " 'mymodel.pkl_32.npy',\n",
       " 'mymodel.pkl_33.npy',\n",
       " 'mymodel.pkl_34.npy',\n",
       " 'mymodel.pkl_35.npy',\n",
       " 'mymodel.pkl_36.npy',\n",
       " 'mymodel.pkl_37.npy',\n",
       " 'mymodel.pkl_38.npy',\n",
       " 'mymodel.pkl_39.npy',\n",
       " 'mymodel.pkl_40.npy',\n",
       " 'mymodel.pkl_41.npy',\n",
       " 'mymodel.pkl_42.npy',\n",
       " 'mymodel.pkl_43.npy',\n",
       " 'mymodel.pkl_44.npy',\n",
       " 'mymodel.pkl_45.npy',\n",
       " 'mymodel.pkl_46.npy',\n",
       " 'mymodel.pkl_47.npy',\n",
       " 'mymodel.pkl_48.npy',\n",
       " 'mymodel.pkl_49.npy',\n",
       " 'mymodel.pkl_50.npy',\n",
       " 'mymodel.pkl_51.npy',\n",
       " 'mymodel.pkl_52.npy',\n",
       " 'mymodel.pkl_53.npy',\n",
       " 'mymodel.pkl_54.npy',\n",
       " 'mymodel.pkl_55.npy',\n",
       " 'mymodel.pkl_56.npy',\n",
       " 'mymodel.pkl_57.npy',\n",
       " 'mymodel.pkl_58.npy',\n",
       " 'mymodel.pkl_59.npy',\n",
       " 'mymodel.pkl_60.npy',\n",
       " 'mymodel.pkl_61.npy',\n",
       " 'mymodel.pkl_62.npy',\n",
       " 'mymodel.pkl_63.npy',\n",
       " 'mymodel.pkl_64.npy',\n",
       " 'mymodel.pkl_65.npy',\n",
       " 'mymodel.pkl_66.npy',\n",
       " 'mymodel.pkl_67.npy',\n",
       " 'mymodel.pkl_68.npy',\n",
       " 'mymodel.pkl_69.npy',\n",
       " 'mymodel.pkl_70.npy',\n",
       " 'mymodel.pkl_71.npy',\n",
       " 'mymodel.pkl_72.npy',\n",
       " 'mymodel.pkl_73.npy',\n",
       " 'mymodel.pkl_74.npy',\n",
       " 'mymodel.pkl_75.npy',\n",
       " 'mymodel.pkl_76.npy',\n",
       " 'mymodel.pkl_77.npy',\n",
       " 'mymodel.pkl_78.npy',\n",
       " 'mymodel.pkl_79.npy',\n",
       " 'mymodel.pkl_80.npy',\n",
       " 'mymodel.pkl_81.npy',\n",
       " 'mymodel.pkl_82.npy',\n",
       " 'mymodel.pkl_83.npy',\n",
       " 'mymodel.pkl_84.npy',\n",
       " 'mymodel.pkl_85.npy',\n",
       " 'mymodel.pkl_86.npy',\n",
       " 'mymodel.pkl_87.npy',\n",
       " 'mymodel.pkl_88.npy',\n",
       " 'mymodel.pkl_89.npy',\n",
       " 'mymodel.pkl_90.npy',\n",
       " 'mymodel.pkl_91.npy',\n",
       " 'mymodel.pkl_92.npy',\n",
       " 'mymodel.pkl_93.npy',\n",
       " 'mymodel.pkl_94.npy',\n",
       " 'mymodel.pkl_95.npy',\n",
       " 'mymodel.pkl_96.npy',\n",
       " 'mymodel.pkl_97.npy',\n",
       " 'mymodel.pkl_98.npy',\n",
       " 'mymodel.pkl_99.npy',\n",
       " 'mymodel.pkl_100.npy',\n",
       " 'mymodel.pkl_101.npy',\n",
       " 'mymodel.pkl_102.npy',\n",
       " 'mymodel.pkl_103.npy',\n",
       " 'mymodel.pkl_104.npy',\n",
       " 'mymodel.pkl_105.npy',\n",
       " 'mymodel.pkl_106.npy',\n",
       " 'mymodel.pkl_107.npy',\n",
       " 'mymodel.pkl_108.npy',\n",
       " 'mymodel.pkl_109.npy',\n",
       " 'mymodel.pkl_110.npy',\n",
       " 'mymodel.pkl_111.npy',\n",
       " 'mymodel.pkl_112.npy',\n",
       " 'mymodel.pkl_113.npy',\n",
       " 'mymodel.pkl_114.npy',\n",
       " 'mymodel.pkl_115.npy',\n",
       " 'mymodel.pkl_116.npy',\n",
       " 'mymodel.pkl_117.npy',\n",
       " 'mymodel.pkl_118.npy',\n",
       " 'mymodel.pkl_119.npy',\n",
       " 'mymodel.pkl_120.npy',\n",
       " 'mymodel.pkl_121.npy',\n",
       " 'mymodel.pkl_122.npy',\n",
       " 'mymodel.pkl_123.npy',\n",
       " 'mymodel.pkl_124.npy',\n",
       " 'mymodel.pkl_125.npy',\n",
       " 'mymodel.pkl_126.npy',\n",
       " 'mymodel.pkl_127.npy',\n",
       " 'mymodel.pkl_128.npy',\n",
       " 'mymodel.pkl_129.npy',\n",
       " 'mymodel.pkl_130.npy',\n",
       " 'mymodel.pkl_131.npy',\n",
       " 'mymodel.pkl_132.npy',\n",
       " 'mymodel.pkl_133.npy',\n",
       " 'mymodel.pkl_134.npy',\n",
       " 'mymodel.pkl_135.npy',\n",
       " 'mymodel.pkl_136.npy',\n",
       " 'mymodel.pkl_137.npy',\n",
       " 'mymodel.pkl_138.npy',\n",
       " 'mymodel.pkl_139.npy',\n",
       " 'mymodel.pkl_140.npy',\n",
       " 'mymodel.pkl_141.npy',\n",
       " 'mymodel.pkl_142.npy',\n",
       " 'mymodel.pkl_143.npy',\n",
       " 'mymodel.pkl_144.npy',\n",
       " 'mymodel.pkl_145.npy',\n",
       " 'mymodel.pkl_146.npy',\n",
       " 'mymodel.pkl_147.npy',\n",
       " 'mymodel.pkl_148.npy',\n",
       " 'mymodel.pkl_149.npy',\n",
       " 'mymodel.pkl_150.npy',\n",
       " 'mymodel.pkl_151.npy',\n",
       " 'mymodel.pkl_152.npy',\n",
       " 'mymodel.pkl_153.npy',\n",
       " 'mymodel.pkl_154.npy',\n",
       " 'mymodel.pkl_155.npy',\n",
       " 'mymodel.pkl_156.npy',\n",
       " 'mymodel.pkl_157.npy',\n",
       " 'mymodel.pkl_158.npy',\n",
       " 'mymodel.pkl_159.npy',\n",
       " 'mymodel.pkl_160.npy',\n",
       " 'mymodel.pkl_161.npy',\n",
       " 'mymodel.pkl_162.npy',\n",
       " 'mymodel.pkl_163.npy',\n",
       " 'mymodel.pkl_164.npy',\n",
       " 'mymodel.pkl_165.npy',\n",
       " 'mymodel.pkl_166.npy',\n",
       " 'mymodel.pkl_167.npy',\n",
       " 'mymodel.pkl_168.npy',\n",
       " 'mymodel.pkl_169.npy',\n",
       " 'mymodel.pkl_170.npy',\n",
       " 'mymodel.pkl_171.npy',\n",
       " 'mymodel.pkl_172.npy',\n",
       " 'mymodel.pkl_173.npy',\n",
       " 'mymodel.pkl_174.npy',\n",
       " 'mymodel.pkl_175.npy',\n",
       " 'mymodel.pkl_176.npy',\n",
       " 'mymodel.pkl_177.npy',\n",
       " 'mymodel.pkl_178.npy',\n",
       " 'mymodel.pkl_179.npy',\n",
       " 'mymodel.pkl_180.npy',\n",
       " 'mymodel.pkl_181.npy',\n",
       " 'mymodel.pkl_182.npy',\n",
       " 'mymodel.pkl_183.npy',\n",
       " 'mymodel.pkl_184.npy',\n",
       " 'mymodel.pkl_185.npy',\n",
       " 'mymodel.pkl_186.npy',\n",
       " 'mymodel.pkl_187.npy',\n",
       " 'mymodel.pkl_188.npy',\n",
       " 'mymodel.pkl_189.npy',\n",
       " 'mymodel.pkl_190.npy',\n",
       " 'mymodel.pkl_191.npy',\n",
       " 'mymodel.pkl_192.npy',\n",
       " 'mymodel.pkl_193.npy',\n",
       " 'mymodel.pkl_194.npy',\n",
       " 'mymodel.pkl_195.npy',\n",
       " 'mymodel.pkl_196.npy',\n",
       " 'mymodel.pkl_197.npy',\n",
       " 'mymodel.pkl_198.npy',\n",
       " 'mymodel.pkl_199.npy',\n",
       " 'mymodel.pkl_200.npy',\n",
       " 'mymodel.pkl_201.npy',\n",
       " 'mymodel.pkl_202.npy',\n",
       " 'mymodel.pkl_203.npy',\n",
       " 'mymodel.pkl_204.npy',\n",
       " 'mymodel.pkl_205.npy',\n",
       " 'mymodel.pkl_206.npy',\n",
       " 'mymodel.pkl_207.npy',\n",
       " 'mymodel.pkl_208.npy',\n",
       " 'mymodel.pkl_209.npy',\n",
       " 'mymodel.pkl_210.npy',\n",
       " 'mymodel.pkl_211.npy',\n",
       " 'mymodel.pkl_212.npy',\n",
       " 'mymodel.pkl_213.npy',\n",
       " 'mymodel.pkl_214.npy',\n",
       " 'mymodel.pkl_215.npy',\n",
       " 'mymodel.pkl_216.npy',\n",
       " 'mymodel.pkl_217.npy',\n",
       " 'mymodel.pkl_218.npy',\n",
       " 'mymodel.pkl_219.npy',\n",
       " 'mymodel.pkl_220.npy',\n",
       " 'mymodel.pkl_221.npy',\n",
       " 'mymodel.pkl_222.npy',\n",
       " 'mymodel.pkl_223.npy',\n",
       " 'mymodel.pkl_224.npy',\n",
       " 'mymodel.pkl_225.npy',\n",
       " 'mymodel.pkl_226.npy',\n",
       " 'mymodel.pkl_227.npy',\n",
       " 'mymodel.pkl_228.npy',\n",
       " 'mymodel.pkl_229.npy',\n",
       " 'mymodel.pkl_230.npy',\n",
       " 'mymodel.pkl_231.npy',\n",
       " 'mymodel.pkl_232.npy',\n",
       " 'mymodel.pkl_233.npy',\n",
       " 'mymodel.pkl_234.npy',\n",
       " 'mymodel.pkl_235.npy',\n",
       " 'mymodel.pkl_236.npy',\n",
       " 'mymodel.pkl_237.npy',\n",
       " 'mymodel.pkl_238.npy',\n",
       " 'mymodel.pkl_239.npy',\n",
       " 'mymodel.pkl_240.npy',\n",
       " 'mymodel.pkl_241.npy',\n",
       " 'mymodel.pkl_242.npy',\n",
       " 'mymodel.pkl_243.npy',\n",
       " 'mymodel.pkl_244.npy',\n",
       " 'mymodel.pkl_245.npy',\n",
       " 'mymodel.pkl_246.npy',\n",
       " 'mymodel.pkl_247.npy',\n",
       " 'mymodel.pkl_248.npy',\n",
       " 'mymodel.pkl_249.npy',\n",
       " 'mymodel.pkl_250.npy',\n",
       " 'mymodel.pkl_251.npy',\n",
       " 'mymodel.pkl_252.npy',\n",
       " 'mymodel.pkl_253.npy',\n",
       " 'mymodel.pkl_254.npy',\n",
       " 'mymodel.pkl_255.npy',\n",
       " 'mymodel.pkl_256.npy',\n",
       " 'mymodel.pkl_257.npy',\n",
       " 'mymodel.pkl_258.npy',\n",
       " 'mymodel.pkl_259.npy',\n",
       " 'mymodel.pkl_260.npy',\n",
       " 'mymodel.pkl_261.npy',\n",
       " 'mymodel.pkl_262.npy',\n",
       " 'mymodel.pkl_263.npy',\n",
       " 'mymodel.pkl_264.npy',\n",
       " 'mymodel.pkl_265.npy',\n",
       " 'mymodel.pkl_266.npy',\n",
       " 'mymodel.pkl_267.npy',\n",
       " 'mymodel.pkl_268.npy',\n",
       " 'mymodel.pkl_269.npy',\n",
       " 'mymodel.pkl_270.npy',\n",
       " 'mymodel.pkl_271.npy',\n",
       " 'mymodel.pkl_272.npy',\n",
       " 'mymodel.pkl_273.npy',\n",
       " 'mymodel.pkl_274.npy',\n",
       " 'mymodel.pkl_275.npy',\n",
       " 'mymodel.pkl_276.npy',\n",
       " 'mymodel.pkl_277.npy',\n",
       " 'mymodel.pkl_278.npy',\n",
       " 'mymodel.pkl_279.npy',\n",
       " 'mymodel.pkl_280.npy',\n",
       " 'mymodel.pkl_281.npy',\n",
       " 'mymodel.pkl_282.npy',\n",
       " 'mymodel.pkl_283.npy',\n",
       " 'mymodel.pkl_284.npy',\n",
       " 'mymodel.pkl_285.npy',\n",
       " 'mymodel.pkl_286.npy',\n",
       " 'mymodel.pkl_287.npy',\n",
       " 'mymodel.pkl_288.npy',\n",
       " 'mymodel.pkl_289.npy',\n",
       " 'mymodel.pkl_290.npy',\n",
       " 'mymodel.pkl_291.npy',\n",
       " 'mymodel.pkl_292.npy',\n",
       " 'mymodel.pkl_293.npy',\n",
       " 'mymodel.pkl_294.npy',\n",
       " 'mymodel.pkl_295.npy',\n",
       " 'mymodel.pkl_296.npy',\n",
       " 'mymodel.pkl_297.npy',\n",
       " 'mymodel.pkl_298.npy',\n",
       " 'mymodel.pkl_299.npy',\n",
       " 'mymodel.pkl_300.npy',\n",
       " 'mymodel.pkl_301.npy',\n",
       " 'mymodel.pkl_302.npy',\n",
       " 'mymodel.pkl_303.npy',\n",
       " 'mymodel.pkl_304.npy',\n",
       " 'mymodel.pkl_305.npy',\n",
       " 'mymodel.pkl_306.npy',\n",
       " 'mymodel.pkl_307.npy',\n",
       " 'mymodel.pkl_308.npy',\n",
       " 'mymodel.pkl_309.npy',\n",
       " 'mymodel.pkl_310.npy',\n",
       " 'mymodel.pkl_311.npy',\n",
       " 'mymodel.pkl_312.npy',\n",
       " 'mymodel.pkl_313.npy',\n",
       " 'mymodel.pkl_314.npy',\n",
       " 'mymodel.pkl_315.npy',\n",
       " 'mymodel.pkl_316.npy',\n",
       " 'mymodel.pkl_317.npy',\n",
       " 'mymodel.pkl_318.npy',\n",
       " 'mymodel.pkl_319.npy',\n",
       " 'mymodel.pkl_320.npy',\n",
       " 'mymodel.pkl_321.npy',\n",
       " 'mymodel.pkl_322.npy',\n",
       " 'mymodel.pkl_323.npy',\n",
       " 'mymodel.pkl_324.npy',\n",
       " 'mymodel.pkl_325.npy',\n",
       " 'mymodel.pkl_326.npy',\n",
       " 'mymodel.pkl_327.npy',\n",
       " 'mymodel.pkl_328.npy',\n",
       " 'mymodel.pkl_329.npy',\n",
       " 'mymodel.pkl_330.npy',\n",
       " 'mymodel.pkl_331.npy',\n",
       " 'mymodel.pkl_332.npy',\n",
       " 'mymodel.pkl_333.npy',\n",
       " 'mymodel.pkl_334.npy',\n",
       " 'mymodel.pkl_335.npy',\n",
       " 'mymodel.pkl_336.npy',\n",
       " 'mymodel.pkl_337.npy',\n",
       " 'mymodel.pkl_338.npy',\n",
       " 'mymodel.pkl_339.npy',\n",
       " 'mymodel.pkl_340.npy',\n",
       " 'mymodel.pkl_341.npy',\n",
       " 'mymodel.pkl_342.npy',\n",
       " 'mymodel.pkl_343.npy',\n",
       " 'mymodel.pkl_344.npy',\n",
       " 'mymodel.pkl_345.npy',\n",
       " 'mymodel.pkl_346.npy',\n",
       " 'mymodel.pkl_347.npy',\n",
       " 'mymodel.pkl_348.npy',\n",
       " 'mymodel.pkl_349.npy',\n",
       " 'mymodel.pkl_350.npy',\n",
       " 'mymodel.pkl_351.npy',\n",
       " 'mymodel.pkl_352.npy',\n",
       " 'mymodel.pkl_353.npy',\n",
       " 'mymodel.pkl_354.npy',\n",
       " 'mymodel.pkl_355.npy',\n",
       " 'mymodel.pkl_356.npy',\n",
       " 'mymodel.pkl_357.npy',\n",
       " 'mymodel.pkl_358.npy',\n",
       " 'mymodel.pkl_359.npy',\n",
       " 'mymodel.pkl_360.npy',\n",
       " 'mymodel.pkl_361.npy',\n",
       " 'mymodel.pkl_362.npy',\n",
       " 'mymodel.pkl_363.npy',\n",
       " 'mymodel.pkl_364.npy',\n",
       " 'mymodel.pkl_365.npy',\n",
       " 'mymodel.pkl_366.npy',\n",
       " 'mymodel.pkl_367.npy',\n",
       " 'mymodel.pkl_368.npy',\n",
       " 'mymodel.pkl_369.npy',\n",
       " 'mymodel.pkl_370.npy',\n",
       " 'mymodel.pkl_371.npy',\n",
       " 'mymodel.pkl_372.npy',\n",
       " 'mymodel.pkl_373.npy',\n",
       " 'mymodel.pkl_374.npy',\n",
       " 'mymodel.pkl_375.npy',\n",
       " 'mymodel.pkl_376.npy',\n",
       " 'mymodel.pkl_377.npy',\n",
       " 'mymodel.pkl_378.npy',\n",
       " 'mymodel.pkl_379.npy',\n",
       " 'mymodel.pkl_380.npy',\n",
       " 'mymodel.pkl_381.npy',\n",
       " 'mymodel.pkl_382.npy',\n",
       " 'mymodel.pkl_383.npy',\n",
       " 'mymodel.pkl_384.npy',\n",
       " 'mymodel.pkl_385.npy',\n",
       " 'mymodel.pkl_386.npy',\n",
       " 'mymodel.pkl_387.npy',\n",
       " 'mymodel.pkl_388.npy',\n",
       " 'mymodel.pkl_389.npy',\n",
       " 'mymodel.pkl_390.npy',\n",
       " 'mymodel.pkl_391.npy',\n",
       " 'mymodel.pkl_392.npy',\n",
       " 'mymodel.pkl_393.npy',\n",
       " 'mymodel.pkl_394.npy',\n",
       " 'mymodel.pkl_395.npy',\n",
       " 'mymodel.pkl_396.npy',\n",
       " 'mymodel.pkl_397.npy',\n",
       " 'mymodel.pkl_398.npy',\n",
       " 'mymodel.pkl_399.npy',\n",
       " 'mymodel.pkl_400.npy',\n",
       " 'mymodel.pkl_401.npy']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = clf.pred(test_pairs_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## prepare submission\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = submission_info[['index']]\n",
    "submission['sameArtist'] = y_pred\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
